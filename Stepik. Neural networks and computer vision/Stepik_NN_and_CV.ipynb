{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch","metadata":{"id":"5d1bbe7b-1773-4c53-8ae2-81b8842696ad"},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"Реализуйте при помощи pyTorch функцию, которая возвращает сумму (x.sum()) элементов тензора X, строго превышающих значение limit, которое является входным значением алгоритма.\n\nВходная матрица: X = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])","metadata":{"id":"39c099c7-b6a1-4736-88f8-6f087fd8dc83"}},{"cell_type":"code","source":"X = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nlimit = int(input())\n\nlarger_than_limit_sum = (X[X > limit]).sum()\n\nprint(larger_than_limit_sum)","metadata":{"id":"16ac1f55-3163-4023-8d11-76ab99d99cc1","outputId":"1ac87447-676c-46ae-a66c-20e24b3bca52"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Неделя 2. Строим первую нейронную сеть","metadata":{"id":"sRVurRpho41A"}},{"cell_type":"markdown","source":"2.6 Семинар: Реализация градиентного спуска (часть 1)","metadata":{"id":"nr1AD9_ipLvS"}},{"cell_type":"code","source":"import torch","metadata":{"id":"3yDtjFC9t4zZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Допустим, у нас есть функция f(x)=loge(x +3)f(x) = log_{e}(x + 3)f(x)=loge​(x +3). Мы выбрали начальное приближение xt=0 =7x^{t=0} = 7xt=0 =7 . И шаг градиентного спуска α=10\\alpha=10α=10\n\nЧему будет равен xt=1x^{t=1}xt=1? ","metadata":{"id":"pg34YJN7pUar"}},{"cell_type":"code","source":"x = torch.tensor(7.0, requires_grad=True)\nf = torch.log(x + 3)\nf.backward()\nlr = 10\nx.data = x.data - lr * x.grad.data\nprint(x.data)","metadata":{"id":"tyN-GjZBoP4y","outputId":"4e2486bb-eb16-4dd0-9167-18f4c608612c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Допустим, у нас есть функция f(X)=∑loge(xij+1)f(X) = \\sum{log_{e}(x_{ij} + 1)}f(X)=∑loge​(xij​+1), где XXX - тензор размера 2x2. Мы выбрали начальное приближение Xt=0 =[[1,2],[4,5]]X^{t=0} = [[1, 2], [4, 5]]Xt=0 =[[1,2],[4,5]] . И шаг градиентного спуска α=10\\alpha=10α=10\n\nЧему будет равен Xt=1X^{t=1}Xt=1? ","metadata":{"id":"-aK8kii25EUh"}},{"cell_type":"code","source":"X = torch.tensor([[1.0, 2.0], [4.0, 5.0]], requires_grad=True)\nf = torch.log(X + 1).sum()\nf.backward()\nlr = 10\nX.data = X.data - lr * X.grad.data\nprint(X.data)","metadata":{"id":"MLGRmDtD5JOp","outputId":"a9756524-7d0e-46d4-95d9-372b649a13ac"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Реализуйте расчет градиента для функции f(w)=∏i,jloge(loge(wi,j +7))f(w) = \\prod\\limits_{i,j}{log_{e}(log_{e}({w_{i,j} + 7}}))f(w)=i,j∏​loge​(loge​(wi,j​ +7)) в точке w =[[5,10],[1,2]]w = [[5, 10], [1, 2]]w =[[5,10],[1,2]]\n\nПодсказка: перемножить все значения функции можно с помощью метода .prod()","metadata":{"id":"g46Ogfd-Ieqw"}},{"cell_type":"code","source":"w = torch.tensor([[5.,10.],\n                  [1.,2.]], requires_grad=True)\n\n#######\ndevice = torch.device('cuda:0' \n                      if torch.cuda.is_available() \n                      else 'cpu')\nw = w.to(device)\n#######\n\nfunction = torch.log(torch.log(w + 7)).prod()\n#function = (w+7).log().log().prod()\n\nfunction.backward()\n\nprint(w.grad, '<- gradient')","metadata":{"id":"6Et8Zc8F6295","outputId":"4aece58a-0d78-436c-d28b-35d47d76abdb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Неделя 3. Задачи решаемые при помощи нейронных сетей","metadata":{"id":"exhMKEUm4bSz"}},{"cell_type":"markdown","source":"**3.4 Теоретические задачи: Функции потерь**","metadata":{"id":"23GpcpHHh3A_"}},{"cell_type":"markdown","source":"Пусть имеется монетка, которую мы подбрасывали NNN раз, и MMM раз монетка выпала орлом вверх. Мы будем восстанавливать вероятность выпадения орла ppp при помощи минимизации бинарной кросс-энтропии:\n\np~=arg⁡min⁡p∑i=1N(−tilog⁡p−(1−ti)log⁡(1−p)),\\tilde{p} = \\arg\\min_p \\sum_{i=1}^N \\left( - t_i \\log p - (1 - t_i) \\log(1 - p) \\right),\np~​=argpmin​i=1∑N​(−ti​logp−(1−ti​)log(1−p)),где arg⁡min⁡xf(x)\\arg\\min_x f(x)argminx​f(x) -- значение xxx, при котором fff минимальна, ti=1t_i = 1ti​=1 в том случае, когда выпал орел и ti=0t_i = 0ti​=0 в том случае, когда выпала решка.","metadata":{"id":"-kVmn-BOG6Gv"}},{"cell_type":"code","source":"import sympy as sp\n\np, n, m = sp.symbols(\"p n m\")\nexpr = -(m * sp.log(p) + (n-m) * sp.log(1-p)) # расписали сумму\ndiff_expr = expr.diff(p) # производная\nsp.solve(diff_expr, 0, p) # решение","metadata":{"id":"ueRLZZqAKkdT","outputId":"c38567f2-5b17-43b6-b8a6-e54c133a7817"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3.5 Семинар: Строим первую нейронную сеть**","metadata":{"id":"ThF6JqiJu2mo"}},{"cell_type":"markdown","source":"Давайте попрактикуемся с SineNet:\n\n1) Добавим еще один fc-слой\n\n2) Заменим активацию между слоями на гиперболический тангенс","metadata":{"id":"jdQFQio-vBc5"}},{"cell_type":"code","source":"#было\nclass SineNet(torch.nn.Module):\n    def __init__(self, n_hidden_neurons):\n        super(SineNet, self).__init__()\n        self.fc1 = torch.nn.Linear(1, n_hidden_neurons)\n        self.act1 = torch.nn.Sigmoid()\n        self.fc2 = torch.nn.Linear(n_hidden_neurons, 1)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act1(x)\n        x = self.fc2(x)\n        return x\n\nsine_net = SineNet(50)","metadata":{"id":"DBEcj-uTHE_l","outputId":"ad642f0d-1260-4629-f1c5-59605235a2a8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Решение\nimport torch\n\nclass SineNet(torch.nn.Module):\n    def __init__(self, n_hidden_neurons):\n        super(SineNet, self).__init__()\n        self.fc1 = torch.nn.Linear(1, n_hidden_neurons)\n        self.act1 = torch.nn.Tanh()\n        self.fc2 = torch.nn.Linear(n_hidden_neurons, n_hidden_neurons)\n        self.act2 = torch.nn.Tanh()\n        self.fc3 = torch.nn.Linear(n_hidden_neurons, 1)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act1(x)\n        x = self.fc2(x)\n        x = self.act2(x)\n        x = self.fc3(x)\n        return x\n\nsine_net = SineNet(int(input()))\nsine_net.forward(torch.Tensor([1.]))\n\nprint(sine_net)","metadata":{"id":"202YwM5iu_yJ","outputId":"e59bf899-0b3d-4dab-9be1-b6e2ece3dfeb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3.5.6 Семинар: Строим первую нейронную сеть","metadata":{"id":"9eyOrdOe8Ttl"}},{"cell_type":"markdown","source":"Обучим нейронную сеть для задачи регрессии:\n\nВозьмем более сложную функцию в качестве таргета: y=2xsin(2−x)y=2^x sin(2^{-x})y=2xsin(2−x).\n\nКроме того, мы хотим получить хорошую метрику MAE на валидации: MAE=1l∑i=1l∣y_predi−y_targeti∣{MAE} = {\\frac {1}{l}}\\sum _{i=1}^{l}{|y\\_pred_{i}-{y\\_target_{i}}|}MAE=l1​∑i=1l​∣y_predi​−y_targeti​∣, тогда как знакомая нам MSE выглядит как MSE=1l∑i=1l(y_predi−y_targeti)2{MSE} = {\\frac {1}{l}}\\sum _{i=1}^{l}(y\\_pred_{i}-{y\\_target_{i}})^{2} MSE=l1​∑i=1l​(y_predi​−y_targeti​)2\n\nВот пример того, как нейросеть может отрабатывать на данной функции:\n\nДанный пример показывает MAE на валидации ~0.021 . Получите метрику не хуже 0.03","metadata":{"id":"Yt1F47w88Qz-"}},{"cell_type":"code","source":"import torch\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.rcParams['figure.figsize'] = (13.0, 5.0)\n\ndef target_function(x):\n    return 2**x * torch.sin(2**-x)\n\nclass RegressionNet(torch.nn.Module):\n    def __init__(self, n_hidden_neurons):\n        super(RegressionNet, self).__init__()\n        self.fc1 = torch.nn.Linear(1, n_hidden_neurons)\n        self.act1 = torch.nn.Sigmoid()\n        self.fc2 = torch.nn.Linear(n_hidden_neurons, 1)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act1(x)\n        x = self.fc2(x)\n        return x\n\nnet = RegressionNet(100)\n\n# ------Dataset preparation start--------:\nx_train =  torch.linspace(-10, 5, 100)\ny_train = target_function(x_train)\nnoise = torch.randn(y_train.shape) / 20.\ny_train = y_train + noise\nx_train.unsqueeze_(1)\ny_train.unsqueeze_(1)\n\nx_validation = torch.linspace(-10, 5, 100)\ny_validation = target_function(x_validation)\nx_validation.unsqueeze_(1)\ny_validation.unsqueeze_(1)\n# ------Dataset preparation end--------:\n\n\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n\ndef loss(pred, target):\n    return ((pred - target) ** 2).mean()\n\nfor epoch_index in range(2000):\n    optimizer.zero_grad()\n\n    y_pred = net.forward(x_train)\n    loss_value = loss(y_pred, y_train)\n    loss_value.backward()\n    optimizer.step()\n\n#Проверка осуществляется вызовом кода:\ndef metric(pred, target):\n    return (pred - target).abs().mean()\n\nprint(metric(net.forward(x_validation), y_validation).item())\n# (раскомментируйте, если решаете задание локально)","metadata":{"id":"59z7cwx7v4XE","outputId":"29c46e2c-0f55-4093-e294-ae72eee1b82a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(net, x, y):\n    y_pred = net.forward(x)\n\n    plt.plot(x.numpy(), y.numpy(), 'o', label='Groud truth')\n    plt.plot(x.numpy(), y_pred.data.numpy(), 'o', c='r', label='Prediction');\n    plt.legend(loc='upper left')\n    plt.xlabel('$x$')\n    plt.ylabel('$y$')\n\npredict(net, x_validation, y_validation)","metadata":{"id":"pXxiggUhZMG0","outputId":"35de0280-c9f9-47c0-ea7b-f43b823ae6f1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#решение от https://stepik.org/lesson/236236/step/15?discussion=1641231&thread=solutions&unit=208641\nimport torch\nimport matplotlib\nimport matplotlib.pyplot as plt\nmatplotlib.rcParams['figure.figsize'] = (15.0, 5.0)\n\n# Создание набора тренировочных и тестовых данных\ndef target_function(x):\n    return 2**x * torch.sin(2**-x)\n\n# ------Dataset preparation start--------:\nx_train =  torch.linspace(-10, 5, 100)\ny_train = target_function(x_train)\nnoise = torch.randn(y_train.shape) / 20.\ny_train = y_train + noise\nx_train.unsqueeze_(1)\ny_train.unsqueeze_(1)\n\nx_validation = torch.linspace(-10, 5, 100)\ny_validation = target_function(x_validation)\nx_validation.unsqueeze_(1)\ny_validation.unsqueeze_(1)\n# ------Dataset preparation end--------:\n\n# Визуализация подготовленных данных\nplt.plot(x_train.numpy(), y_train.numpy(), 'o', label='train dataset')\n# Визуализация тестовых данных\nplt.plot(x_validation.numpy(), y_validation.numpy(), '-', label='validation dataset')\n# Визуализация валидационных данных\nplt.title('2**x * torch.sin(2**-x)')\nplt.legend(loc='upper left')\nplt.xlabel('x_validation')\nplt.ylabel('y_validation')\nplt.show()","metadata":{"id":"xSv0Eua2aSbk","outputId":"dcf178e2-914e-4271-e07a-42baf230af00"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Функция оценки качества работы неросейти\ndef metric(pred, target):\n    return (pred - target).abs().mean()\n\n# Создание класса нейросети L-S-L-S-L (два скрытых слоя нейронов)\nclass RegressionNet(torch.nn.Module):\n  def __init__(self, n_hidden_neurons):\n    super(RegressionNet, self).__init__()\n    self.fc1 = torch.nn.Linear(1, n_hidden_neurons)\n    self.act1 = torch.nn.Sigmoid()\n    self.fc2 = torch.nn.Linear(n_hidden_neurons, n_hidden_neurons)\n    self.act2 = torch.nn.Sigmoid()\n    self.fc3 = torch.nn.Linear(n_hidden_neurons, 1)\n\n  # Функция определяющая последовательность применения слоев. x - это входное значение.\n  # значение x последовательно обрабатывается слоями и активационными функциями.\n  def forward(self, x):                               \n    x = self.fc1(x)                                   \n    x = self.act1(x)\n    x = self.fc2(x)\n    x = self.act2(x)\n    x = self.fc3(x)\n    return x\n\n# Создаем экземпляр класса нейросети\nnet = RegressionNet(5)\n\n# Задаем оптимизатор для нейросети\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n\n# Задаем фенкцию потерь\ndef loss(pred, target):\n  # mae = abs(pred - target)\n  # return mae.mean()\n  squares = (pred - target) ** 2\n  return squares.mean()","metadata":{"id":"k0j79MifbgFE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"При обучении нейросети записывается история изменения функции потерь (loss функции)\nи при завершении обучения сети выводиться график это функции.\nТаким образом можно визуализировать процесс обучения сети, наблюдать как меняется ошибка в процессе обучения.","metadata":{"id":"ifF7IYC7cAA_"}},{"cell_type":"code","source":"epoch_num = 2000\nloss_history = [[0,0] for i in range(epoch_num)]\n\nfor epoch_index in range(epoch_num):\n  optimizer.zero_grad()\n\n  y_pred = net.forward(x_train)\n  loss_value = loss(y_pred, y_train)\n  \n  loss_history[epoch_index][0] = epoch_index\n  loss_history[epoch_index][1] = loss_value.data.numpy().tolist()\n\n  loss_value.backward()\n  optimizer.step()\n\n# При построении отсекается первые 100 значений,\n# так как функция сначала имеет большие значения и начинает резко сходиться\nplt.plot([row[0] for row in loss_history][100:], [row[1] for row in loss_history][100:], '.')\nplt.title(label='Loss function')\nplt.xlabel('Epoch_index')\nplt.ylabel('Error');\nplt.show()","metadata":{"id":"Ohf6z2gjbjD7","outputId":"b793f67e-a130-4d5a-92f0-134899c962f4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Теперь смотрим на результат работы нейросети","metadata":{"id":"nYSnPhYbcUzg"}},{"cell_type":"code","source":"def predict(net, x, y):\n  y_pred = net.forward(x)\n  \n  # Визуализация тестовых данных\n  plt.plot(x.numpy(), y.numpy(), '-', label='Ground trurh')                     \n  # Визуализация предсказания нейросети данных\n  plt.plot(x.numpy(), y_pred.data.numpy(), 'x', c='g', label='Prediction')      \n  plt.title('2**x * torch.sin(2**-x)')\n  plt.legend(loc='upper left')\n  plt.xlabel('x')\n  plt.ylabel('y')                                                             \n  plt.show()\n\n# Визуализация работы нейросети\npredict(net, x_validation, y_validation)\n\n# Проверка качества нейросети (погрешность)\nprint(metric(net.forward(x_validation), y_validation).item())","metadata":{"id":"hUWxKlnvcCU9","outputId":"ad505237-9775-4d97-f380-9a16111ef101"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nrandom.seed(464466656562)","metadata":{"id":"gfq4PZ8gcXEu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.randint(0, 100)","metadata":{"id":"Ppj4NApvjPUX","outputId":"7f152480-e94f-4d46-e2e3-3516d098c2e3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3.6 Семинар: Классификация в PyTorch**","metadata":{"id":"MI1ezK-KVna2"}},{"cell_type":"markdown","source":"Давайте попрактикуемся с WineNet. Измените архитектуру так, чтобы на вход принимались все 13 признаков и проведите следующие эксперименты:\n\n1. Поэкспериментируйте с количеством нейронов в скрытых слоях. Попробуйте поставить очень маленькое число. Существует ли пороговое значение количества скрытых нейронов, при котором обучение становится невозможным?\n\n2. Попробуйте передавать различные значения test_size в функцию train_test_split. При каком значении test_size сеть предсказывает хуже чем Base Rate*? И какой Base Rate у датасета вин?\n\n3. Зависит ли время обучения на одной эпохе от размера батча? Исследуйте эту зависимость.\n\nПоделитесь своими выводами в комментариях :)\n\n*Base Rate - значение accuracy для случая, когда модель для всех объектов предсказывает самый частотный класс в датасете","metadata":{"id":"ovkfKNWKVs4_"}},{"cell_type":"code","source":"import torch\nimport random\nimport numpy as np\nimport pandas as pd\n\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)\ntorch.backends.cudnn.deterministic = True","metadata":{"id":"VhgKEB2SeOrG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.datasets\nwine = sklearn.datasets.load_wine()\nwine.data.shape","metadata":{"id":"KrqdNkF0eOrK","outputId":"dde7bbaf-2445-4aac-8af7-b5740fc149ff"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wine.data.shape[1]","metadata":{"id":"RQmOAsuPXEk7","outputId":"24bdb32c-05fb-403e-bf66-9504b28a72c9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(wine.data)","metadata":{"id":"wl6gB6PgWbPD","outputId":"802c4720-c07b-4653-fd4d-0085ff27b34b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(wine.target).value_counts()","metadata":{"id":"3jGrkARCWvhb","outputId":"2d86ea18-1a6d-4dca-df71-76f1aa17eae0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_rate = pd.DataFrame(wine.target).value_counts().max()/pd.DataFrame(wine.target).count()\nbase_rate","metadata":{"id":"7bdddqLMX8il","outputId":"7801c1cc-6c9b-4ff2-9ba9-7e4cd6a3ad6d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    wine.data, \n    wine.target, \n    test_size=0.3, \n    shuffle=True)\n\nX_train = torch.FloatTensor(X_train)\nX_test = torch.FloatTensor(X_test)\ny_train = torch.LongTensor(y_train)\ny_test = torch.LongTensor(y_test)","metadata":{"id":"UH2lA6bfeOrM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class WineNet(torch.nn.Module):\n    def __init__(self, n_hidden_neurons):\n        super(WineNet, self).__init__()\n        \n        self.fc1 = torch.nn.Linear(13, n_hidden_neurons)\n        self.activ1 = torch.nn.Sigmoid()\n        # self.fc2 = torch.nn.Linear(n_hidden_neurons, n_hidden_neurons)\n        # self.activ2 = torch.nn.Sigmoid()\n        self.fc3 = torch.nn.Linear(n_hidden_neurons, 3)\n        self.sm = torch.nn.Softmax(dim=1)\n        \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.activ1(x)\n        # x = self.fc2(x)\n        # x = self.activ2(x)\n        x = self.fc3(x)\n        return x\n\n    def inference(self, x):\n        x = self.forward(x)\n        x = self.sm(x)\n        return x\n    \nwine_net = WineNet(30)","metadata":{"id":"UtKzUXp1eOrN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = torch.nn.CrossEntropyLoss()\n\noptimizer = torch.optim.Adam(wine_net.parameters(), \n                             lr=1.0e-3)","metadata":{"id":"WYfQoRIWeOrO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 1000\n\nfor epoch in range(5000):\n    order = np.random.permutation(len(X_train))\n    for start_index in range(0, len(X_train), batch_size):\n        optimizer.zero_grad()\n        \n        batch_indexes = order[start_index:start_index+batch_size]\n        \n        x_batch = X_train[batch_indexes]\n        y_batch = y_train[batch_indexes]\n        \n        preds = wine_net.forward(x_batch) \n        \n        loss_value = loss(preds, y_batch)\n        loss_value.backward()\n        \n        optimizer.step()\n        \n    if epoch % 100 == 0:\n        test_preds = wine_net.forward(X_test)\n        test_preds = test_preds.argmax(dim=1)\n        print((test_preds == y_test).float().mean())","metadata":{"id":"nF7ewzm-eOrR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#4 Неделя. Методы оптимизации.","metadata":{"id":"maM6ncsPe3ld"}},{"cell_type":"markdown","source":"**4.4.1 Семинар: Классификация рукописных чисел полносвязанной сетью**","metadata":{"id":"Zg7BoV0q3BE7"}},{"cell_type":"markdown","source":"Попрактикуемся с методом reshape. У нас есть трехмерный тензор размерности (6000, 28, 28) . Сопоставьте операцию над этим тензором и её результатат:","metadata":{"id":"vGKn91Ek3LO5"}},{"cell_type":"code","source":"import torch\nimport random\nimport numpy as np","metadata":{"id":"75CMBjOSXSAU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = torch.tensor(np.random.default_rng(42).random((6000,28,28)))\nx.shape","metadata":{"id":"FhjRg9FM3KFA","outputId":"da5196eb-f3ca-4a54-fb22-668f4ae9cc9f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.reshape(-1).shape","metadata":{"id":"RSpX5daq4SP0","outputId":"37073c03-4d76-458f-bf10-3177498d2014"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.reshape(-1,1,1).shape","metadata":{"id":"_UW_e9pb6TV7","outputId":"9e164986-d0fa-4f11-f786-36647c6d4245"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.reshape(len(x[1]), len(x), len(x[2])).shape","metadata":{"id":"P9ryDUyJ7QZy","outputId":"8b35a869-379c-4f75-e171-faa9ab995133"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.reshape(-1,14,32,7).shape","metadata":{"id":"RzFA-_S37a6N","outputId":"9e663ffa-6d32-4f11-9d6b-919517b5d925"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.reshape(-1,9).shape","metadata":{"id":"_8QwUWyM7e-l","outputId":"cc8dad63-0924-4e56-d4f7-48c4e85576b0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.reshape(-1,6000).shape","metadata":{"id":"w6h9BD4y7lv8","outputId":"37f3f3f7-29f0-435f-8730-1759393393b6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Проверяем доступность GPU","metadata":{"id":"g5CDJnup-2Nq"}},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"id":"9YmHLly27seG","outputId":"2447913f-ada1-4863-e32d-19962841cf58"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"CYUTfi7x_Aox","outputId":"50f32a7a-d8ba-4998-b893-e046a243b15d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"M9S_Swd-_GmZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4.4.5 Семинар: Классификация рукописных чисел полносвязанной сетью**","metadata":{"id":"wsX1Ikhb3uiK"}},{"cell_type":"markdown","source":"Запустите код из видео на GPU. В последнем шаге мы рисовали график accuracy и loss на валидации. А что с ними происходит на train'е?\n\n    Постройте на одном графике loss для train и validation.\n    Правда ли, что loss на train и validation падает одинаково быстро и выходит на одинаковое значение, или же у нас есть переобучение?\n    Ведет ли увеличение количества эпох (40 эпох -> 200 эпох) к улучшению метрик на валидации?\n    Замерьте время вычисления 100 эпох на CPU и на GPU. Какое ускорение вы наблюдаете?\n    Замедляет ли torch.backends.cudnn.deterministic = True обучение на практике? Если да, то насколько?\n    Попробуйте разные методы градиентного спуска, которые были в лекции. Как выбор градиентного спуска влияет на accuracy? Для уверенности лучше проводить один эксперимент 3-5 раз на разных random seed: так вы поймете, действительно ли сказывается влияние метода или дело в случайности.\n","metadata":{"id":"8BzYa5sQ3y7y"}},{"cell_type":"code","source":"import torch\nimport random\nimport numpy as np\n\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)\ntorch.backends.cudnn.deterministic = True","metadata":{"id":"nkZNu2muAzxy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.datasets\nMNIST_train = torchvision.datasets.MNIST('./', download=True, train=True)\nMNIST_test = torchvision.datasets.MNIST('./', download=True, train=False)","metadata":{"id":"-4eIRW9q4W_C","outputId":"cf224a3e-51af-4507-f0dc-668272f1868f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = MNIST_train.train_data\ny_train = MNIST_train.train_labels\nX_test = MNIST_test.test_data\ny_test = MNIST_test.test_labels","metadata":{"id":"7Gn04nUt4YjM","outputId":"4c5e4759-63d0-4a1f-a45b-02c6273de4b2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.dtype, y_train.dtype","metadata":{"id":"8Rs237qF4fJr","outputId":"6ee24b96-35ba-4dcb-e1c5-7a375f052bce"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.float()\nX_test = X_test.float()","metadata":{"id":"sHQlmMjs4i6b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_test.shape","metadata":{"id":"wLmrvicO4kbz","outputId":"62498217-4c39-4365-b00c-2fb7cd36bac6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.shape, y_test.shape","metadata":{"id":"BL5rC7ev4qbN","outputId":"0787ee20-33d0-4b80-f064-da2f7476d58b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(X_train[0, :, :])\nplt.show()\nprint(y_train[0])","metadata":{"id":"bqqEvJP54sn8","outputId":"2c14953f-10f1-4fc3-93f2-b617eabb3af7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.reshape([-1, 28 * 28])\nX_test = X_test.reshape([-1, 28 * 28])","metadata":{"id":"peAFZJL-4xUV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MNISTNet(torch.nn.Module):\n\n    def __init__(self, n_hidden_neurons):\n        super(MNISTNet, self).__init__()\n        self.fc1 = torch.nn.Linear(28 * 28, n_hidden_neurons)\n        self.ac1 = torch.nn.Sigmoid()\n        self.fc2 = torch.nn.Linear(n_hidden_neurons, 10)\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.ac1(x)\n        x = self.fc2(x)\n        return x\n\nmnist_net = MNISTNet(100)\n","metadata":{"id":"RMAiVlBT40j1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nmnist_net = mnist_net.to(device)\n#list(mnist_net.parameters())","metadata":{"id":"4ZAGUg1H444X","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(mnist_net.parameters(), lr=1.0e-3)","metadata":{"id":"Vy_UcIEc5BsZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = X_test.to(device)\ny_test = y_test.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 100\n\ntest_accuracy_history = []\ntest_loss_history = []\ntrain_accuracy_history = []\ntrain_loss_history = []\n\nX_test = X_test.to(device)\ny_test = y_test.to(device)\n\nfor epoch in range(100):\n    order = np.random.permutation(len(X_train))\n\n    train_accuracy_epoch = []\n    train_loss_epoch = []\n    \n    for start_index in range(0, len(X_train), batch_size):\n        optimizer.zero_grad()\n        \n        batch_indexes = order[start_index:start_index+batch_size]\n        \n        X_batch = X_train[batch_indexes].to(device)\n        y_batch = y_train[batch_indexes].to(device)\n        \n        preds = mnist_net.forward(X_batch)\n        \n        loss_value = loss(preds, y_batch)\n        train_loss_epoch.append(loss_value)\n\n        loss_value.backward()\n        \n        train_accuracy_epoch.append((preds.argmax(dim=1) == y_batch).float().mean())\n\n        optimizer.step()\n\n    test_preds = mnist_net.forward(X_test)\n    test_loss_history.append(loss(test_preds, y_test))\n    train_loss_history.append(torch.stack(train_loss_epoch).float().mean())\n\n    accuracy_test = (test_preds.argmax(dim=1) == y_test).float().mean()\n    accuracy_train = torch.stack(train_accuracy_epoch).float().mean()\n    test_accuracy_history.append(accuracy_test)\n    train_accuracy_history.append(accuracy_train)\n    print('epoch = {}, accuracy_test = {}, accuracy_train = {}'.format(epoch, accuracy_test, accuracy_train))","metadata":{"id":"Z8VnaNTk4_Yq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(test_accuracy_history) #blue\nplt.plot(train_accuracy_history) #orange","metadata":{"id":"W_20Y92A5FU3","outputId":"4259ce9b-da07-42bd-c79a-d1452388ceb2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(test_loss_history)  #blue\nplt.plot(train_loss_history) #orange","metadata":{"id":"lpTrk0gfGSDB","outputId":"5d59060c-4c31-493a-9df2-3279391aab6e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"TL0mkzVv1YWS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Решение с функцией, для гибкой настройки параметров и профилирования","metadata":{"id":"gDmPZXSI1ZPD"}},{"cell_type":"code","source":"import torch\nimport random\nimport numpy as np\n\nimport matplotlib\nmatplotlib.rcParams['figure.figsize'] = (15.0, 5.0)\n\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)\ntorch.backends.cudnn.deterministic = True","metadata":{"id":"ELdpzZNx10Qd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.datasets\nMNIST_train = torchvision.datasets.MNIST('./', download=True, train=True)\nMNIST_test = torchvision.datasets.MNIST('./', download=True, train=False)","metadata":{"id":"dTxq1vz010Qd","outputId":"bde8a042-84bc-45cb-e574-95f999a09c9d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MNISTNet(torch.nn.Module):\n\n    def __init__(self, n_hidden_neurons):\n        super(MNISTNet, self).__init__()\n        self.fc1 = torch.nn.Linear(28 * 28, n_hidden_neurons)\n        self.ac1 = torch.nn.Sigmoid()\n        self.fc2 = torch.nn.Linear(n_hidden_neurons, 10)\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.ac1(x)\n        x = self.fc2(x)\n        return x\n\n#Create function\ndef learn_MNISTNet(mnist_net, loss, optimizer, epoch_num=100, batch_size=100, device='cpu', verbose=True):\n    learn_history = {}\n    learn_history['accuracy_test'] = []\n    learn_history['accuracy_train'] = []\n    learn_history['loss_test'] = []\n    learn_history['loss_train'] = []\n    X_train = MNIST_train.data\n    y_train = MNIST_train.targets\n    X_test = MNIST_test.data\n    y_test = MNIST_test.targets\n\n    X_train = X_train.float()\n    X_test = X_test.float()\n    X_train = X_train.reshape([-1, 28 * 28])\n    X_test = X_test.reshape([-1, 28 * 28])  \n\n    X_test = X_test.to(device)\n    y_test = y_test.to(device)\n\n    for epoch in range(epoch_num):\n        order = np.random.permutation(len(X_train))\n\n        train_accuracy_epoch = []\n        train_loss_epoch = []\n        \n        for start_index in range(0, len(X_train), batch_size):\n            optimizer.zero_grad()\n            \n            batch_indexes = order[start_index:start_index+batch_size]\n            \n            X_batch = X_train[batch_indexes].to(device)\n            y_batch = y_train[batch_indexes].to(device)\n            \n            preds = mnist_net.forward(X_batch)\n            \n            loss_value = loss(preds, y_batch)\n            train_loss_epoch.append(loss_value)\n\n            loss_value.backward()\n            \n            train_accuracy_epoch.append((preds.argmax(dim=1) == y_batch).float().mean())\n\n            optimizer.step()\n\n        test_preds = mnist_net.forward(X_test)\n        learn_history['loss_test'].append(loss(test_preds, y_test))\n        learn_history['loss_train'].append(torch.stack(train_loss_epoch).float().mean())\n\n        accuracy_test = (test_preds.argmax(dim=1) == y_test).float().mean()\n        accuracy_train = torch.stack(train_accuracy_epoch).float().mean()\n        learn_history['accuracy_test'].append(accuracy_test)\n        learn_history['accuracy_train'].append(accuracy_train)\n        if verbose:\n            print('epoch = {}, accuracy_test = {:.3f}, accuracy_train = {:.3f}'.format(epoch, accuracy_test, accuracy_train))\n\n    return learn_history","metadata":{"id":"WZneYGGJNyBM","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rs=42\nrandom.seed(rs)\nnp.random.seed(rs)\ntorch.manual_seed(rs)\ntorch.cuda.manual_seed(rs)\ntorch.backends.cudnn.deterministic = True","metadata":{"id":"VgaIUIHj8oSg","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%timeit\ndevice = 'cuda:0'\n\nmnist_net = MNISTNet(100)\nmnist_net = mnist_net.to(device)\n\nloss = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(mnist_net.parameters(), lr=1.0e-3)\n#optimizer = torch.optim.SGD(mnist_net.parameters(), lr=1.0e-2)\n#optimizer = torch.optim.SGD(mnist_net.parameters(), lr=1.0e-2, momentum=0.9)\n\nlearn_history = learn_MNISTNet(mnist_net, loss, optimizer, epoch_num=40, batch_size=1000, device=device, verbose=False)\n\nprint('Accuracy: test = {:.3f}, train = {:.3f}; Loss: test = {:.3f}, train = {:.3f};'.format(learn_history['accuracy_test'][-5].mean(), \n                                                       learn_history['accuracy_train'][-5].mean(),\n                                                       learn_history['loss_test'][-5].mean(), \n                                                       learn_history['loss_train'][-5].mean()))","metadata":{"id":"w5doBdTB1PMq","outputId":"c4413d4a-9a3c-4a06-b8ab-8849059fab37","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(learn_history['accuracy_test']) #blue\nplt.plot(learn_history['accuracy_train']) #orange","metadata":{"id":"RANZGNih731V","outputId":"7b72943a-6736-499f-aa46-aea4a0f60595"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(learn_history['loss_test'])  #blue\nplt.plot(learn_history['loss_train']) #orange","metadata":{"id":"N-_uoKbr731W","outputId":"5512634d-9a9b-43e5-936e-d822d87183de"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Постройте на одном графике loss для train и validation. \n# - построил\n\n\n# Правда ли, что loss на train и validation падает одинаково быстро и выходит на одинаковое значение, или же у нас есть переобучение? \n# - нет, переобучения не замечено, падает одинаково\n\n\n# Ведет ли увеличение количества эпох (40 эпох -> 200 эпох) к улучшению метрик на валидации?\n# - да, ведет, до 100 однозначно видно улучшение метрик, со 100 до 200 рост значительно замедляется, но все же еще есть (сотые)\n\n# Замерьте время вычисления 100 эпох на CPU и на GPU. Какое ускорение вы наблюдаете?\n# - learn_MNISTNet(mnist_net, loss, optimizer, epoch_num=10, batch_size=100, device='cuda:0', verbose=True) - 1 loop, best of 5: 12.7 s per loop\n# - learn_MNISTNet(mnist_net, loss, optimizer, epoch_num=10, batch_size=100, device='cpu', verbose=True) - 1 loop, best of 5: 20.5 s per loop\n# - learn_MNISTNet(mnist_net, loss, optimizer, epoch_num=10, batch_size=1000, device='cuda:0', verbose=True) - 1 loop, best of 5: 2.1 s per loop\n# - learn_MNISTNet(mnist_net, loss, optimizer, epoch_num=10, batch_size=1000, device='cpu', verbose=True) - 1 loop, best of 5: 11.3 s per loop\n# Вывод: очень существенно сказывается на выигрыше по скорости размер батча, при батче 100 выигрыш GPU в 2 раза, при батче 1000 выигрыш GPU в 5 раз\n#        еще более сущетсвенная (на порядки) разница, наблюдается разница при увеличении кол-ва нейронов скрытых слоев, например до 1000\n\n\n# Замедляет ли torch.backends.cudnn.deterministic = True обучение на практике? Если да, то насколько?\n# - deterministic=True (neurons = 1000, batch = 1000, epoch = 10): 1 loop, best of 5: 2.58 s per loop\n# - deterministic=False (neurons = 1000, batch = 1000, epoch = 10): 1 loop, best of 5: 2.59 s per loop\n# Вывод, разницы не замечено\n\n# Попробуйте разные методы градиентного спуска, которые были в лекции. Как выбор градиентного спуска влияет на accuracy? Для уверенности лучше \n# проводить один эксперимент 3-5 раз на разных random seed: так вы поймете, действительно ли сказывается влияние метода или дело в случайности.\n# neurons = 100, batch = 1000, epoch=100, Adam(lr = 0.001) ----> Accuracy: test = 0.966, train = 0.978; Loss: test = 0.112, train = 0.072;\n# neurons = 100, batch = 1000, epoch=100, SGD(lr = 0.001) ----> Accuracy: test = 0.902, train = 0.902; Loss: test = 0.484, train = 0.484;\n# neurons = 100, batch = 1000, epoch=100, SGD(lr = 0.01) ----> Accuracy: test = 0.936, train = 0.957; Loss: test = 0.219, train = 0.163;\n# neurons = 100, batch = 1000, epoch=100, SGD(lr = 0.01, momentum=0.9) ---> Accuracy: test = 0.965, train = 0.985; Loss: test = 0.111, train = 0.061;\n# neurons = 100, batch = 1000, epoch=100, SGD(lr = 0.01, momentum=0.1) ---> Accuracy: test = 0.938, train = 0.959; Loss: test = 0.214, train = 0.156;","metadata":{"id":"7xjeStoL73OF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Пробую определить проблему из видео про нейронные сети, когда на примере рандомного изображения, показывается, что нейронная сеть работает не совсем так, как мы думали (в ролике) и она не строит никаких предположений по наличию колец, элементов и т.п.**","metadata":{}},{"cell_type":"code","source":"import torch\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.rcParams['figure.figsize'] = (15.0, 5.0)\n\nrs=42\nrandom.seed(rs)\nnp.random.seed(rs)\ntorch.manual_seed(rs)\ntorch.cuda.manual_seed(rs)\ntorch.backends.cudnn.deterministic = True","metadata":{"id":"ELdpzZNx10Qd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.datasets\nMNIST_train = torchvision.datasets.MNIST('./', download=True, train=True)\nMNIST_test = torchvision.datasets.MNIST('./', download=True, train=False)","metadata":{"id":"dTxq1vz010Qd","outputId":"bde8a042-84bc-45cb-e574-95f999a09c9d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MNISTNet(torch.nn.Module):\n\n    def __init__(self, n_hidden_neurons):\n        super(MNISTNet, self).__init__()\n        self.fc1 = torch.nn.Linear(28 * 28, n_hidden_neurons)\n        self.ac1 = torch.nn.Sigmoid()\n        self.fc2 = torch.nn.Linear(n_hidden_neurons, 10)\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.ac1(x)\n        x = self.fc2(x)\n        return x\n\n#Create function\ndef learn_MNISTNet(mnist_net, loss, optimizer, epoch_num=100, batch_size=100, device='cpu', verbose=True):\n    learn_history = {}\n    learn_history['accuracy_test'] = []\n    learn_history['accuracy_train'] = []\n    learn_history['loss_test'] = []\n    learn_history['loss_train'] = []\n\n    X_train = X_train.float()\n    X_test = X_test.float()\n    X_train = X_train.reshape([-1, 28 * 28])\n    X_test = X_test.reshape([-1, 28 * 28])\n\n    X_test = X_test.to(device)\n    y_test = y_test.to(device)\n\n    for epoch in range(epoch_num):\n        order = np.random.permutation(len(X_train))\n\n        train_accuracy_epoch = []\n        train_loss_epoch = []\n        \n        for start_index in range(0, len(X_train), batch_size):\n            optimizer.zero_grad()\n            \n            batch_indexes = order[start_index:start_index+batch_size]\n            \n            X_batch = X_train[batch_indexes].to(device)\n            y_batch = y_train[batch_indexes].to(device)\n            \n            preds = mnist_net.forward(X_batch)\n            \n            loss_value = loss(preds, y_batch)\n            train_loss_epoch.append(loss_value)\n\n            loss_value.backward()\n            \n            train_accuracy_epoch.append((preds.argmax(dim=1) == y_batch).float().mean())\n\n            optimizer.step()\n\n        test_preds = mnist_net.forward(X_test)\n        learn_history['loss_test'].append(loss(test_preds, y_test))\n        learn_history['loss_train'].append(torch.stack(train_loss_epoch).float().mean())\n\n        accuracy_test = (test_preds.argmax(dim=1) == y_test).float().mean()\n        accuracy_train = torch.stack(train_accuracy_epoch).float().mean()\n        learn_history['accuracy_test'].append(accuracy_test)\n        learn_history['accuracy_train'].append(accuracy_train)\n        if verbose:\n            print('epoch = {}, accuracy_test = {:.3f}, accuracy_train = {:.3f}'.format(epoch, accuracy_test, accuracy_train))\n\n    return learn_history","metadata":{"id":"WZneYGGJNyBM","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = MNIST_train.data\ny_train = MNIST_train.targets\nX_test = MNIST_test.data\ny_test = MNIST_test.targets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train[0, :, :]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(X_train[0, :, :], cmap='gray', vmin=0, vmax=255)\nplt.show()\nprint(y_train[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.randint(0, 2, (20, 20))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(torch.randint(0, 256, (1, 28, 28))[0, :, :], cmap='gray', vmin=0, vmax=255)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%%timeit\ndevice = 'cuda:0'\n\nmnist_net = MNISTNet(32)\nmnist_net = mnist_net.to(device)\n\nloss = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(mnist_net.parameters(), lr=1.0e-3)\n#optimizer = torch.optim.SGD(mnist_net.parameters(), lr=1.0e-2)\n#optimizer = torch.optim.SGD(mnist_net.parameters(), lr=1.0e-2, momentum=0.9)\n\nlearn_history = learn_MNISTNet(mnist_net, loss, optimizer, epoch_num=100, batch_size=1000, device=device, verbose=False)\n\nprint('Accuracy: test = {:.3f}, train = {:.3f}; Loss: test = {:.3f}, train = {:.3f};'.format(learn_history['accuracy_test'][-5].mean(), \n                                                       learn_history['accuracy_train'][-5].mean(),\n                                                       learn_history['loss_test'][-5].mean(), \n                                                       learn_history['loss_train'][-5].mean()))","metadata":{"id":"w5doBdTB1PMq","outputId":"c4413d4a-9a3c-4a06-b8ab-8849059fab37","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = mnist_net.forward(X_train[0, :, :].float().reshape([-1, 28 * 28]).to(device))\nprint(preds)\nprint(preds.argmax(dim=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_img = torch.randint(0, 256, (1, 28, 28))\nplt.imshow(random_img[0, :, :], cmap='gray', vmin=0, vmax=255)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = mnist_net.forward(random_img[0, :, :].float().reshape([-1, 28 * 28]).to(device))\nprint(preds)\nprint(preds.argmax(dim=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"white_img = torch.randint(255, 256, (1, 28, 28))\nplt.imshow(white_img[0, :, :], cmap='gray', vmin=0, vmax=255)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = mnist_net.forward(white_img[0, :, :].float().reshape([-1, 28 * 28]).to(device))\nprint(preds)\nprint(preds.argmax(dim=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"black_img = torch.randint(0, 1, (1, 28, 28))\nplt.imshow(black_img[0, :, :], cmap='gray', vmin=0, vmax=255)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = mnist_net.forward(black_img[0, :, :].float().reshape([-1, 28 * 28]).to(device))\nprint(preds)\nprint(preds.argmax(dim=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_low_img = torch.randint(220, 256, (1, 28, 28))\nplt.imshow(random_low_img[0, :, :], cmap='gray', vmin=0, vmax=255)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = mnist_net.forward(random_low_img[0, :, :].float().reshape([-1, 28 * 28]).to(device))\nprint(preds)\nprint(preds.argmax(dim=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(learn_history['accuracy_test']) #blue\nplt.plot(learn_history['accuracy_train']) #orange","metadata":{"id":"RANZGNih731V","outputId":"7b72943a-6736-499f-aa46-aea4a0f60595","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Модифицируем нейронную сеть и тестовые/трейновые датасеты, добавляем еще один класс 10, к которому относим все картинки без цифр (рандомный шум от 0 до 255, рандомный шум от 220 до 255, белый фон, черный фон)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.rcParams['figure.figsize'] = (15.0, 5.0)\n\nrs=42\nrandom.seed(rs)\nnp.random.seed(rs)\ntorch.manual_seed(rs)\ntorch.cuda.manual_seed(rs)\ntorch.backends.cudnn.deterministic = True","metadata":{"id":"ELdpzZNx10Qd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.datasets\nMNIST_train = torchvision.datasets.MNIST('./', download=True, train=True)\nMNIST_test = torchvision.datasets.MNIST('./', download=True, train=False)","metadata":{"id":"dTxq1vz010Qd","outputId":"bde8a042-84bc-45cb-e574-95f999a09c9d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = MNIST_train.data\ny_train = MNIST_train.targets\nX_test = MNIST_test.data\ny_test = MNIST_test.targets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape[0]/10) # на это количество добавляем картинок с 10 категорией (отсутсвие цифр)\nprint(X_test.shape[0]/10) # на это количество добавляем картинок с 10 категорией (отсутсвие цифр)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_no_numbers = []\nX_test_no_numbers = []\nX_train_no_numbers.append(torch.randint(0, 1, (300, 28, 28))) #6000/10/2 = 300, черных картинок\nX_test_no_numbers.append(torch.randint(0, 1, (50, 28, 28))) #1000/10/2 = 50, черных картинок","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_no_numbers.append(torch.randint(255, 256, (300, 28, 28))) # + 6000/10/2 = 300, белых картинок\nX_test_no_numbers.append(torch.randint(255, 256, (50, 28, 28))) # + 1000/10/2 = 50, белых картинок","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# + 6000/10*9 = 5400 с рандомным диапазоном шума\ntemp = []\nfor _ in range(5400):\n    low_rand = np.random.randint(0,256)\n    high_rand = np.random.randint(low_rand+1,256+1)\n    temp.append(torch.randint(low_rand, high_rand, (1, 28, 28)))\nX_train_no_numbers.append(torch.cat(temp))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# + 100/10*9 = 900 с рандомным диапазоном шума\ntemp = []\nfor _ in range(900):\n    low_rand = np.random.randint(0,256)\n    high_rand = np.random.randint(low_rand+1,256+1)\n    temp.append(torch.randint(low_rand, high_rand, (1, 28, 28)))\nX_test_no_numbers.append(torch.cat(temp))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(X_train_no_numbers[2][31, :, :], cmap='gray', vmin=0, vmax=255)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Добавляем в наши обучающие и тестовые выборки данные по классу 10 (без цифр)\nX_train = torch.cat((X_train, torch.cat(X_train_no_numbers)))\ny_train = torch.cat((y_train, torch.full((6000,), 10)))\nX_test = torch.cat((X_test, torch.cat(X_test_no_numbers)))\ny_test = torch.cat((y_test, torch.full((1000,), 10)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, y_train.shape, X_test.shape, y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MNISTNet(torch.nn.Module):\n\n    def __init__(self, n_hidden_neurons):\n        super(MNISTNet, self).__init__()\n        self.fc1 = torch.nn.Linear(28 * 28, n_hidden_neurons)\n        self.ac1 = torch.nn.Sigmoid()\n        self.fc2 = torch.nn.Linear(n_hidden_neurons, 11)\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.ac1(x)\n        x = self.fc2(x)\n        return x\n\n#Create function\ndef learn_MNISTNet(mnist_net, X_train, X_test, y_train, y_test, loss, optimizer, epoch_num=100, batch_size=100, device='cpu', verbose=True):\n    learn_history = {}\n    learn_history['accuracy_test'] = []\n    learn_history['accuracy_train'] = []\n    learn_history['loss_test'] = []\n    learn_history['loss_train'] = []\n\n    X_train = X_train.float()\n    X_test = X_test.float()\n    X_train = X_train.reshape([-1, 28 * 28])\n    X_test = X_test.reshape([-1, 28 * 28])\n\n    X_test = X_test.to(device)\n    y_test = y_test.to(device)\n\n    for epoch in range(epoch_num):\n        order = np.random.permutation(len(X_train))\n\n        train_accuracy_epoch = []\n        train_loss_epoch = []\n        \n        for start_index in range(0, len(X_train), batch_size):\n            optimizer.zero_grad()\n            \n            batch_indexes = order[start_index:start_index+batch_size]\n            \n            X_batch = X_train[batch_indexes].to(device)\n            y_batch = y_train[batch_indexes].to(device)\n            \n            preds = mnist_net.forward(X_batch)\n            \n            loss_value = loss(preds, y_batch)\n            train_loss_epoch.append(loss_value)\n\n            loss_value.backward()\n            \n            train_accuracy_epoch.append((preds.argmax(dim=1) == y_batch).float().mean())\n\n            optimizer.step()\n\n        test_preds = mnist_net.forward(X_test)\n        learn_history['loss_test'].append(loss(test_preds, y_test))\n        learn_history['loss_train'].append(torch.stack(train_loss_epoch).float().mean())\n\n        accuracy_test = (test_preds.argmax(dim=1) == y_test).float().mean()\n        accuracy_train = torch.stack(train_accuracy_epoch).float().mean()\n        learn_history['accuracy_test'].append(accuracy_test)\n        learn_history['accuracy_train'].append(accuracy_train)\n        if verbose:\n            print('epoch = {}, accuracy_test = {:.3f}, accuracy_train = {:.3f}'.format(epoch, accuracy_test, accuracy_train))\n\n    return learn_history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%%timeit\n#device = 'cuda:0'\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\nmnist_net = MNISTNet(100)\nmnist_net = mnist_net.to(device)\n\nloss = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(mnist_net.parameters(), lr=1.0e-3)\n#optimizer = torch.optim.SGD(mnist_net.parameters(), lr=1.0e-2)\n#optimizer = torch.optim.SGD(mnist_net.parameters(), lr=1.0e-2, momentum=0.9)\n\nlearn_history = learn_MNISTNet(mnist_net, X_train, X_test, y_train, y_test, loss, optimizer, epoch_num=100, batch_size=1000, device=device, verbose=False)\n\nprint('Accuracy: test = {:.3f}, train = {:.3f}; Loss: test = {:.3f}, train = {:.3f};'.format(learn_history['accuracy_test'][-5].mean(), \n                                                       learn_history['accuracy_train'][-5].mean(),\n                                                       learn_history['loss_test'][-5].mean(), \n                                                       learn_history['loss_train'][-5].mean()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_img = torch.randint(200, 256, (1, 28, 28))\nplt.imshow(random_img[0, :, :], cmap='gray', vmin=0, vmax=255)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = mnist_net.forward(random_img[0, :, :].float().reshape([-1, 28 * 28]).to(device))\nprint(preds)\nprint(preds.argmax(dim=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#смотрим на чем сеть ошибается.\ntest_preds = mnist_net.forward(X_test.float().reshape([-1, 28 * 28]).to(device))\nX_errors = X_test[test_preds.argmax(dim=1) != y_test.to(device)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.imshow(X_errors[0, :, :], cmap='gray', vmin=0, vmax=255)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4.4.6 Семинар: Классификация рукописных чисел полносвязанной сетью**","metadata":{"id":"kL_NNsIvSu4_"}},{"cell_type":"markdown","source":"Как было сказано в предыдущем уроке, полносвязный слой может быть представлен как матричное умножение матрицы входов (X) и матрицы весов нейронов слоя (W), плюс вектор bias'ов слоя (b). \n\nВ документации к классу torch.nn.Linear (полносвязному слою) написано следующее: Applies a linear transformation to the incoming data: y=xAT+by = xA^T + by=xAT+b . А здесь – это то, как PyTorch хранит веса слоя. Но чтобы эта матрица совпала с W из предыдущего урока, нужно её сперва транспонировать.\n\nДавайте реализуем функциональность torch.nn.Linear и сверим с оригиналом!\n\nПусть у нас будет 1 объект x на входе с двумя компонентами. Его мы передадим в полносвязный слой с 3-мя нейронами и получим, соотсветственно, 3 выхода. После напишем эту же функциональность с помощью матричного умножения. ","metadata":{"id":"hpMONSJNS77x"}},{"cell_type":"code","source":"import torch\n\n# Сперва создадим тензор x:\nx = torch.tensor([[10., 20.]])\n\n# Оригинальный полносвязный слой с 2-мя входами и 3-мя нейронами (выходами):\nfc = torch.nn.Linear(2, 3)\n\n# Веса fc-слоя хранятся в fc.weight, а bias'ы соответственно в fc.bias\n# fc.weight и fc.bias по умолчанию инициализируются случайными числами\n\n# Давайте проставим свои значения в веса и bias'ы:\nw = torch.tensor([[11., 12.], [21., 22.], [31., 32]])\nfc.weight.data = w\nfc.weight.data","metadata":{"id":"fSTBSEdeS650","outputId":"8d75195a-e20a-488c-8bcb-e83cbfeb7b72","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fc.weight.data.transpose(0,1)","metadata":{"id":"EKDP3Bf5VHUJ","outputId":"3886e775-79f0-4ea1-f6fa-845c3b3ec177","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b = torch.tensor([[31., 32., 33.]])\nfc.bias.data = b\nfc.bias.data","metadata":{"id":"V6ttweW1S9qk","outputId":"5d4def41-6e8d-48dd-fec2-787caa51e100","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Получим выход fc-слоя:\nfc_out = fc(x)\nfc_out","metadata":{"id":"KkD3o2v6UWNB","outputId":"5173adb3-34f9-4418-f6e1-6ac594839a58","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Попробуем теперь получить аналогичные выходы с помощью матричного перемножения:\nfc_out_alternative =  x @ w.t() + b\nfc_out_alternative\n\n# Проверка осуществляется автоматически вызовом функции\n# print(fc_out == fc_out_alternative)\n# (раскомментируйте, если решаете задачу локально)","metadata":{"id":"b88u0etbUaSc","outputId":"fd852f20-1f68-4767-82d5-e66a00799ec3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В предыдущем шаге мы написали функцию, эмулирующую fc-слой. Проверим, что по ней правильно считается градиент. \n\nФункцию backward() в PyTorch можно посчитать только от скалярной функции (выход из такой функции – одно число). Это логично, так как loss-функция выдает всегда одно число. Но fc-слой, который мы проэмулировали, имел 3 выхода. Предлагаем их просуммировать, чтобы получить в итоге скалярную функцию. Заметим, впрочем, что можно было бы выбрать любую агрегирующую операцию, например умножение.\n\nДополните код так, чтобы градиент по весам и смещениям (bias) совпадал с аналогичным градиентом в вашей фунции.\n\nЧем обусловлен полученный градиент? Изменится ли он, если мы подадим другие входы или другую инициализацию весов?","metadata":{"id":"DaiqrxVHmCHk"}},{"cell_type":"code","source":"import torch\n\n# Сперва создадим тензор x:\nx = torch.tensor([[10., 20.]])\n\n# Оригинальный полносвязный слой с 2-мя входами и 3-мя нейронами (выходами):\nfc = torch.nn.Linear(2, 3)\n\n# Веса fc-слоя хранятся в fc.weight, а bias'ы соответственно в fc.bias\n# fc.weight и fc.bias по умолчанию инициализируются случайными числами\n\n# Давайте проставим свои значения в веса и bias'ы:\nw = torch.tensor([[11., 12.], [21., 22.], [31., 32]])\nfc.weight.data = w\n\nb = torch.tensor([[31., 32., 33.]])\nfc.bias.data = b\n\n# Получим выход fc-слоя:\nfc_out = fc(x)\n# Просуммируем выход fc-слоя, чтобы получить скаляр:\nfc_out_summed = fc_out.sum()\n\n# Посчитаем градиенты формулы fc_out_summed:\nfc_out_summed.backward()\nweight_grad = fc.weight.grad\nbias_grad = fc.bias.grad\n\n# Ok, теперь воспроизведем вычисления выше но без fc-слоя:\n# Проставим, что у \"w\" и \"b\" нужно вычислять градиенты (для fc-слоя это произошло автоматически):\nw.requires_grad_(True)\nb.requires_grad_(True)\n\n# Получим выход нашей формулы:\nour_formula = (x @ w.t() + b).sum() # SUM{x * w^T + b}\n\n# Сделайте backward для нашей формулы:\nour_formula.backward()\n\n# Проверка осуществляется автоматически, вызовом функций:\nprint('fc_weight_grad:', weight_grad)\nprint('our_weight_grad:', w.grad)\nprint('fc_bias_grad:', bias_grad)\nprint('out_bias_grad:', b.grad)\n# (раскомментируйте, если работаете над задачей локально)","metadata":{"id":"_ln7NUnDVeAZ","outputId":"14e794b4-af7f-4de4-a817-3f357e0d635a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Неделя 5. Сверточные нейронные сети","metadata":{"id":"5fkeBgKmoc18"}},{"cell_type":"markdown","source":"5.1 Свёртка, каскад свёрток","metadata":{"id":"jLM9iSqQmg-p"}},{"cell_type":"markdown","source":"Пусть матрица признаков равна [[4, 2, -1],[-6, 0, 5],[3, 2, 2]], а ядро свертки -- [[0, 1, 2],[1, -1, 0],[1, 0, -2]]\n\nКаков будет результат применения свертки со stride=2, padding=1?\n\nЗапишите значения матрицы в одну строчку в порядке сверху вниз, слева направо, разделяя числа одной строки пробелами, а сами строки -- запятыми (например, запись \"1 2 3, -4 -5 -6\" соответствует матрице [[1, 2, 3], [-4, -5, -6]], осторожно, скобки писать не нужно).","metadata":{}},{"cell_type":"code","source":"import torch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"source = torch.tensor([[4, 2, -1],[-6, 0, 5],[3, 2, 2]])\nkernel = torch.tensor([[0, 1, 2],[1, -1, 0],[1, 0, -2]])\nsource = torch.nn.functional.pad(input=source, pad=(1, 1, 1, 1), mode='constant', value=0) #add padding","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nconv = torch.nn.Conv2d(1,1,kernel_size=3, padding=1, stride=2, bias=False)\nX = torch.FloatTensor([[[\n    [4, 2, -1],\n    [-6, 0, 5],\n    [3, 2, 2]]]])\nconv.weight.data = torch.FloatTensor([[[\n    [0, 1, 2],\n    [1, -1, 0],\n    [1, 0, -2]]]])\nres = conv(X).data[0,0]\nprint(res)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nx = torch.tensor([[4, 2, -1],[-6, 0, 5],[3, 2, 2]], dtype=torch.float64).reshape(1,1,3,3)\nk = torch.tensor([[0, 1, 2],[1, -1, 0],[1, 0, -2]], dtype=torch.float64).reshape(1,1,3,3)\nconv = torch.nn.functional.conv2d(x, k, stride=2, padding=1).numpy()\nprint(*conv.reshape(-1).astype(int))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Пусть размер матрицы признаков = 4(высота)х5(ширина)x2(кол-во каналов), размеры ядра свертки = 3x3, stride=2, padding=1, количество выходных фильтров = 8.\n\nСколько элементов будет в матрице, полученной в результате применения свёртки? В качестве ответа введите одно число.","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\n\nx = torch.ones(1,2,4,5)\nconv = nn.Conv2d(2, 8, kernel_size=3, stride=2, padding=1, bias=False)\nres = conv(x)\nres.view(-1).shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5.2.1 Семинар: Реализация сверточного слоя**","metadata":{}},{"cell_type":"raw","source":"На этом уроке мы с вами реализуем прямой проход сверточного слоя, обратный проход и расчет производных мы трогать не будем.\n\nВспомним как работает сверточный слой:\n\n    на вход подается массив изображений, еще он называется батчем\n\n    к каждому изображению по границам добавляются нули\n\n    по каждому изображению \"скользит\" каждый из фильтров сверточного слоя\n\nДавайте начнем с разминки - реализуем функцию, добавляющую padding.\n\nПусть у нас есть батч input_images из двух изображений с тремя каналами (RGB). Размер изображений пусть будет 3*3. Вспомним, что вход сверточного слоя имеет следующую размерность:\n\n    размер батча\n\n    число каналов\n\n    высота\n\n    ширина\n\nВ рассматриваемом случае размерность входа (2, 3, 3, 3).\n\nЕсли мы добавим вокруг каждого изображения отступ из одного нуля, то размер каждого изображений станет 3+2*1 = 5 пикселей в ширину и 5 в высоту соответственно (добавляем по одному нулю с каждой стороны изображения).\n\nНапишите любую работающую реализацию.","metadata":{}},{"cell_type":"code","source":"import torch\n\n# Создаем входной массив из двух изображений RGB 3*3\ninput_images = torch.tensor(\n      [[[[0,  1,  2],\n         [3,  4,  5],\n         [6,  7,  8]],\n\n        [[9, 10, 11],\n         [12, 13, 14],\n         [15, 16, 17]],\n\n        [[18, 19, 20],\n         [21, 22, 23],\n         [24, 25, 26]]],\n\n\n       [[[27, 28, 29],\n         [30, 31, 32],\n         [33, 34, 35]],\n\n        [[36, 37, 38],\n         [39, 40, 41],\n         [42, 43, 44]],\n\n        [[45, 46, 47],\n         [48, 49, 50],\n         [51, 52, 53]]]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Мое решение\ndef add_padding_2dim(x):\n    z = torch.zeros(1, x.shape[1])\n    y = torch.cat([z, x.float(), z])\n    z = torch.zeros(y.shape[0], 1)\n    return torch.cat([z, y, z], dim=1)\n\ndef get_padding2d(input_images):\n    lst = []\n    for i in range(input_images.shape[0]):\n        for j in range(input_images.shape[1]):\n            lst.append(add_padding_2dim(input_images[i,j]))    \n    padded_images = torch.cat(lst).reshape(input_images.shape[0], input_images.shape[1], input_images.shape[2]+2, input_images.shape[3]+2)\n    return padded_images","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct_padded_images = torch.tensor(\n       [[[[0.,  0.,  0.,  0.,  0.],\n          [0.,  0.,  1.,  2.,  0.],\n          [0.,  3.,  4.,  5.,  0.],\n          [0.,  6.,  7.,  8.,  0.],\n          [0.,  0.,  0.,  0.,  0.]],\n\n         [[0.,  0.,  0.,  0.,  0.],\n          [0.,  9., 10., 11.,  0.],\n          [0., 12., 13., 14.,  0.],\n          [0., 15., 16., 17.,  0.],\n          [0.,  0.,  0.,  0.,  0.]],\n\n         [[0.,  0.,  0.,  0.,  0.],\n          [0., 18., 19., 20.,  0.],\n          [0., 21., 22., 23.,  0.],\n          [0., 24., 25., 26.,  0.],\n          [0.,  0.,  0.,  0.,  0.]]],\n\n\n        [[[0.,  0.,  0.,  0.,  0.],\n          [0., 27., 28., 29.,  0.],\n          [0., 30., 31., 32.,  0.],\n          [0., 33., 34., 35.,  0.],\n          [0.,  0.,  0.,  0.,  0.]],\n\n         [[0.,  0.,  0.,  0.,  0.],\n          [0., 36., 37., 38.,  0.],\n          [0., 39., 40., 41.,  0.],\n          [0., 42., 43., 44.,  0.],\n          [0.,  0.,  0.,  0.,  0.]],\n\n         [[0.,  0.,  0.,  0.,  0.],\n          [0., 45., 46., 47.,  0.],\n          [0., 48., 49., 50.,  0.],\n          [0., 51., 52., 53.,  0.],\n          [0.,  0.,  0.,  0.,  0.]]]])\n\n# Проверка происходит автоматически вызовом следующего кода\n# (раскомментируйте для самостоятельной проверки,\n#  в коде для сдачи задания должно быть закомментировано):\nprint(torch.allclose(get_padding2d(input_images), correct_padded_images))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.zeros(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_padding2d(input_images):\n    padded_images = torch.zeros([input_images.shape[0], \n                                 input_images.shape[1], \n                                 input_images.shape[2]+2, \n                                 input_images.shape[3]+2])\n    padded_images[:,:,1:-1,1:-1] = input_images\n    return padded_images","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Решение с комментов!! Как раз то что я искал, т.е. сложение со сдвигами, но не нашел\ndef get_padding2d(input_images):\n    padded_images = torch.zeros([input_images.shape[0], \n                                 input_images.shape[1], \n                                 input_images.shape[2]+2, \n                                 input_images.shape[3]+2])\n    padded_images[:,:,1:-1,1:-1] = input_images\n    #или можно через +=\n    #padded_images[:,:,1:-1,1:-1] += input_images\n    return padded_images","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_padding2d(input_images):\n    padded_images = torch.nn.functional.pad(input_images, pad=(1,1,1,1)) \n    return padded_images.float()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5.2.2 Семинар: Реализация сверточного слоя**","metadata":{}},{"cell_type":"raw","source":"На этом шаге детально рассмотрим из чего состоит сверточный слой.\n\nСверточный слой это массив фильтров.\n\nКаждый фильтр имеет следующую размерность:\n\n    число слоев во входном изображении (для RGB это 3)\n\n    высота фильтра\n\n    ширина фильтра\n\nВ ядре (кернеле) все фильтры имеют одинаковые размерность, поэтому ширину и высоту фильтров называют шириной и высотой ядра. Чаще всего ширина ядра равна высоте ядра, в таком случае их называют размером ядра (kernel_size).\n\n \n\nТакже слой имеет такие параметры:\n\n    padding - на какое количество пикселей увеличивать входное изображение с каждой стороны.\n\n    stride - на сколько пикселей смещается фильтр при вычислении свертки\n\n \n\nПопробуйте самостоятельно вывести формулу размерности выхода сверточного слоя, зная параметры входа и ядра. \n\nПравильность формулы проверьте, сравнив ее с формулой из документации.\n\n \n\nЧтобы убедиться в правильности вашей формулы, напишите функцию, принимающую на вход:\n\n    входную размерность (число изображений в батче*число слоев в одном изображении*высота изображения*ширина изображения)\n\n    количество фильтров\n\n    размер фильтров (считаем, что высота совпадает с шириной)\n\n    padding\n\n    stride\n\nФункция должна возвращать размерность выхода.","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n\ndef calc_out_shape(input_matrix_shape, out_channels, kernel_size, stride, padding):\n    out_shape = [input_matrix_shape[0],\n                 out_channels,\n                 (input_matrix_shape[2] + padding * 2 - kernel_size) // stride + 1,\n                 (input_matrix_shape[3] + padding * 2 - kernel_size) // stride + 1]\n                 \n\n    return out_shape\n\nprint(np.array_equal(\n    calc_out_shape(input_matrix_shape=[2, 3, 10, 10],\n                   out_channels=10,\n                   kernel_size=3,\n                   stride=1,\n                   padding=0),\n    [2, 10, 8, 8]))\n\n# ... и ещё несколько подобных кейсов","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5.2.3 Семинар: Реализация сверточного слоя**","metadata":{}},{"cell_type":"raw","source":"Для удобства все наши реализации оформим в виде классов. Интерфейс классов сделаем одинаковым и максимально похожим на интерфейс стандартной реализации.\n\nТестировать наши реализации слоя будем одной и той же функцией.\n\n*Паддить вход вы уже умеете - будем считать, что padding = 0.\n\n \n\nВ этом шаге вам предлагается изучить код для проверки.","metadata":{}},{"cell_type":"code","source":"import torch\nfrom abc import ABC, abstractmethod\n\n\n# абстрактный класс для сверточного слоя\nclass ABCConv2d(ABC):\n    def __init__(self, in_channels, out_channels, kernel_size, stride):\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n\n    def set_kernel(self, kernel):\n        self.kernel = kernel\n\n    @abstractmethod\n    def __call__(self, input_tensor):\n        pass\n\n\n# класс-обертка над torch.nn.Conv2d для унификации интерфейса\nclass Conv2d(ABCConv2d):\n    def __init__(self, in_channels, out_channels, kernel_size, stride):\n        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size,\n                                      stride, padding=0, bias=False)\n\n    def set_kernel(self, kernel):\n        self.conv2d.weight.data = kernel\n\n    def __call__(self, input_tensor):\n        return self.conv2d(input_tensor)\n\n\n# функция, создающая объект класса cls и возвращающая свертку от input_matrix\ndef create_and_call_conv2d_layer(conv2d_layer_class, stride, kernel, input_matrix):\n    out_channels = kernel.shape[0]\n    in_channels = kernel.shape[1]\n    kernel_size = kernel.shape[2]\n\n    layer = conv2d_layer_class(in_channels, out_channels, kernel_size, stride)\n    layer.set_kernel(kernel)\n\n    return layer(input_matrix)\n\n\n# Функция, тестирующая класс conv2d_cls.\n# Возвращает True, если свертка совпадает со сверткой с помощью torch.nn.Conv2d.\ndef test_conv2d_layer(conv2d_layer_class, batch_size=2,\n                      input_height=4, input_width=4, stride=2):\n    kernel = torch.tensor(\n                      [[[[0., 1, 0],\n                         [1,  2, 1],\n                         [0,  1, 0]],\n\n                        [[1, 2, 1],\n                         [0, 3, 3],\n                         [0, 1, 10]],\n\n                        [[10, 11, 12],\n                         [13, 14, 15],\n                         [16, 17, 18]]]])\n\n    in_channels = kernel.shape[1]\n\n    input_tensor = torch.arange(0, batch_size * in_channels *\n                                input_height * input_width,\n                                out=torch.FloatTensor()) \\\n        .reshape(batch_size, in_channels, input_height, input_width)\n\n    custom_conv2d_out = create_and_call_conv2d_layer(conv2d_layer_class, stride, kernel, input_tensor)\n    conv2d_out = create_and_call_conv2d_layer(Conv2d, stride, kernel, input_tensor)\n\n    return torch.allclose(custom_conv2d_out, conv2d_out) \\\n              and (custom_conv2d_out.shape == conv2d_out.shape)\n\nprint(test_conv2d_layer(Conv2d))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5.2.4 Семинар: Реализация сверточного слоя**","metadata":{}},{"cell_type":"raw","source":"Переиспользуем код с предыдущего шага для проверки своей реализации сверточного слоя.\n\nРассмотрим свертку батча из одного однослойного изображения 3*3 с ядром из одного фильтра 2*2, stride = 1, то есть, на выходе должна получиться одна матрица 2*2. Строго записанная размерность выхода равна (1 - изображений в батче, 1 - количество фильтров в ядре, 2 - высота матрицы выхода, 2 - ширина матрицы выхода).\n\nПусть W - веса ядра, X - вход, Y - выход.\n\nВычислить выход можно в цикле:\n \n\nНа каждой итерации цикла фильтр умножается попиксельно на часть изображения, а потом 4 получившиеся числа складываются - получается один пиксель выхода.\n\nТребуемое количество итераций для данного случая - 4, так как может быть 2 положения ядра и 2 по вертикали, общее число итераций - произведение количеств положений, то есть в данном случае 2*2 = 4.\n\nДавайте перейдем от простого случая к общему.\n\n    Если бы изображение было многослойным, например трехслойное - RGB, значит, фильтры в ядре тоже должны быть трехслойные. Каждый слой фильтра попиксельно умножается на соответствующий слой исходного изображения. То есть в данном случае после умножения получилось бы 4*3 = 12 произведений, результаты которых складываются, и получается значение выходного пикселя.\n\n    Если бы фильтров в ядре было больше одного, то добавился бы внешний цикл по фильтрам, внутри которого мы считаем свертку для каждого фильтра.\n\n    Если бы во входном батче было более 1 изображения, то добавился бы еще один внешний цикл по изображениям в батче.\n\nНапоминание: во всех шагах этого урока мы считаем bias в сверточных слоях нулевым.\n\nНа этом шаге требуется реализовать сверточный слой через циклы.\n\nОбратите внимание, что в коде рассматривается общий случай - батч на входе не обязательно состоит из одного изображения, в ядре несколько слоев.","metadata":{}},{"cell_type":"code","source":"import torch\nfrom abc import ABC, abstractmethod\n\n\ndef calc_out_shape(input_matrix_shape, out_channels, kernel_size, stride, padding):\n    batch_size, channels_count, input_height, input_width = input_matrix_shape\n    output_height = (input_height + 2 * padding - (kernel_size - 1) - 1) // stride + 1\n    output_width = (input_width + 2 * padding - (kernel_size - 1) - 1) // stride + 1\n\n    return batch_size, out_channels, output_height, output_width\n\n\nclass ABCConv2d(ABC):\n    def __init__(self, in_channels, out_channels, kernel_size, stride):\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n\n    def set_kernel(self, kernel):\n        self.kernel = kernel\n\n    @abstractmethod\n    def __call__(self, input_tensor):\n        pass\n\n\nclass Conv2d(ABCConv2d):\n    def __init__(self, in_channels, out_channels, kernel_size, stride):\n        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size,\n                                      stride, padding=0, bias=False)\n\n    def set_kernel(self, kernel):\n        self.conv2d.weight.data = kernel\n\n    def __call__(self, input_tensor):\n        return self.conv2d(input_tensor)\n\n\ndef create_and_call_conv2d_layer(conv2d_layer_class, stride, kernel, input_matrix):\n    out_channels = kernel.shape[0]\n    in_channels = kernel.shape[1]\n    kernel_size = kernel.shape[2]\n\n    layer = conv2d_layer_class(in_channels, out_channels, kernel_size, stride)\n    layer.set_kernel(kernel)\n\n    return layer(input_matrix)\n\n\ndef test_conv2d_layer(conv2d_layer_class, batch_size=2,\n                      input_height=4, input_width=4, stride=2):\n    kernel = torch.tensor(\n                      [[[[0., 1, 0],\n                         [1,  2, 1],\n                         [0,  1, 0]],\n\n                        [[1, 2, 1],\n                         [0, 3, 3],\n                         [0, 1, 10]],\n\n                        [[10, 11, 12],\n                         [13, 14, 15],\n                         [16, 17, 18]]]])\n\n    in_channels = kernel.shape[1]\n\n    input_tensor = torch.arange(0, batch_size * in_channels *\n                                input_height * input_width,\n                                out=torch.FloatTensor()) \\\n        .reshape(batch_size, in_channels, input_height, input_width)\n\n    custom_conv2d_out = create_and_call_conv2d_layer(\n        conv2d_layer_class, stride, kernel, input_tensor)\n    conv2d_out = create_and_call_conv2d_layer(\n        Conv2d, stride, kernel, input_tensor)\n\n    return torch.allclose(custom_conv2d_out, conv2d_out) \\\n             and (custom_conv2d_out.shape == conv2d_out.shape)\n\n\n# Сверточный слой через циклы.\nclass Conv2dLoop(ABCConv2d):\n    def __call__(self, input_tensor):\n        \n        n_out_batchs = input_tensor.shape[0]\n        n_out_rows = (input_tensor.shape[2] - self.kernel_size) // self.stride + 1\n        n_out_cols = (input_tensor.shape[3] - self.kernel_size) // self.stride + 1\n        \n        output_tensor = torch.zeros([n_out_batchs, self.out_channels, n_out_rows, n_out_cols])\n        \n        #цикл по количеству входных изображений (кол-ву батчей) \n        for n_batch in range(n_out_batchs):\n            #цикл по количеству фильтров (кернелов) = кол-ву выходных каналов\n            for n_filters in range(self.out_channels):\n                #цикл по строкам\n                    for row in range(n_out_rows):\n                        #цикл по столбцам\n                            for col in range(n_out_cols):\n                                output_tensor[n_batch, n_filters, row, col] = (input_tensor[n_batch,\n                                                                                            :,\n                                                                                            row * self.stride : row * self.stride + self.kernel_size,\n                                                                                            col * self.stride : col * self.stride + self.kernel_size] * self.kernel[n_filters]).sum()\n                                \n        return output_tensor\n\n# Корректность реализации определится в сравнении со стандартным слоем из pytorch.\n# Проверка происходит автоматически вызовом следующего кода\n# (раскомментируйте для самостоятельной проверки,\n#  в коде для сдачи задания должно быть закомментировано):\nprint(test_conv2d_layer(Conv2dLoop))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5.2.4 Семинар: Реализация сверточного слоя**","metadata":{}},{"cell_type":"raw","source":"Переиспользуем код с третьего шага для проверки своей реализации сверточного слоя.\n\nРеализация через циклы очень неэффективна по производительности. Есть целых два способа сделать то же самое с помощью матричного умножения. \n\nНа этом шаге будет реализация первым из них.\n\n \n\nРассмотрим свертку одного одноканального изображения размером 4*4 пикселя (значения пикселей обозначены через X).\n\nСворачивать будем с ядром из одного фильтра размером 3*3, веса обозначены через W.\n\nДля простоты примем stride = 1.\n\nТогда выход Y будет иметь размерность 1*1*2*2 (в данном случае на входе одно изображение - это первая единица в размерности, в ядре один фильтр - это вторая единица в размерности выхода).\n\nОказывается, выход свертки можно получить умножением матриц, как показано ниже.\n\n \n\n \n\nРекомендуем убедиться в этом, перемножив матрицы на листочке.\n\nДавайте перейдем от простого случая к общему:\n\n    Если фильтров в ядре больше одного. Заметим, что для каждого фильтра, матрица W’ будет умножаться на один и тот же вектор изображения. Значит, можно сконкатенировать матрицы фильтров ядра по вертикали и за одно умножение получить ответ для всех фильтров.\n\n \n\n \n\n    Если на входе более одного изображения: заметим, что матрица W’ одинакова для всех изображений батча, то есть, можно каждое изображение вначале вытянуть в столбец, а затем эти столбцы для всех изображений батча сконкатенировать по горизонтали.\n\n \n\n \n\n    Если в изображении больше одного слоя, вначале выполним преобразования входа и ядра для каждого слоя, а затем сконкатенируем: вектора разных слоев входа в один большой вектор, а матрицы ядра соответственно в одну длинную матрицу. И мы получим сложение от выходов по слоям в процессе перемножения матриц.\n\n \n\nТо есть даже в самом общем случае мы за одно умножение матриц можем получить ответ.\n\nНо рассчитанный таким способом выход не совпадает по размерности с выходом стандартного слоя из PyTorch - нужно изменить размерность.\n\n \n\nВ коде уже реализовано:\n\n    преобразование входного батча изображений\n\n    умножение матрицы ядра на матрицу входа\n\n    преобразование ответа\n\nНапоминание: во всех шагах этого урока мы считаем bias в сверточных слоях нулевым.\n\nВам осталось реализовать преобразование ядра в описанный выше формат.\n\nОбратите внимание, что в коде рассматривается общий случай - вход состоит из нескольких многослойных изображений, в ядре несколько слоев.","metadata":{}},{"cell_type":"code","source":"import torch\nfrom abc import ABC, abstractmethod\n\n\ndef calc_out_shape(input_matrix_shape, out_channels, kernel_size, stride, padding):\n    batch_size, channels_count, input_height, input_width = input_matrix_shape\n    output_height = (input_height + 2 * padding - (kernel_size - 1) - 1) // stride + 1\n    output_width = (input_width + 2 * padding - (kernel_size - 1) - 1) // stride + 1\n\n    return batch_size, out_channels, output_height, output_width\n\n\nclass ABCConv2d(ABC):\n    def __init__(self, in_channels, out_channels, kernel_size, stride):\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n\n    def set_kernel(self, kernel):\n        self.kernel = kernel\n\n    @abstractmethod\n    def __call__(self, input_tensor):\n        pass\n\n\nclass Conv2d(ABCConv2d):\n    def __init__(self, in_channels, out_channels, kernel_size, stride):\n        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size,\n                                      stride, padding=0, bias=False)\n\n    def set_kernel(self, kernel):\n        self.conv2d.weight.data = kernel\n\n    def __call__(self, input_tensor):\n        return self.conv2d(input_tensor)\n\n\ndef create_and_call_conv2d_layer(conv2d_layer_class, stride, kernel, input_matrix):\n    out_channels = kernel.shape[0]\n    in_channels = kernel.shape[1]\n    kernel_size = kernel.shape[2]\n\n    layer = conv2d_layer_class(in_channels, out_channels, kernel_size, stride)\n    layer.set_kernel(kernel)\n\n    return layer(input_matrix)\n\n\ndef test_conv2d_layer(conv2d_layer_class, batch_size=2,\n                      input_height=4, input_width=4, stride=2):\n    kernel = torch.tensor(\n                      [[[[0., 1, 0],\n                         [1,  2, 1],\n                         [0,  1, 0]],\n\n                        [[1, 2, 1],\n                         [0, 3, 3],\n                         [0, 1, 10]],\n\n                        [[10, 11, 12],\n                         [13, 14, 15],\n                         [16, 17, 18]]]])\n\n    in_channels = kernel.shape[1]\n\n    input_tensor = torch.arange(0, batch_size * in_channels *\n                                input_height * input_width,\n                                out=torch.FloatTensor()) \\\n        .reshape(batch_size, in_channels, input_height, input_width)\n\n    custom_conv2d_out = create_and_call_conv2d_layer(\n        conv2d_layer_class, stride, kernel, input_tensor)\n    conv2d_out = create_and_call_conv2d_layer(\n        Conv2d, stride, kernel, input_tensor)\n\n    return torch.allclose(custom_conv2d_out, conv2d_out) \\\n             and (custom_conv2d_out.shape == conv2d_out.shape)\n\n\nclass Conv2dMatrix(ABCConv2d):\n    # Функция преобразование кернела в матрицу нужного вида.\n    def _unsqueeze_kernel(self, torch_input, output_height, output_width):\n        ##################################Мой код###################################\n        kernel_list_final = []\n        for n_filter in range(self.kernel.shape[0]):\n            kernel_list_channel = []\n            for n_channel_inp in range(self.kernel.shape[1]):\n                kernel_current = torch.zeros(output_height * output_width, torch_input.shape[-2] * torch_input.shape[-1])\n                n_row = 0\n                for nrow_w in range(output_height):\n                    for nrow_h in range(output_width):\n                        kernel_row = torch.nn.functional.pad(self.kernel[n_filter, n_channel_inp], pad=(nrow_h,torch_input.shape[-1] - self.kernel_size - nrow_h)).reshape(-1)\n                        kernel_row = torch.nn.functional.pad(kernel_row, pad=(nrow_w * torch_input.shape[-1], 0))\n                        kernel_current[n_row,0:len(kernel_row)] = kernel_row\n                        n_row += 1\n                kernel_list_channel.append(kernel_current)\n            kernel_list_final.append(torch.cat(kernel_list_channel, dim=1).reshape(output_height * output_width, -1))\n\n        kernel_unsqueezed = torch.cat(kernel_list_final).reshape(output_height * output_width * self.kernel.shape[0], -1)\n        ############################################################################\n        \n        return kernel_unsqueezed\n\n    def __call__(self, torch_input):\n        batch_size, out_channels, output_height, output_width\\\n            = calc_out_shape(\n                input_matrix_shape=torch_input.shape,\n                out_channels=self.kernel.shape[0],\n                kernel_size=self.kernel.shape[2],\n                stride=self.stride,\n                padding=0)\n\n        kernel_unsqueezed = self._unsqueeze_kernel(torch_input, output_height, output_width)\n        result = kernel_unsqueezed @ torch_input.view((batch_size, -1)).permute(1, 0)\n        return result.permute(1, 0).view((batch_size, self.out_channels,\n                                          output_height, output_width))\n\n# Проверка происходит автоматически вызовом следующего кода\n# (раскомментируйте для самостоятельной проверки,\n#  в коде для сдачи задания должно быть закомментировано):\nprint(test_conv2d_layer(Conv2dMatrix))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5.2.5 Семинар: Реализация сверточного слоя**","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:46:47.492139Z","iopub.execute_input":"2021-12-01T12:46:47.493328Z","iopub.status.idle":"2021-12-01T12:46:47.501176Z","shell.execute_reply.started":"2021-12-01T12:46:47.493262Z","shell.execute_reply":"2021-12-01T12:46:47.499967Z"}}},{"cell_type":"raw","source":"На прошлом шаге W’ имеет много нулей. Это снижает эффективность метода.\n\nНа этом шаге будет реализация через матрицы другим, более эффективным способом.\n\nПусть в этот раз на входе батч из одного трехслойного (RGB) изображения размером 3*3.\n\nПусть ядро имеет 2 фильтра шириной и высотой 2 пикселя.\n\nТогда выход должен иметь размерность 1*2*2*2.\n\nПусть W - веса ядра, X - значения входной матрицы, Y - значения на выходе.\n\nДля простоты слои изображения и слои фильтров ядра покрашены в цвета.\n\nОбратите внимание, например, \"синяя\" X0 не обязано быть равно \"красному\" X0, аналогично и про значения в фильтрах ядра - разный цвет и одинаковые переменные могут иметь разные значения, такое обозначение выбрано, чтобы не загромождать рисунок сложными индексами.\n\n \n\nЕсли в первом матричном способе мы вытягивали изображения в столбцы, то теперь будем вытягивать фильтры кернела в строки.\n\n \n\n \n\nРекомендуем проверить на листочке, что результат произведения таких матриц дает тот же результат, что и свертка.\n\nДавайте перейдем от простого случая к общему:\n\n    Если изображений в батче больше одного: преобразования ядра от этого не меняется, а преобразованные матрицы входных изображений конкатенируются по горизонтали.\n\n \n\nНо рассчитанный таким способом выход не совпадает по размерности с выходом стандартного слоя из PyTorch - нужно изменить размерность.\n\n \n\nФункция умножения матриц уже реализована.\n\n \n\nНапоминание: во всех шагах этого урока мы считаем bias в сверточных слоях нулевым.\n\nТребуется написать функции преобразования ядра и входа.","metadata":{}},{"cell_type":"code","source":"import torch\nfrom abc import ABC, abstractmethod\n\n\ndef calc_out_shape(input_matrix_shape, out_channels, kernel_size, stride, padding):\n    batch_size, channels_count, input_height, input_width = input_matrix_shape\n    output_height = (input_height + 2 * padding - (kernel_size - 1) - 1) // stride + 1\n    output_width = (input_width + 2 * padding - (kernel_size - 1) - 1) // stride + 1\n\n    return batch_size, out_channels, output_height, output_width\n\n\nclass ABCConv2d(ABC):\n    def __init__(self, in_channels, out_channels, kernel_size, stride):\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n\n    def set_kernel(self, kernel):\n        self.kernel = kernel\n\n    @abstractmethod\n    def __call__(self, input_tensor):\n        pass\n\n\ndef create_and_call_conv2d_layer(conv2d_layer_class, stride, kernel, input_matrix):\n    out_channels = kernel.shape[0]\n    in_channels = kernel.shape[1]\n    kernel_size = kernel.shape[2]\n\n    layer = conv2d_layer_class(in_channels, out_channels, kernel_size, stride)\n    layer.set_kernel(kernel)\n\n    return layer(input_matrix)\n\n\nclass Conv2d(ABCConv2d):\n    def __init__(self, in_channels, out_channels, kernel_size, stride):\n        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size,\n                                      stride, padding=0, bias=False)\n\n    def set_kernel(self, kernel):\n        self.conv2d.weight.data = kernel\n\n    def __call__(self, input_tensor):\n        return self.conv2d(input_tensor)\n\n\ndef test_conv2d_layer(conv2d_layer_class, batch_size=2,\n                      input_height=4, input_width=4, stride=2):\n    kernel = torch.tensor(\n                      [[[[0., 1, 0],\n                         [1,  2, 1],\n                         [0,  1, 0]],\n\n                        [[1, 2, 1],\n                         [0, 3, 3],\n                         [0, 1, 10]],\n\n                        [[10, 11, 12],\n                         [13, 14, 15],\n                         [16, 17, 18]]]])\n\n    in_channels = kernel.shape[1]\n\n    input_tensor = torch.arange(0, batch_size * in_channels *\n                                input_height * input_width,\n                                out=torch.FloatTensor()) \\\n        .reshape(batch_size, in_channels, input_height, input_width)\n\n    custom_conv2d_out = create_and_call_conv2d_layer(\n        conv2d_layer_class, stride, kernel, input_tensor)\n    conv2d_out = create_and_call_conv2d_layer(\n        Conv2d, stride, kernel, input_tensor)\n\n    return torch.allclose(custom_conv2d_out, conv2d_out) \\\n             and (custom_conv2d_out.shape == conv2d_out.shape)\n\n\nclass Conv2dMatrixV2(ABCConv2d):\n    # Функция преобразования кернела в нужный формат.\n    def _convert_kernel(self):\n        converted_kernel = self.kernel.reshape(self.kernel.shape[0],-1)\n        return converted_kernel\n\n    # Функция преобразования входа в нужный формат.\n    def _convert_input(self, torch_input, output_height, output_width):\n       \n        lst = []\n        for row in range(output_height):\n            for col in range(output_width):\n                lst.append(torch_input[:,:,row : row + self.kernel_size,\n                                      col : col + self.kernel_size].reshape(-1))\n        \n        #converted_input = torch.cat(lst).reshape(-1,self.kernel.reshape(self.kernel.shape[0], -1).shape[1]).T\n        converted_input = torch.cat(lst).reshape(-1,self.kernel.reshape(self.kernel.shape[0], -1).shape[1]).transpose(1, 0)\n        return converted_input\n\n    def __call__(self, torch_input):\n        batch_size, out_channels, output_height, output_width\\\n            = calc_out_shape(\n                input_matrix_shape=torch_input.shape,\n                out_channels=self.kernel.shape[0],\n                kernel_size=self.kernel.shape[2],\n                stride=self.stride,\n                padding=0)\n\n        converted_kernel = self._convert_kernel()\n        converted_input = self._convert_input(torch_input, output_height, output_width)\n\n        conv2d_out_alternative_matrix_v2 = converted_kernel @ converted_input\n        return conv2d_out_alternative_matrix_v2.transpose(0, 1).view(torch_input.shape[0],\n                                                     self.out_channels, output_height,\n                                                     output_width).transpose(1, 3).transpose(2, 3)\n\n# Проверка происходит автоматически вызовом следующего кода\n# (раскомментируйте для самостоятельной проверки,\n#  в коде для сдачи задания должно быть закомментировано):\nprint(test_conv2d_layer(Conv2dMatrixV2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5.6.5 Семинар: Распознавание рукописных чисел свёрточной нейросетью**","metadata":{}},{"cell_type":"raw","source":"Подберите размеры паддингов:","metadata":{}},{"cell_type":"code","source":"import torch\n\nN = 4\nC = 3\nC_out = 10\nH = 8\nW = 16\n\nx = torch.ones((N, C, H, W))\n\n# torch.Size([4, 10, 8, 16])\nout1 = torch.nn.Conv2d(C, C_out, kernel_size=(3, 3), padding=1)(x)\nprint(out1.shape) # для самопроверки\n\n# torch.Size([4, 10, 8, 16])\nout2 = torch.nn.Conv2d(C, C_out, kernel_size=(5, 5), padding=2)(x)\nprint(out2.shape) # для самопроверки\n\n# torch.Size([4, 10, 8, 16])\nout3 = torch.nn.Conv2d(C, C_out, kernel_size=(7, 7), padding=3)(x)\nprint(out3.shape) # для самопроверки\n\n# torch.Size([4, 10, 8, 16])\nout4 = torch.nn.Conv2d(C, C_out, kernel_size=(9, 9), padding=4)(x)\nprint(out4.shape) # для самопроверки\n\n# torch.Size([4, 10, 8, 16])\nout5 = torch.nn.Conv2d(C, C_out, kernel_size=(3, 5), padding=[1, 2])(x)\nprint(out5.shape) # для самопроверки\n\n# torch.Size([4, 10, 22, 30])\nout6 = torch.nn.Conv2d(C, C_out, kernel_size=(3, 3), padding=8)(x)\nprint(out6.shape) # для самопроверки\n\n# torch.Size([4, 10, 7, 15])\nout7 = torch.nn.Conv2d(C, C_out, kernel_size=(4, 4), padding=1)(x)\nprint(out7.shape) # для самопроверки\n\n# torch.Size([4, 10, 9, 17])\nout8 = torch.nn.Conv2d(C, C_out, kernel_size=(2, 2), padding=1)(x)\nprint(out8.shape) # для самопроверки","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5.6.7 Семинар: Распознавание рукописных чисел свёрточной нейросетью**","metadata":{}},{"cell_type":"raw","source":"Наверняка, посмотрев лекции, у вас появились идеи о том, как улучшить нашу реализацию LeNet. Мы посвятим этому следующий семинар, но сейчас у вас есть возможность наработать собственную интуицию.\n\nПопробуйте добиться качества 0.992  на данном датасете (в максимуме на валидации). Обратите внимание на следующие моменты:\n\n    Появляется ли у вас переобучение при увеличении количества эпох?\n    Как добавление различных слоев влияет на скорость обучения (какие слои быстрее: сверточные или полносвязные)?\n\nПомните, что результат обучения может меняться в от запуска к запуску. Проанализируйте дисперсию целевой метрики от запуска к запуску. Сколько запусков достаточно произвести, перед тем как утверждать, что одна архитектура лучше другой?","metadata":{}},{"cell_type":"code","source":"import torch\nimport random\nimport numpy as np\nimport matplotlib\nmatplotlib.rcParams['figure.figsize'] = (15.0, 5.0)\n\nrs = 42\nrandom.seed(rs)\nnp.random.seed(rs)\ntorch.manual_seed(rs)\ntorch.cuda.manual_seed(rs)\ntorch.backends.cudnn.deterministic = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.datasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MNIST_train = torchvision.datasets.MNIST('./', download=True, train=True)\nMNIST_test = torchvision.datasets.MNIST('./', download=True, train=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = MNIST_train.data\ny_train = MNIST_train.targets\nX_test = MNIST_test.data\ny_test = MNIST_test.targets\n\nlen(y_train), len(y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(X_train[0, :, :])\nplt.show()\nprint(y_train[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.unsqueeze(1).float()\nX_test = X_test.unsqueeze(1).float()\nX_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class LeNet5(torch.nn.Module):\n#     def __init__(self):\n#         super(LeNet5, self).__init__()\n        \n#         self.conv1 = torch.nn.Conv2d(\n#             in_channels=1, out_channels=6, kernel_size=5, padding=2)\n#         self.act1  = torch.nn.ReLU()\n#         self.pool1 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n       \n#         self.conv2 = torch.nn.Conv2d(\n#             in_channels=6, out_channels=16, kernel_size=5, padding=0)\n#         self.act2  = torch.nn.ReLU()\n#         self.pool2 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n        \n#         self.fc1   = torch.nn.Linear(5 * 5 * 16, 120)\n#         self.act3  = torch.nn.ReLU()\n        \n#         self.fc2   = torch.nn.Linear(120, 84)\n#         self.act4  = torch.nn.ReLU()\n        \n#         self.fc3   = torch.nn.Linear(84, 10)\n    \n#     def forward(self, x):\n        \n#         x = self.conv1(x)\n#         x = self.act1(x)\n#         x = self.pool1(x)\n        \n#         x = self.conv2(x)\n#         x = self.act2(x)\n#         x = self.pool2(x)\n        \n#         x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n\n#         x = self.fc1(x)\n#         x = self.act3(x)\n#         x = self.fc2(x)\n#         x = self.act4(x)\n#         x = self.fc3(x)\n        \n#         return x\n    \n# lenet5 = LeNet5()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LeNet5(torch.nn.Module):\n    def __init__(self):\n        super(LeNet5, self).__init__()\n        \n        self.conv1_1 = torch.nn.Conv2d(\n            in_channels=1, out_channels=10, kernel_size=3, padding=1)\n        self.conv1_2 = torch.nn.Conv2d(\n            in_channels=10, out_channels=10, kernel_size=3, padding=1)\n        self.act1  = torch.nn.ReLU()\n        self.pool1 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n       \n        self.conv2_1 = torch.nn.Conv2d(\n            in_channels=10, out_channels=16, kernel_size=3, padding=0)\n        self.conv2_2 = torch.nn.Conv2d(\n            in_channels=16, out_channels=16, kernel_size=3, padding=0)\n        self.act2  = torch.nn.ReLU()\n        self.pool2 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n        \n        self.fc1   = torch.nn.Linear(5 * 5 * 16, 40)\n        self.act3  = torch.nn.ReLU()\n        \n#         self.fc2   = torch.nn.Linear(120, 84)\n#         self.act4  = torch.nn.ReLU()\n        \n#         self.fc3   = torch.nn.Linear(84, 10)\n        self.fc3   = torch.nn.Linear(40, 10)\n    \n    def forward(self, x):\n        \n        x = self.conv1_1(x)\n        x = self.conv1_2(x)\n        x = self.act1(x)\n        x = self.pool1(x)\n        \n        x = self.conv2_1(x)\n        x = self.conv2_2(x)\n        x = self.act2(x)\n        x = self.pool2(x)\n        \n        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n\n        x = self.fc1(x)\n        x = self.act3(x)\n#         x = self.fc2(x)\n#         x = self.act4(x)\n        x = self.fc3(x)\n        \n        return x\n    \nlenet5 = LeNet5()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nlenet5 = lenet5.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = torch.nn.CrossEntropyLoss()\n# optimizer = torch.optim.Adam(lenet5.parameters(), lr=1.0e-3)\noptimizer = torch.optim.Adam(lenet5.parameters(), lr=3.0e-4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 100\n\ntest_accuracy_history = []\ntest_loss_history = []\ntrain_accuracy_history = []\ntrain_loss_history = []\n\nX_test = X_test.to(device)\ny_test = y_test.to(device)\n\nfor epoch in range(10000):\n    order = np.random.permutation(len(X_train))\n    \n    train_accuracy_epoch = []\n    train_loss_epoch = []    \n    \n    for start_index in range(0, len(X_train), batch_size):\n        optimizer.zero_grad()\n        \n        batch_indexes = order[start_index:start_index+batch_size]\n        \n        X_batch = X_train[batch_indexes].to(device)\n        y_batch = y_train[batch_indexes].to(device)\n        \n        preds = lenet5.forward(X_batch) \n        \n        loss_value = loss(preds, y_batch)\n        train_loss_epoch.append(loss_value.data.cpu())\n        \n        loss_value.backward()\n        \n        train_accuracy_epoch.append((preds.argmax(dim=1) == y_batch).float().mean().data.cpu())\n        \n        optimizer.step()\n        \n    test_preds = lenet5.forward(X_test)\n    test_loss_history.append(loss(test_preds, y_test).data.cpu())\n    train_loss_history.append(torch.stack(train_loss_epoch).float().mean().data.cpu())\n    \n   \n    accuracy_test = (test_preds.argmax(dim=1) == y_test).float().mean().data.cpu()\n    accuracy_train = torch.stack(train_accuracy_epoch).float().mean().data.cpu()\n    test_accuracy_history.append(accuracy_test)\n    train_accuracy_history.append(accuracy_train)\n    print('epoch = {}, accuracy_test = {:.3f}, accuracy_train = {:.3f}'.format(epoch, accuracy_test, accuracy_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(test_accuracy_history) #blue\nplt.plot(train_accuracy_history) #orange","metadata":{"id":"W_20Y92A5FU3","outputId":"4259ce9b-da07-42bd-c79a-d1452388ceb2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(test_loss_history)  #blue\nplt.plot(train_loss_history) #orange","metadata":{"id":"lpTrk0gfGSDB","outputId":"5d59060c-4c31-493a-9df2-3279391aab6e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#смотрим на чем сеть ошибается.\ntest_preds =  lenet5.forward(X_test).data.cpu()\nX_errors = X_test[test_preds.argmax(dim=1) != y_test.data.cpu()].data.cpu()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_errors.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_from = 0\nfor i in range(num_from, num_from + 20):\n    plt.imshow(X_errors[i, 0, :, :], cmap='gray', vmin=0, vmax=255)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"Итоговые ответы на вопросы:\n    - Попробуйте добиться качества 0.992  на данном датасете (в максимуме на валидации). \n      = получилось путем:\n          == изменения в Adam lr на lr=3.0e-4\n          == изменения функции активации на всех слоях с гиперб. тангенса на ReLU\n      = далее, еще путсям всяких модификаций (удаление одного полносвязного слоя, увеличение количества нейронов в сверточнх слоях) удалось добиться стабильного результата 0.994 \n      (но параметры при которых удалось это сделать не сохранил.\n\nОбратите внимание на следующие моменты:\n    - Появляется ли у вас переобучение при увеличении количества эпох?\n        == когда результате на трейне доходят до 1.000, на тестве так же наблюдаются максимальные значения, но если еще подержать несколько десятков эпох, то наблюдается переобучение и снижение результатов на тесте\n    - Как добавление различных слоев влияет на скорость обучения (какие слои быстрее: сверточные или полносвязные)?\n\nПомните, что результат обучения может меняться в от запуска к запуску. Проанализируйте дисперсию целевой метрики от запуска к запуску. \n    - Сколько запусков достаточно произвести, перед тем как утверждать, что одна архитектура лучше другой?","metadata":{}},{"cell_type":"markdown","source":"**6.3.1 Семинар: cлой нормализации**","metadata":{}},{"cell_type":"raw","source":"В данном шаге вам требуется реализовать функцию батч-нормализации без использования стандартной функции со следующими упрощениями:\n\n    Параметр Бета принимается равным 0.\n    Параметр Гамма принимается равным 1.\n    Функция должна корректно работать только на этапе обучения.\n    Вход имеет размерность число элементов в батче * длина каждого инстанса.\n\nОчень внимательно посмотрите на определение функции, вычисляющей std.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def custom_batch_norm1d(input_tensor, eps):\n    gamma = 1\n    betta = 0\n    E = input_tensor.mean(dim=0) #мат. ожидание или среднее\n    #The variance is the square of the standard deviation\n    #sigma_squared = ((input_tensor - E)**2).sum(dim=0)/input_tensor.shape[0] #or sigma_squared\n    #or\n    sigma_squared = input_tensor.std(dim=0, unbiased=False)**2\n    \n    normed_tensor = (input_tensor - E)*gamma/(sigma_squared + eps).sqrt() + betta\n    return normed_tensor\n\n\ninput_tensor = torch.Tensor([[0.0, 0, 1, 0, 2], \n                             [0, 1, 1, 0, 10]])\nbatch_norm = nn.BatchNorm1d(input_tensor.shape[1], affine=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Проверка происходит автоматически вызовом следующего кода\n# (раскомментируйте для самостоятельной проверки,\n#  в коде для сдачи задания должно быть закомментировано):\nimport numpy as np\nall_correct = True\nfor eps_power in range(10):\n    eps = np.power(10., -eps_power)\n    batch_norm.eps = eps\n    batch_norm_out = batch_norm(input_tensor)\n    custom_batch_norm_out = custom_batch_norm1d(input_tensor, eps)\n\n    all_correct &= torch.allclose(batch_norm_out, custom_batch_norm_out)\n    all_correct &= batch_norm_out.shape == custom_batch_norm_out.shape\nprint(all_correct)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**6.3.2 Семинар: cлой нормализации**","metadata":{"execution":{"iopub.status.busy":"2021-12-07T12:47:39.154716Z","iopub.execute_input":"2021-12-07T12:47:39.15502Z","iopub.status.idle":"2021-12-07T12:47:39.161195Z","shell.execute_reply.started":"2021-12-07T12:47:39.154989Z","shell.execute_reply":"2021-12-07T12:47:39.160089Z"}}},{"cell_type":"raw","source":"Немного обобщим функцию с предыдущего шага - добавим возможность задавать параметры Бета и Гамма.\n\nНа данном шаге вам требуется реализовать функцию батч-нормализации без использования стандартной функции со следующими упрощениями:\n\n    Функция должна корректно работать только на этапе обучения.\n    Вход имеет размерность число элементов в батче * длина каждого инстанса.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\ninput_size = 7\nbatch_size = 5\ninput_tensor = torch.randn(batch_size, input_size, dtype=torch.float)\n\neps = 1e-3\n\ndef custom_batch_norm1d(input_tensor, weight, bias, eps):\n    E = input_tensor.mean(dim=0) #мат. ожидание или среднее\n    #The variance is the square of the standard deviation\n    #sigma_squared = ((input_tensor - E)**2).sum(dim=0)/input_tensor.shape[0] #or sigma_squared\n    #or\n    sigma_squared = input_tensor.std(dim=0, unbiased=False)**2\n    \n    normed_tensor = (input_tensor - E)*weight/(sigma_squared + eps).sqrt() + bias\n    return normed_tensor\n\n# Проверка происходит автоматически вызовом следующего кода\n# (раскомментируйте для самостоятельной проверки,\n#  в коде для сдачи задания должно быть закомментировано):\nbatch_norm = nn.BatchNorm1d(input_size, eps=eps)\nbatch_norm.bias.data = torch.randn(input_size, dtype=torch.float)\nbatch_norm.weight.data = torch.randn(input_size, dtype=torch.float)\nbatch_norm_out = batch_norm(input_tensor)\ncustom_batch_norm_out = custom_batch_norm1d(input_tensor, batch_norm.weight.data, batch_norm.bias.data, eps)\nprint(torch.allclose(batch_norm_out, custom_batch_norm_out) \\\n      and batch_norm_out.shape == custom_batch_norm_out.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**6.3.3 Семинар: cлой нормализации**","metadata":{"execution":{"iopub.status.busy":"2021-12-07T12:47:39.154716Z","iopub.execute_input":"2021-12-07T12:47:39.15502Z","iopub.status.idle":"2021-12-07T12:47:39.161195Z","shell.execute_reply.started":"2021-12-07T12:47:39.154989Z","shell.execute_reply":"2021-12-07T12:47:39.160089Z"}}},{"cell_type":"raw","source":"Избавимся еще от одного упрощения - реализуем работу слоя батч-нормализации на этапе предсказания.\n\nНа этом этапе вместо статистик по батчу будем использовать экспоненциально сглаженные статистики из истории обучения слоя.\n\nВ данном шаге вам требуется реализовать полноценный класс батч-нормализации без использования стандартной функции, принимающий на вход двумерный тензор. Осторожно, расчёт дисперсии ведётся по смещенной выборке, а расчет скользящего среднего по несмещенной.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\ninput_size = 3\nbatch_size = 5\neps = 1e-1\n\n\nclass CustomBatchNorm1d:\n    def __init__(self, weight, bias, eps, momentum):\n        # Реализуйте в этом месте конструктор.\n        self.weight = weight\n        self.bias = bias\n        self.eps = eps\n        self.momentum = momentum\n        self.E_EMA = 0\n        self.sigma_squared_EMA = 1\n        self.predict_mode = False\n\n    def __call__(self, input_tensor):\n        if not self.predict_mode:\n            #работаем в режиме обучения\n            E = input_tensor.mean(dim=0) #мат. ожидание или среднее\n            sigma_squared = input_tensor.std(dim=0, unbiased=False)**2\n            sigma_squared_for_EMA = input_tensor.std(dim=0, unbiased=True)**2\n            self.E_EMA = (1 - self.momentum) * E + self.momentum * self.E_EMA\n            self.sigma_squared_EMA = (1 - self.momentum) * sigma_squared_for_EMA + self.momentum * self.sigma_squared_EMA\n        else:\n            #работаем в режиме предикта\n            E = self.E_EMA\n            sigma_squared = self.sigma_squared_EMA\n            \n        normed_tensor = (input_tensor - E)*self.weight/(sigma_squared + self.eps).sqrt() + self.bias #нормирование входного тензора.\n        return normed_tensor\n\n    def eval(self):\n        # В этом методе реализуйте переключение в режим предикта.\n        self.predict_mode = True\n        \n\n\nbatch_norm = nn.BatchNorm1d(input_size, eps=eps)\nbatch_norm.bias.data = torch.randn(input_size, dtype=torch.float)\nbatch_norm.weight.data = torch.randn(input_size, dtype=torch.float)\nbatch_norm.momentum = 0.5\n\ncustom_batch_norm1d = CustomBatchNorm1d(batch_norm.weight.data,\n                                        batch_norm.bias.data, eps, batch_norm.momentum)\n\n# Проверка происходит автоматически вызовом следующего кода\n# (раскомментируйте для самостоятельной проверки,\n#  в коде для сдачи задания должно быть закомментировано):\nall_correct = True\n\nfor i in range(8):\n    torch_input = torch.randn(batch_size, input_size, dtype=torch.float)\n    norm_output = batch_norm(torch_input)\n    custom_output = custom_batch_norm1d(torch_input)\n    all_correct &= torch.allclose(norm_output, custom_output, atol=1e-06) \\\n        and norm_output.shape == custom_output.shape\n# print(all_correct)\n\nbatch_norm.eval()\ncustom_batch_norm1d.eval()\n\nfor i in range(8):\n    torch_input = torch.randn(batch_size, input_size, dtype=torch.float)\n    norm_output = batch_norm(torch_input)\n    custom_output = custom_batch_norm1d(torch_input)\n    all_correct &= torch.allclose(norm_output, custom_output, atol=1e-06) \\\n        and norm_output.shape == custom_output.shape\nprint(all_correct)\ncustom_output.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**6.3.4 Семинар: cлой нормализации**","metadata":{"execution":{"iopub.status.busy":"2021-12-07T12:47:39.154716Z","iopub.execute_input":"2021-12-07T12:47:39.15502Z","iopub.status.idle":"2021-12-07T12:47:39.161195Z","shell.execute_reply.started":"2021-12-07T12:47:39.154989Z","shell.execute_reply":"2021-12-07T12:47:39.160089Z"}}},{"cell_type":"raw","source":"Как вы могли убедиться, реализовать батч-норм слой на этапе предсказания не так просто, поэтому в дальнейших шагах этого урока мы больше не будем требовать реализовать эту часть.\n\nСлой батч-нормализации существует для входа любой размерности.\n\nВ данном шаге рассмотрим его для входа из многоканальных двумерных тензоров, например, изображений.\n\nЕсли вытянуть каждый канал картинки в вектор, то вход будет трехмерным:\n\n    количество картинок в батче\n    число каналов в каждой картинке\n    число пикселей в картинке\n\nПроцесс нормализации:\n\n    Вход разбивается на срезы, параллельные синей части. То есть, каждый срез - это все пиксели всех изображений по одному из каналов.\n    Для каждого среза считаются мат. ожидание и дисперсия.\n    Каждый срез нормализуется независимо.\n\nНа данном шаге вам предлагается реализовать батч-норм слой для четырехмерного входа (например, батч из многоканальных двумерных картинок) без использования стандартной реализации со следующими упрощениями:\n\n    Параметр Бета = 0.\n    Параметр Гамма = 1.\n    Функция должна корректно работать только на этапе обучения.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\neps = 1e-3\n\ninput_channels = 3\nbatch_size = 3\nheight = 10\nwidth = 10\n\nbatch_norm_2d = nn.BatchNorm2d(input_channels, affine=False, eps=eps)\n\ninput_tensor = torch.randn(batch_size, input_channels, height, width, dtype=torch.float)\n\ndef custom_batch_norm2d(input_tensor, eps):\n    gamma = 1\n    betta = 0   \n    input_tensor_2d = input_tensor.permute((1, 0, 2, 3)).flatten(1)\n    E = input_tensor_2d.mean(dim=1) #мат. ожидание или среднее\n    sigma_squared = input_tensor_2d.var(dim=1, unbiased=False)\n    input_tensor_2d = input_tensor_2d.permute((1,0))\n    normed_tensor = (input_tensor_2d - E)*gamma/(sigma_squared + eps).sqrt() + betta\n    normed_tensor = normed_tensor.permute((1,0))\n    normed_tensor = normed_tensor.reshape(input_tensor.shape[1], \n                                          input_tensor.shape[0], \n                                          input_tensor.shape[2], \n                                          input_tensor.shape[3])\n    normed_tensor = normed_tensor.permute((1, 0, 2, 3))\n    \n    return normed_tensor\n\n\n# Проверка происходит автоматически вызовом следующего кода\n# (раскомментируйте для самостоятельной проверки,\n#  в коде для сдачи задания должно быть закомментировано):\nnorm_output = batch_norm_2d(input_tensor)\ncustom_output = custom_batch_norm2d(input_tensor, eps)\nprint(torch.allclose(norm_output, custom_output) and norm_output.shape == custom_output.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**6.3.5 Семинар: cлой нормализации**","metadata":{"execution":{"iopub.status.busy":"2021-12-07T12:47:39.154716Z","iopub.execute_input":"2021-12-07T12:47:39.15502Z","iopub.status.idle":"2021-12-07T12:47:39.161195Z","shell.execute_reply.started":"2021-12-07T12:47:39.154989Z","shell.execute_reply":"2021-12-07T12:47:39.160089Z"}}},{"cell_type":"raw","source":"Идея, лежащая в основе слоя нормализации \"по каналу\", что сеть должна быть независимой от контраста исходного изображения.\n\nНормализация \"по каналу\" работает независимо по каждому изображению батча.\n\nНа этом шаге вам предлагается реализовать нормализацию \"по каналу\" без использования стандартного слоя со следующими упрощениями:\n\n    Параметр Бета = 0.\n    Параметр Гамма = 1.\n    Требуется реализация только этапа обучения.\n    Нормализация делается по всем размерностям входа, кроме нулевой.\n\nОбратите внимание, что размерность входа на данном шаге не фиксирована.\n\nУточним, что в слое нормализации \"по каналу\" статистики считаются по всем размерностям, кроме нулевой.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n\neps = 1e-10\n\n\ndef custom_layer_norm(input_tensor, eps):\n    gamma = 1\n    betta = 0   \n    input_tensor_2d = input_tensor.flatten(1)\n    E = input_tensor_2d.mean(dim=1) #мат. ожидание или среднее\n    sigma_squared = input_tensor_2d.var(dim=1, unbiased=False)\n    input_tensor_2d = input_tensor_2d.permute((1,0))\n    normed_tensor = (input_tensor_2d - E)*gamma/(sigma_squared + eps).sqrt() + betta\n    normed_tensor = normed_tensor.permute((1,0))\n    normed_tensor = normed_tensor.reshape(input_tensor.shape)\n    return normed_tensor\n\n\n# Проверка происходит автоматически вызовом следующего кода\n# (раскомментируйте для самостоятельной проверки,\n#  в коде для сдачи задания должно быть закомментировано):\nall_correct = True\nfor dim_count in range(3, 9):\n    input_tensor = torch.randn(*list(range(3, dim_count + 2)), dtype=torch.float)\n    layer_norm = nn.LayerNorm(input_tensor.size()[1:], elementwise_affine=False, eps=eps)\n\n    norm_output = layer_norm(input_tensor)\n    custom_output = custom_layer_norm(input_tensor, eps)\n\n    all_correct &= torch.allclose(norm_output, custom_output, 1e-2)\n    all_correct &= norm_output.shape == custom_output.shape\nprint(all_correct)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**6.3.6 Семинар: cлой нормализации**","metadata":{"execution":{"iopub.status.busy":"2021-12-07T12:47:39.154716Z","iopub.execute_input":"2021-12-07T12:47:39.15502Z","iopub.status.idle":"2021-12-07T12:47:39.161195Z","shell.execute_reply.started":"2021-12-07T12:47:39.154989Z","shell.execute_reply":"2021-12-07T12:47:39.160089Z"}}},{"cell_type":"raw","source":"Нормализация \"по инстансу\" была изначально разработана для задачи style transfer. Идея, лежащая в основе этого слоя, что сеть должна быть независимой от контраста отдельных каналов исходного изображения.\n\nНа этом шаге вам предлагается реализовать нормализацию \"по инстансу\" без использования стандартного слоя со следующими упрощениями:\n\n    Параметр Бета = 0.\n    Параметр Гамма = 1.\n    На вход подается трехмерный тензор (размер батча, число каналов, длина каждого канала инстанса).\n    Требуется реализация только этапа обучения.\n\nВ слое нормализации \"по инстансу\" статистики считаются по последней размерности (по каждому входному каналу каждого входного примера).","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\neps = 1e-3\n\nbatch_size = 5\ninput_channels = 2\ninput_length = 30\n\ninstance_norm = nn.InstanceNorm1d(input_channels, affine=False, eps=eps)\n\ninput_tensor = torch.randn(batch_size, input_channels, input_length, dtype=torch.float)\n\n\ndef custom_instance_norm1d(input_tensor, eps):\n    gamma = 1\n    betta = 0   \n    input_tensor_3d = input_tensor.flatten(2)\n    E = input_tensor_3d.mean(dim=2) #мат. ожидание или среднее\n    sigma_squared = input_tensor_3d.var(dim=2, unbiased=False)\n    input_tensor_3d = input_tensor_3d.permute((2,0,1))\n    normed_tensor = (input_tensor_3d - E)*gamma/(sigma_squared + eps).sqrt() + betta\n    normed_tensor = normed_tensor.permute((1,2,0))\n    normed_tensor = normed_tensor.reshape(input_tensor.shape)\n    return normed_tensor\n\n\n# Проверка происходит автоматически вызовом следующего кода\n# (раскомментируйте для самостоятельной проверки,\n#  в коде для сдачи задания должно быть закомментировано):\nnorm_output = instance_norm(input_tensor)\ncustom_output = custom_instance_norm1d(input_tensor, eps)\nprint(torch.allclose(norm_output, custom_output, atol=1e-06) and norm_output.shape == custom_output.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**6.3.7 Семинар: cлой нормализации**","metadata":{"execution":{"iopub.status.busy":"2021-12-07T12:47:39.154716Z","iopub.execute_input":"2021-12-07T12:47:39.15502Z","iopub.status.idle":"2021-12-07T12:47:39.161195Z","shell.execute_reply.started":"2021-12-07T12:47:39.154989Z","shell.execute_reply":"2021-12-07T12:47:39.160089Z"}}},{"cell_type":"raw","source":"Нормализация \"по группе\" - это обобщение нормализации \"по каналу\" и \"по инстансу\".\n\nКаналы в изображении не являются полностью независимыми, поэтому возможность использования статистики соседних каналов является преимуществом нормализации \"по группе\" по сравнению с нормализацией \"по инстансу\".\n\nВ то же время, каналы изображения могут сильно отличатся, поэтому нормализация \"по группе\" является более гибкой, чем нормализация \"по каналу\".\n\nНа этом шаге вам предлагается реализовать нормализацию \"по группе\" без использования стандартного слоя со следующими упрощениями:\n\n    Параметр Бета = 0.\n    Параметр Гамма = 1.\n    Требуется реализация только этапа обучения.\n    На вход подается трехмерный тензор.\n\nТакже слой принимает на вход число групп.\n\nВ слое нормализации \"по группе\" статистики считаются очень похоже на нормализацию \"по каналу\", только каналы разбиваются на группы.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nchannel_count = 6\neps = 1e-3\nbatch_size = 20\ninput_size = 2\n\ninput_tensor = torch.randn(batch_size, channel_count, input_size)\n\n\ndef custom_group_norm(input_tensor, groups, eps):\n    gamma = 1\n    betta = 0   \n    input_tensor_3d = input_tensor.reshape(input_tensor.shape[0], groups, -1)\n    E = input_tensor_3d.mean(dim=2) #мат. ожидание или среднее\n    sigma_squared = input_tensor_3d.var(dim=2, unbiased=False)\n    input_tensor_3d = input_tensor_3d.permute((2,0,1))\n    normed_tensor = (input_tensor_3d - E)*gamma/(sigma_squared + eps).sqrt() + betta\n    normed_tensor = normed_tensor.permute((1,2,0))\n    normed_tensor = normed_tensor.reshape(input_tensor.shape)\n    return normed_tensor\n\n\n# Проверка происходит автоматически вызовом следующего кода\n# (раскомментируйте для самостоятельной проверки,\n#  в коде для сдачи задания должно быть закомментировано):\nall_correct = True\nfor groups in [1, 2, 3, 6]:\n    group_norm = nn.GroupNorm(groups, channel_count, eps=eps, affine=False)\n    norm_output = group_norm(input_tensor)\n    custom_output = custom_group_norm(input_tensor, groups, eps)\n    all_correct &= torch.allclose(norm_output, custom_output, 1e-3)\n    all_correct &= norm_output.shape == custom_output.shape\nprint(all_correct)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**6.4.1 Семинар: Решаем задачу классификации на датасете CIFAR**","metadata":{}},{"cell_type":"raw","source":"Проверим утверждение про затухание градиента на практике. В документации pytorch можно найти следующие функции активации (самые популярные мы подсветили жирным шрифтом.): \n\nELU, Hardtanh, LeakyReLU, LogSigmoid, PReLU, ReLU, ReLU6, RReLU, SELU, CELU, Sigmoid, Softplus, Softshrink, Softsign, Tanh, Tanhshrink, Hardshrink.\n\nВам предстоит найти активацию, которая приводит к наименьшему затуханию градиента. \n\nДля проверки мы сконструируем SimpleNet, которая будет иметь внутри 3 fc-слоя, по 1 нейрону в каждом без bias'ов. Веса этих нейронов мы проинициализируем единицами. На вход в эту сеть будем подавать числа из нормального распределения. Сделаем 200 запусков (NUMBER_OF_EXPERIMENTS) для честного сравнения и посчитаем среднее значение градиента в первом слое. Найдите такую функцию, которая будет давать максимальные значения градиента в первом слое. Все функции активации нужно инициализировать с аргументами по умолчанию (пустыми скобками).","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\n\nseed = int(input())\nnp.random.seed(seed)\ntorch.manual_seed(seed)\n\nNUMBER_OF_EXPERIMENTS = 200\n\nclass SimpleNet(torch.nn.Module):\n    def __init__(self, activation):\n        super().__init__()\n\n        self.activation = activation\n        self.fc1 = torch.nn.Linear(1, 1, bias=False)  # one neuron without bias\n        self.fc1.weight.data.fill_(1.)  # init weight with 1\n        self.fc2 = torch.nn.Linear(1, 1, bias=False)\n        self.fc2.weight.data.fill_(1.)\n        self.fc3 = torch.nn.Linear(1, 1, bias=False)\n        self.fc3.weight.data.fill_(1.)\n\n    def forward(self, x):\n        x = self.activation(self.fc1(x))\n        x = self.activation(self.fc2(x))\n        x = self.activation(self.fc3(x))\n        return x\n\n    def get_fc1_grad_abs_value(self):\n        return torch.abs(self.fc1.weight.grad)\n\ndef get_fc1_grad_abs_value(net, x):\n    output = net.forward(x)\n    output.backward()  # no loss function. Pretending that we want to minimize output\n                       # In our case output is scalar, so we can calculate backward\n    fc1_grad = net.get_fc1_grad_abs_value().item()\n    net.zero_grad()\n    return fc1_grad\n\ncompare_act = {}\n\nfor act in ['ELU', 'Hardtanh', 'LeakyReLU', 'LogSigmoid', 'PReLU', 'ReLU', 'ReLU6', \n            'RReLU', 'SELU', 'CELU', 'Sigmoid', 'Softplus', 'Softshrink', 'Softsign', 'Tanh', 'Tanhshrink', 'Hardshrink']:\n    \n    activation =  eval('torch.nn.' + act +'()')\n    #activation = getattr(torch.nn, act)()\n    \n    \n    net = SimpleNet(activation=activation)\n\n    fc1_grads = []\n    for x in torch.randn((NUMBER_OF_EXPERIMENTS, 1)):\n        fc1_grads.append(get_fc1_grad_abs_value(net, x))\n    \n    compare_act[act] = np.mean(fc1_grads)\n\n# Проверка осуществляется автоматически, вызовом функции:\nprint(pd.Series(compare_act).sort_values(ascending=False))\n# (раскомментируйте, если решаете задачу локально)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**6.4.2 Семинар: Решаем задачу классификации на датасете CIFAR**","metadata":{}},{"cell_type":"code","source":"from math import exp\nx = 100\ndef th(x):\n    return (exp(x) - exp(-x))/(exp(x) + exp(-x))\n\ndf_dw4 = (1 - th(th(th(th(x))))**2) * th(th(th(x)))\ndf_dw3 = (1 - th(th(th(th(x))))**2) * (1 - th(th(th(x)))**2) * th(th(x))\ndf_dw2 = (1 - th(th(th(th(x))))**2) * (1 - th(th(th(x)))**2) * (1 - th(th(x))**2) * th(x)\ndf_dw1 = (1 - th(th(th(th(x))))**2) * (1 - th(th(th(x)))**2) * (1 - th(th(x))**2) * (1 - th(x)**2) * x\n[round(df_dw1, 3), round(df_dw2, 3), round(df_dw3, 3), round(df_dw4, 3)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ReLU(x):\n    return max(0, x)\n\ndef dReLU(x):\n    return int(x > 0)\n\ndf_dw4 = dReLU(ReLU(ReLU(ReLU(100)))) * ReLU(ReLU(ReLU(100)))\ndf_dw3 = dReLU(ReLU(ReLU(ReLU(100)))) * dReLU(ReLU(ReLU(100)))* ReLU(ReLU(100))\ndf_dw2 = dReLU(ReLU(ReLU(ReLU(100)))) * dReLU(ReLU(ReLU(100)))* dReLU(ReLU(100)) * ReLU(100)\ndf_dw1 = dReLU(ReLU(ReLU(ReLU(100)))) * dReLU(ReLU(ReLU(100)))* dReLU(ReLU(100)) * dReLU(100) * 100\n[round(df_dw1, 3), round(df_dw2, 3), round(df_dw3, 3), round(df_dw4, 3)]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**6.4.3 Семинар: Решаем задачу классификации на датасете CIFAR**","metadata":{}},{"cell_type":"raw","source":"Итак, мы успели поупражняться с построением собственных архитектур, однако сейчас редко кто трудится над конструированием новой архитектуры для популярных задач CV. Победитель конкурса классификации на ImageNet каждый год меняется, тем не менее, самый популярный в бытовом использовании вариант – это ResNet.\n\nМодификаций данной сети довольно много: ResNet13, ResNet18, ResNet34, ResNet50, ResNet101, ResNet152, которые были созданы для ImageNet. А так же есть ResNet20, ResNet32, ResNet44, ResNet56, ResNet110, ResNet1202 для датасета CIFAR10. Предлагаем проверить эти сетки на прочность!\n\n    - Из библиотеки torchvision (ставится вместе с pytorch), можно проимпортировать ResNet18 командой \"from torchvision.models import resnet18\". Вот так просто. Сравните результаты resnet18 и CIFARNet. Какая сеть дает лучший результат?\n    - Попробуйте, пользуясь нашей лекцией и описанием архитектуры из оригинальной статьи, написать собственную реализацию ResNet20. Если возникнут сомнения, можно свериться с кодом из https://github.com/akamaster/pytorch_resnet_cifar10 . Удалось ли побить resnet18?\n    - Реализуйте ResNet110 (возможно, придется уменьшить размер batch'a). Проверьте утверждение, что ResNet110 не обучается (или обучается в 10% случаев), если отключить BatchNorm.\n    - Добавьте Dropout2d после каждого BatchNorm2d для ResNet20. Есть ли положительный эффект? Как параметр \"p\" этого слоя влияет на accuracy и на переобучение? \n    - Добавьте l2-регуляризацию. В PyTorch она активируется с помощью параметра weight_decay в оптимизаторе. Значение обычно выбирают из [1e-3, 1e-4, 1e-5]. Значение 1e-2 ставить не стоит, т.к. сеть не сможет учиться,  а 1e-6 скорее всего просто не повлияет на обучение (но лучше это проверить это утверждение самостоятельно). Пример:\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)","metadata":{}},{"cell_type":"code","source":"import torch\nimport random\nimport numpy as np\nimport matplotlib\n\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:39:21.501413Z","iopub.execute_input":"2021-12-15T10:39:21.502201Z","iopub.status.idle":"2021-12-15T10:39:23.092247Z","shell.execute_reply.started":"2021-12-15T10:39:21.502088Z","shell.execute_reply":"2021-12-15T10:39:23.091526Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torchvision.datasets","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:39:23.094020Z","iopub.execute_input":"2021-12-15T10:39:23.094296Z","iopub.status.idle":"2021-12-15T10:39:23.439300Z","shell.execute_reply.started":"2021-12-15T10:39:23.094261Z","shell.execute_reply":"2021-12-15T10:39:23.438507Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"CIFAR_train = torchvision.datasets.CIFAR10('./', download=True, train=True)\nCIFAR_test = torchvision.datasets.CIFAR10('./', download=True, train=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:39:23.440780Z","iopub.execute_input":"2021-12-15T10:39:23.441550Z","iopub.status.idle":"2021-12-15T10:39:33.495676Z","shell.execute_reply.started":"2021-12-15T10:39:23.441512Z","shell.execute_reply":"2021-12-15T10:39:33.494871Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"X_train = torch.FloatTensor(CIFAR_train.data)\ny_train = torch.LongTensor(CIFAR_train.targets)\nX_test = torch.FloatTensor(CIFAR_test.data)\ny_test = torch.LongTensor(CIFAR_test.targets)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:39:33.500200Z","iopub.execute_input":"2021-12-15T10:39:33.502148Z","iopub.status.idle":"2021-12-15T10:39:33.963248Z","shell.execute_reply.started":"2021-12-15T10:39:33.502110Z","shell.execute_reply":"2021-12-15T10:39:33.962520Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"len(y_train), len(y_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:39:33.967198Z","iopub.execute_input":"2021-12-15T10:39:33.967453Z","iopub.status.idle":"2021-12-15T10:39:33.977090Z","shell.execute_reply.started":"2021-12-15T10:39:33.967418Z","shell.execute_reply":"2021-12-15T10:39:33.976217Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X_train.min(), X_train.max()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:39:33.978782Z","iopub.execute_input":"2021-12-15T10:39:33.979076Z","iopub.status.idle":"2021-12-15T10:39:35.320784Z","shell.execute_reply.started":"2021-12-15T10:39:33.979038Z","shell.execute_reply":"2021-12-15T10:39:35.320060Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"X_train /= 255.\nX_test /= 255.","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:39:35.321884Z","iopub.execute_input":"2021-12-15T10:39:35.322173Z","iopub.status.idle":"2021-12-15T10:39:35.392694Z","shell.execute_reply.started":"2021-12-15T10:39:35.322119Z","shell.execute_reply":"2021-12-15T10:39:35.391987Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"CIFAR_train.classes","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:39:35.393807Z","iopub.execute_input":"2021-12-15T10:39:35.394077Z","iopub.status.idle":"2021-12-15T10:39:35.399396Z","shell.execute_reply.started":"2021-12-15T10:39:35.394041Z","shell.execute_reply":"2021-12-15T10:39:35.398712Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(20,2))\nfor i in range(10):\n    plt.subplot(1, 10, i+1)\n    plt.imshow(X_train[i])\n    print(y_train[i], end=' ')","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:39:35.400650Z","iopub.execute_input":"2021-12-15T10:39:35.401108Z","iopub.status.idle":"2021-12-15T10:39:36.387518Z","shell.execute_reply.started":"2021-12-15T10:39:35.401072Z","shell.execute_reply":"2021-12-15T10:39:36.386805Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_train.shape, y_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:39:36.388591Z","iopub.execute_input":"2021-12-15T10:39:36.388874Z","iopub.status.idle":"2021-12-15T10:39:36.395704Z","shell.execute_reply.started":"2021-12-15T10:39:36.388836Z","shell.execute_reply":"2021-12-15T10:39:36.394969Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.permute(0, 3, 1, 2)\nX_test = X_test.permute(0, 3, 1, 2)\nX_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:39:36.396961Z","iopub.execute_input":"2021-12-15T10:39:36.397690Z","iopub.status.idle":"2021-12-15T10:39:36.694909Z","shell.execute_reply.started":"2021-12-15T10:39:36.397646Z","shell.execute_reply":"2021-12-15T10:39:36.694064Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#https://stackoverflow.com/questions/4529815/saving-an-object-data-persistence/4529901\nimport pickle\ndef save_object(obj, filename):\n    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n\ndef load_object(filename):\n    with open(filename, 'rb') as inp:\n        return pickle.load(inp)\n\n# sample usage\n#company1 = [1,2,3,4,5]\n#save_object(company1, '/kaggle/working/company1.pkl')\n#del company\n#company1 = load_object(filename)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:39:36.696581Z","iopub.execute_input":"2021-12-15T10:39:36.696995Z","iopub.status.idle":"2021-12-15T10:39:36.704822Z","shell.execute_reply.started":"2021-12-15T10:39:36.696955Z","shell.execute_reply":"2021-12-15T10:39:36.704053Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def train(net, X_train, y_train, X_test, y_test, adam_params = {'lr': 1.0e-3}, batch_size = 100, epoch_num = 30):\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    net = net.to(device)\n    loss = torch.nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(net.parameters(), **adam_params)\n    \n    test_accuracy_history = []\n    test_loss_history = []\n    train_accuracy_history = []\n    train_loss_history = []\n\n    X_test = X_test.to(device)\n    y_test = y_test.to(device)\n\n    for epoch in range(epoch_num):\n        order = np.random.permutation(len(X_train))\n        \n        train_accuracy_epoch = []\n        train_loss_epoch = []\n    \n        for start_index in range(0, len(X_train), batch_size):\n            optimizer.zero_grad()\n            net.train()\n\n            batch_indexes = order[start_index:start_index+batch_size]\n\n            X_batch = X_train[batch_indexes].to(device)\n            y_batch = y_train[batch_indexes].to(device)\n\n            preds = net.forward(X_batch)\n\n            loss_value = loss(preds, y_batch)\n            \n            #logging\n            train_accuracy_epoch.append((preds.argmax(dim=1) == y_batch).float().mean().data.cpu())\n            train_loss_epoch.append(loss_value.data.cpu())\n            \n            loss_value.backward()\n\n            optimizer.step()\n        \n        net.eval()\n        with torch.no_grad(): #не храним градиенты для теста, многоркатно сокращает потребление памяти\n            test_preds = net.forward(X_test)\n        \n            #logging\n            test_loss_history.append(loss(test_preds, y_test).data.cpu())\n            train_loss_history.append(torch.stack(train_loss_epoch).float().mean().data.cpu())\n\n            accuracy_test = (test_preds.argmax(dim=1) == y_test).float().mean().data.cpu()\n            accuracy_train = torch.stack(train_accuracy_epoch).float().mean().data.cpu()\n            test_accuracy_history.append(accuracy_test)\n            train_accuracy_history.append(accuracy_train)\n\n        print('Epoch = {:>3},     ACCURACY: test = {:.3f}, train = {:.3f},     LOSS: test = {:.3f}, train = {:.3f}'.format(epoch, \n                                                                                                                 accuracy_test, \n                                                                                                                 accuracy_train,\n                                                                                                                 test_loss_history[-1],\n                                                                                                                 train_loss_history[-1]))\n    del net\n    return test_accuracy_history, train_accuracy_history, test_loss_history, train_loss_history\n\naccuracies = {}\nlosses = {}","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:39:36.706852Z","iopub.execute_input":"2021-12-15T10:39:36.707144Z","iopub.status.idle":"2021-12-15T10:39:36.723461Z","shell.execute_reply.started":"2021-12-15T10:39:36.707095Z","shell.execute_reply":"2021-12-15T10:39:36.722670Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# accuracies = load_object('/kaggle/working/accuracies_6_4_3.pkl')\n# losses = load_object('/kaggle/working/losses_6_4_3.pkl')\n# print(list(accuracies))\n# print(list(losses))","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:39:36.726994Z","iopub.execute_input":"2021-12-15T10:39:36.727335Z","iopub.status.idle":"2021-12-15T10:39:36.733222Z","shell.execute_reply.started":"2021-12-15T10:39:36.727303Z","shell.execute_reply":"2021-12-15T10:39:36.732230Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def show_experiments_plots(accuracies, losses, figsize = (16.0, 6.0)):\n    matplotlib.rcParams['figure.figsize'] = figsize\n    \n    for experiment_id in accuracies.keys():\n        print('{:-<100}'.format(experiment_id))\n        epoch_max_acc = np.array(accuracies[experiment_id]['test']).argmax()\n        print('Max test accuracy on: Epoch = {:>3},     ACCURACY: test = {:.3f}, train = {:.3f},     LOSS: test = {:.3f}, train = {:.3f}'.format(epoch_max_acc, \n                                                                                                                 accuracies[experiment_id]['test'][epoch_max_acc], \n                                                                                                                 accuracies[experiment_id]['train'][epoch_max_acc],\n                                                                                                                 losses[experiment_id]['test'][epoch_max_acc],\n                                                                                                                 losses[experiment_id]['train'][epoch_max_acc]))\n        epoch_min_loss = np.array(losses[experiment_id]['test']).argmin()\n        print('Min test loss on:     Epoch = {:>3},     ACCURACY: test = {:.3f}, train = {:.3f},     LOSS: test = {:.3f}, train = {:.3f}'.format(epoch_min_loss, \n                                                                                                                 accuracies[experiment_id]['test'][epoch_min_loss], \n                                                                                                                 accuracies[experiment_id]['train'][epoch_min_loss],\n                                                                                                                 losses[experiment_id]['test'][epoch_min_loss],\n                                                                                                                 losses[experiment_id]['train'][epoch_min_loss]))\n    \n    for experiment_id in accuracies.keys():\n        plt.plot(accuracies[experiment_id]['test'], label=experiment_id + ' test')\n    plt.legend()\n    plt.title('Validation Accuracy (Test only)')\n    plt.show()\n\n    for experiment_id in accuracies.keys():\n        plt.plot(accuracies[experiment_id]['test'], label=experiment_id + ' test')\n        plt.plot(accuracies[experiment_id]['train'], label=experiment_id + ' train')\n    plt.legend()\n    plt.title('Validation Accuracy (Test/Train)');\n    plt.show()\n\n    for experiment_id in losses.keys():\n        plt.plot(losses[experiment_id]['test'], label=experiment_id  + ' test')\n    plt.legend()\n    plt.title('Validation Loss (Test only)');\n    plt.show()\n\n    for experiment_id in losses.keys():\n        plt.plot(losses[experiment_id]['test'], label=experiment_id  + ' test')\n        plt.plot(losses[experiment_id]['train'], label=experiment_id  + ' train')\n    plt.legend()\n    plt.title('Validation Loss (Test/Train)');\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:39:36.734618Z","iopub.execute_input":"2021-12-15T10:39:36.735067Z","iopub.status.idle":"2021-12-15T10:39:36.749589Z","shell.execute_reply.started":"2021-12-15T10:39:36.735029Z","shell.execute_reply":"2021-12-15T10:39:36.748798Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class CIFARNet(torch.nn.Module):\n    def __init__(self):\n        super(CIFARNet, self).__init__()\n        self.batch_norm0 = torch.nn.BatchNorm2d(3)\n\n        self.conv1 = torch.nn.Conv2d(3, 16, 3, padding=1)\n        self.act1  = torch.nn.ReLU()\n        self.batch_norm1 = torch.nn.BatchNorm2d(16)\n        self.pool1 = torch.nn.MaxPool2d(2, 2)\n        \n        self.conv2 = torch.nn.Conv2d(16, 32, 3, padding=1)\n        self.act2  = torch.nn.ReLU()\n        self.batch_norm2 = torch.nn.BatchNorm2d(32)\n        self.pool2 = torch.nn.MaxPool2d(2, 2)\n        \n        self.conv3 = torch.nn.Conv2d(32, 64, 3, padding=1)\n        self.act3  = torch.nn.ReLU()\n        self.batch_norm3 = torch.nn.BatchNorm2d(64)\n\n        self.fc1   = torch.nn.Linear(8 * 8 * 64, 256)\n        self.act4  = torch.nn.Tanh()\n        self.batch_norm4 = torch.nn.BatchNorm1d(256)\n        \n        self.fc2   = torch.nn.Linear(256, 64)\n        self.act5  = torch.nn.Tanh()\n        self.batch_norm5 = torch.nn.BatchNorm1d(64)\n        \n        self.fc3   = torch.nn.Linear(64, 10)\n    \n    def forward(self, x):\n        x = self.batch_norm0(x)\n        x = self.conv1(x)\n        x = self.act1(x)\n        x = self.batch_norm1(x)\n        x = self.pool1(x)\n        \n        x = self.conv2(x)\n        x = self.act2(x)\n        x = self.batch_norm2(x)\n        x = self.pool2(x)\n        \n        x = self.conv3(x)\n        x = self.act3(x)\n        x = self.batch_norm3(x)\n        \n        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n        x = self.fc1(x)\n        x = self.act4(x)\n        x = self.batch_norm4(x)\n        x = self.fc2(x)\n        x = self.act5(x)\n        x = self.batch_norm5(x)\n        x = self.fc3(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:39:36.751039Z","iopub.execute_input":"2021-12-15T10:39:36.751717Z","iopub.status.idle":"2021-12-15T10:39:36.768452Z","shell.execute_reply.started":"2021-12-15T10:39:36.751626Z","shell.execute_reply":"2021-12-15T10:39:36.767683Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"net_name = 'cifar_net'\naccuracies[net_name] = {}\nlosses[net_name] = {}\naccuracies[net_name]['test'], accuracies[net_name]['train'], losses[net_name]['test'],  losses[net_name]['train']= \\\n    train(CIFARNet(), X_train, y_train, X_test, y_test, batch_size = 100, epoch_num = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:39:44.548039Z","iopub.execute_input":"2021-12-15T10:39:44.548512Z","iopub.status.idle":"2021-12-15T10:40:58.879879Z","shell.execute_reply.started":"2021-12-15T10:39:44.548475Z","shell.execute_reply":"2021-12-15T10:40:58.879125Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from torchvision.models import resnet18\n\nnet_name = 'resnet18'\naccuracies[net_name] = {}\nlosses[net_name] = {}\naccuracies[net_name]['test'], accuracies[net_name]['train'], losses[net_name]['test'],  losses[net_name]['train']= \\\n    train(resnet18(), X_train, y_train, X_test, y_test, batch_size = 100, epoch_num = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:40:58.881492Z","iopub.execute_input":"2021-12-15T10:40:58.882244Z","iopub.status.idle":"2021-12-15T10:45:23.828354Z","shell.execute_reply.started":"2021-12-15T10:40:58.882202Z","shell.execute_reply":"2021-12-15T10:45:23.827547Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# show_experiments_plots(accuracies, losses)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#my realization v1.0\nclass ResNetСifar(torch.nn.Module):\n    def __init__(self, device, n_repeat_layers = 3):\n        #n_repeat_layers = 3, 5, 7, 9 or 18, for 20, 32, 44, 56, 110-layers ResNet Сifar respectively\n        \n        super(ResNetСifar, self).__init__()\n        \n        self.n_repeat_layers = n_repeat_layers\n        \n        #######Initial layer#######\n        self.layer_init_norm_3 = torch.nn.BatchNorm2d(3, device=device)\n        self.layer_init_conv_3_16_3_p1 = torch.nn.Conv2d(3, 16, 3, padding=1, device=device)\n        self.layer_init_act = torch.nn.ReLU()\n        self.layer_init_norm_16 = torch.nn.BatchNorm2d(16, device=device)\n        \n        #######Layer 1#######\n        self.layer_1_dict = {'conv01_16_16_3_p1': [],\n                             'act01': [], \n                             'norm01_16': [],\n                             'conv02_16_16_3_p1': [],\n                             'act02': [], \n                             'norm02_16': []}\n        for _ in range(self.n_repeat_layers):\n            self.layer_1_dict['conv01_16_16_3_p1'].append(torch.nn.Conv2d(16, 16, 3, padding=1, device=device))\n            self.layer_1_dict['act01'].append(torch.nn.ReLU())\n            self.layer_1_dict['norm01_16'].append(torch.nn.BatchNorm2d(16, device=device))\n            self.layer_1_dict['conv02_16_16_3_p1'].append(torch.nn.Conv2d(16, 16, 3, padding=1, device=device))\n            self.layer_1_dict['act02'].append(torch.nn.ReLU())\n            self.layer_1_dict['norm02_16'].append(torch.nn.BatchNorm2d(16, device=device))\n        \n        #######Layer 2#######\n        self.layer_2_conv_16_32_3_p1_s2 = torch.nn.Conv2d(16, 32, 3, padding=1, stride=2, device=device)\n        self.layer_2_act01 = torch.nn.ReLU()\n        self.layer_2_norm01_32 = torch.nn.BatchNorm2d(32, device=device)\n        self.layer_2_conv_32_32_3_p1 = torch.nn.Conv2d(32, 32, 3, padding=1, device=device)\n        self.layer_2_conv_16_32_1_p0_s2 = torch.nn.Conv2d(16, 32, 1, padding=0, stride=2, device=device)\n        self.layer_2_act02 = torch.nn.ReLU()\n        self.layer_2_norm02_32 = torch.nn.BatchNorm2d(32, device=device)\n        \n        self.layer_2_dict = {'conv01_32_32_3_p1': [],\n                             'act01': [], \n                             'norm01_32': [],\n                             'conv02_32_32_3_p1': [],\n                             'act02': [], \n                             'norm02_32': []}\n        for _ in range(self.n_repeat_layers - 1):\n            self.layer_2_dict['conv01_32_32_3_p1'].append(torch.nn.Conv2d(32, 32, 3, padding=1, device=device))\n            self.layer_2_dict['act01'].append(torch.nn.ReLU())\n            self.layer_2_dict['norm01_32'].append(torch.nn.BatchNorm2d(32, device=device))            \n            self.layer_2_dict['conv02_32_32_3_p1'].append(torch.nn.Conv2d(32, 32, 3, padding=1, device=device))\n            self.layer_2_dict['act02'].append(torch.nn.ReLU())\n            self.layer_2_dict['norm02_32'].append(torch.nn.BatchNorm2d(32, device=device))\n        \n        #######Layer 3#######\n        \n        self.layer_3_conv_32_64_3_p1_s2 = torch.nn.Conv2d(32, 64, 3, padding=1, stride=2, device=device)\n        self.layer_3_act01 = torch.nn.ReLU()\n        self.layer_3_norm01_64 = torch.nn.BatchNorm2d(64, device=device)\n        self.layer_3_conv_64_64_3_p1 = torch.nn.Conv2d(64, 64, 3, padding=1, device=device)\n        self.layer_3_conv_32_64_1_p0_s2 = torch.nn.Conv2d(32, 64, 1, padding=0, stride=2, device=device)\n        self.layer_3_act02 = torch.nn.ReLU()\n        self.layer_3_norm02_64 = torch.nn.BatchNorm2d(64, device=device)\n\n        self.layer_3_dict = {'conv01_64_64_3_p1': [],\n                             'act01': [], \n                             'norm01_64': [],\n                             'conv02_64_64_3_p1': [],\n                             'act02': [], \n                             'norm02_64': []}\n        for _ in range(self.n_repeat_layers - 1):\n            self.layer_3_dict['conv01_64_64_3_p1'].append(torch.nn.Conv2d(64, 64, 3, padding=1, device=device))\n            self.layer_3_dict['act01'].append(torch.nn.ReLU())\n            self.layer_3_dict['norm01_64'].append(torch.nn.BatchNorm2d(64, device=device))\n            self.layer_3_dict['conv02_64_64_3_p1'].append(torch.nn.Conv2d(64, 64, 3, padding=1, device=device))\n            self.layer_3_dict['act02'].append(torch.nn.ReLU())\n            self.layer_3_dict['norm02_64'].append(torch.nn.BatchNorm2d(64, device=device))\n        \n        #######Finishing layers#######\n        self.layer_fin_pool = torch.nn.AvgPool2d(kernel_size=8)\n        self.layer_fin_fc_64_10   = torch.nn.Linear(64, 10, device=device)\n        \n    def forward(self, x):\n        \n        #######Initial layer#######\n        x = self.layer_init_norm_3(x)        \n        x = self.layer_init_conv_3_16_3_p1(x)\n        x = self.layer_init_norm_16(x)\n        x = self.layer_init_act(x)\n        \n        #######Layer 1####### \n        for i in range(self.n_repeat_layers):\n            x_init = x\n            \n            x = self.layer_1_dict['conv01_16_16_3_p1'][i](x)\n            x = self.layer_1_dict['norm01_16'][i](x)\n            x = self.layer_1_dict['act01'][i](x)\n            \n            x = self.layer_1_dict['conv02_16_16_3_p1'][i](x)\n            \n            x += x_init\n            \n            x = self.layer_1_dict['norm02_16'][i](x)\n            x = self.layer_1_dict['act02'][i](x)\n            \n        \n        #######Layer 2#######\n        x_init = x\n        \n        x = self.layer_2_conv_16_32_3_p1_s2(x)\n        x = self.layer_2_norm01_32(x)\n        x = self.layer_2_act01(x)\n        x = self.layer_2_conv_32_32_3_p1(x)\n        \n        x_init = self.layer_2_conv_16_32_1_p0_s2(x_init)\n\n        x += x_init\n        \n        x = self.layer_2_norm02_32(x)\n        x = self.layer_2_act02(x)\n        \n        for i in range(self.n_repeat_layers - 1):\n            x_init = x\n            \n            x = self.layer_2_dict['conv01_32_32_3_p1'][i](x)\n            x = self.layer_2_dict['norm01_32'][i](x)\n            x = self.layer_2_dict['act01'][i](x)\n            \n            x = self.layer_2_dict['conv02_32_32_3_p1'][i](x)\n            \n            x += x_init\n            x = self.layer_2_dict['norm02_32'][i](x)\n            x = self.layer_2_dict['act02'][i](x)\n            \n        \n        \n        #######Layer 3#######\n        x_init = x\n        \n        x = self.layer_3_conv_32_64_3_p1_s2(x)\n        x = self.layer_3_norm01_64(x)\n        x = self.layer_3_act01(x)\n        x = self.layer_3_conv_64_64_3_p1(x)\n        \n        x_init = self.layer_3_conv_32_64_1_p0_s2(x_init)\n\n        x += x_init\n        \n        x = self.layer_3_norm02_64(x)\n        x = self.layer_3_act02(x)\n        \n        for i in range(self.n_repeat_layers - 1):\n            x_init = x\n            \n            x = self.layer_3_dict['conv01_64_64_3_p1'][i](x)\n            x = self.layer_3_dict['norm01_64'][i](x)\n            x = self.layer_3_dict['act01'][i](x)\n            \n            x = self.layer_3_dict['conv02_64_64_3_p1'][i](x)\n            x += x_init\n            \n            x = self.layer_3_dict['norm02_64'][i](x) \n            x = self.layer_3_dict['act02'][i](x)\n        \n        \n        #######Finishing layers#######\n        x = self.layer_fin_pool(x)\n        x = torch.flatten(x, 1)\n        x = self.layer_fin_fc_64_10(x)\n              \n        return x","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# net_name = 'ResNet20'\n# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n# accuracies[net_name] = {}\n# losses[net_name] = {}\n# accuracies[net_name]['test'], accuracies[net_name]['train'], losses[net_name]['test'],  losses[net_name]['train']= \\\n#     train(ResNetСifar(device, 3), X_train, y_train, X_test, y_test, batch_size = 100, epoch_num = 30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# net_name = 'ResNet32'\n# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n# accuracies[net_name] = {}\n# losses[net_name] = {}\n# accuracies[net_name]['test'], accuracies[net_name]['train'], losses[net_name]['test'],  losses[net_name]['train']= \\\n#     train(ResNetСifar(device, 5), X_train, y_train, X_test, y_test, batch_size = 100, epoch_num = 20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show_experiments_plots(accuracies, losses)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from numba import cuda\n# device = cuda.get_current_device()\n# device.reset()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nProperly implemented ResNet-s for CIFAR10 as described in paper [1].\nThe implementation and structure of this file is hugely influenced by [2]\nwhich is implemented for ImageNet and doesn't have option A for identity.\nMoreover, most of the implementations on the web is copy-paste from\ntorchvision's resnet and has wrong number of params.\nProper ResNet-s for CIFAR10 (for fair comparision and etc.) has following\nnumber of layers and parameters:\nname      | layers | params\nResNet20  |    20  | 0.27M\nResNet32  |    32  | 0.46M\nResNet44  |    44  | 0.66M\nResNet56  |    56  | 0.85M\nResNet110 |   110  |  1.7M\nResNet1202|  1202  | 19.4m\nwhich this implementation indeed has.\nReference:\n[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n[2] https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\nIf you use this implementation in you work, please don't forget to mention the\nauthor, Yerlan Idelbayev.\n'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.init as init\n\nfrom torch.autograd import Variable\n\n__all__ = ['ResNet', 'resnet20', 'resnet32', 'resnet44', 'resnet56', 'resnet110', 'resnet1202']\n\ndef _weights_init(m):\n    classname = m.__class__.__name__\n    #print(classname)\n    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n        init.kaiming_normal_(m.weight)\n\nclass LambdaLayer(nn.Module):\n    def __init__(self, lambd):\n        super(LambdaLayer, self).__init__()\n        self.lambd = lambd\n\n    def forward(self, x):\n        return self.lambd(x)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1, option='B'):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            if option == 'A':\n                \"\"\"\n                For CIFAR10 ResNet paper uses option A.\n                \"\"\"\n                self.shortcut = LambdaLayer(lambda x:\n                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n            elif option == 'B':\n                self.shortcut = nn.Sequential(\n                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                     nn.BatchNorm2d(self.expansion * planes)\n                )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNet, self).__init__()\n        self.in_planes = 16\n\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n        self.linear = nn.Linear(64, num_classes)\n\n        self.apply(_weights_init)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = F.avg_pool2d(out, out.size()[3])\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\ndef resnet20():\n    return ResNet(BasicBlock, [3, 3, 3])\n\n\ndef resnet32():\n    return ResNet(BasicBlock, [5, 5, 5])\n\n\ndef resnet44():\n    return ResNet(BasicBlock, [7, 7, 7])\n\n\ndef resnet56():\n    return ResNet(BasicBlock, [9, 9, 9])\n\n\ndef resnet110():\n    return ResNet(BasicBlock, [18, 18, 18])\n\n\ndef resnet1202():\n    return ResNet(BasicBlock, [200, 200, 200])\n\n\ndef test(net):\n    import numpy as np\n    total_params = 0\n\n    for x in filter(lambda p: p.requires_grad, net.parameters()):\n        total_params += np.prod(x.data.numpy().shape)\n    print(\"Total number of params\", total_params)\n    print(\"Total layers\", len(list(filter(lambda p: p.requires_grad and len(p.data.size())>1, net.parameters()))))\n\n\nif __name__ == \"__main__\":\n    for net_name in __all__:\n        if net_name.startswith('resnet'):\n            print(net_name)\n            test(globals()[net_name]())\n            print()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_experiments_plots(accuracies, losses)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#my realization 2.1 (with custom norm/dropout)\nclass myResidualBlock_ResNet_Cifar(torch.nn.Module):\n    def __init__(self, in_channels, out_channels, bias = True, batchnorm = True, dropout_p = None):\n        super(myResidualBlock_ResNet_Cifar, self).__init__()\n        \n        list_general_sequential = []\n        \n        if in_channels == out_channels: #block without reduce image\n            list_general_sequential.append(torch.nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=bias))\n\n            if batchnorm:\n                list_general_sequential.append(torch.nn.BatchNorm2d(out_channels))\n            if not dropout_p is None:\n                list_general_sequential.append(torch.nn.Dropout2d(dropout_p))\n            \n            list_general_sequential.append(torch.nn.ReLU())\n            \n            list_general_sequential.append(torch.nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=bias))\n            \n            if batchnorm:\n                list_general_sequential.append(torch.nn.BatchNorm2d(out_channels))\n            if not dropout_p is None:\n                list_general_sequential.append(torch.nn.Dropout2d(dropout_p))\n            \n            self.shortcut = torch.nn.Sequential()\n            \n        else: #first block with reduce image\n            list_general_sequential.append(torch.nn.Conv2d(in_channels, out_channels, 3, padding=1, stride=2, bias=bias))\n\n            if batchnorm:\n                list_general_sequential.append(torch.nn.BatchNorm2d(out_channels))\n            if not dropout_p is None:\n                list_general_sequential.append(torch.nn.Dropout2d(dropout_p))\n\n            list_general_sequential.append(torch.nn.ReLU())\n            \n            list_general_sequential.append(torch.nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=bias))\n            \n            if batchnorm:\n                list_general_sequential.append(torch.nn.BatchNorm2d(out_channels))\n            if not dropout_p is None:\n                list_general_sequential.append(torch.nn.Dropout2d(dropout_p))\n            \n            list_shortcut_sequential = []\n            list_shortcut_sequential.append(torch.nn.Conv2d(in_channels, out_channels, 1, padding=0, stride=2, bias=bias))\n            if batchnorm:\n                list_shortcut_sequential.append(torch.nn.BatchNorm2d(out_channels))\n            if not dropout_p is None:\n                list_shortcut_sequential.append(torch.nn.Dropout2d(dropout_p))            \n            self.shortcut = torch.nn.Sequential(*list_shortcut_sequential)\n        \n        self.general_sequential = torch.nn.Sequential(*list_general_sequential)\n        self.act_finish = torch.nn.ReLU()\n        \n           \n    def forward(self, x):\n        out = self.general_sequential(x)\n        out += self.shortcut(x)\n        out = self.act_finish(out)\n        \n        return out\n   \nclass myResNetСifar(torch.nn.Module):\n    def __init__(self, num_repeat_layers = 3, bias = True, batchnorm = True, dropout_p = None):\n        #num_repeat_layers = 3, 5, 7, 9 or 18, for 20, 32, 44, 56, 110-layers ResNet Сifar respectively\n        \n        super(myResNetСifar, self).__init__()\n        \n        #######Initial layer#######\n        list_layer_init_sequential = []\n        \n        if batchnorm:\n            list_layer_init_sequential.append(torch.nn.BatchNorm2d(3))\n        if not dropout_p is None:\n            list_layer_init_sequential.append(torch.nn.Dropout2d(dropout_p))\n        \n        list_layer_init_sequential.append(torch.nn.Conv2d(3, 16, 3, padding=1, bias=bias))\n        \n        if batchnorm:\n            list_layer_init_sequential.append(torch.nn.BatchNorm2d(16))\n        if not dropout_p is None:\n            list_layer_init_sequential.append(torch.nn.Dropout2d(dropout_p))        \n                                              \n        list_layer_init_sequential.append(torch.nn.ReLU())\n        \n        self.layer_init = torch.nn.Sequential(*list_layer_init_sequential)\n        \n        #######Layer 1#######\n        list_of_sequential_blocks = []\n        for _ in range(num_repeat_layers):\n            list_of_sequential_blocks.append(myResidualBlock_ResNet_Cifar(in_channels = 16, \n                                                                          out_channels = 16, bias = bias,\n                                                                          batchnorm = batchnorm, dropout_p = dropout_p))\n        self.layer_1 = torch.nn.Sequential(*list_of_sequential_blocks)\n        \n        #######Layer 2#######\n        list_of_sequential_blocks = []\n        list_of_sequential_blocks.append(myResidualBlock_ResNet_Cifar(in_channels = 16, \n                                                                      out_channels = 32, bias = bias,\n                                                                          batchnorm = batchnorm, dropout_p = dropout_p)) #first block with reduce image\n        for _ in range(num_repeat_layers - 1):\n            list_of_sequential_blocks.append(myResidualBlock_ResNet_Cifar(in_channels = 32, \n                                                                          out_channels = 32, bias = bias,\n                                                                          batchnorm = batchnorm, dropout_p = dropout_p))\n        self.layer_2 = torch.nn.Sequential(*list_of_sequential_blocks)\n        \n        #######Layer 3#######\n        list_of_sequential_blocks = []\n        list_of_sequential_blocks.append(myResidualBlock_ResNet_Cifar(in_channels = 32, \n                                                                      out_channels = 64, bias = bias,\n                                                                          batchnorm = batchnorm, dropout_p = dropout_p)) #first block with reduce image\n        for _ in range(num_repeat_layers - 1):\n            list_of_sequential_blocks.append(myResidualBlock_ResNet_Cifar(in_channels = 64, \n                                                                          out_channels = 64, bias = bias,\n                                                                          batchnorm = batchnorm, dropout_p = dropout_p))\n        self.layer_3 = torch.nn.Sequential(*list_of_sequential_blocks)\n                                             \n        #######Finishing layers#######\n        self.layer_fin_pool = torch.nn.AvgPool2d(kernel_size=8)\n        self.layer_fin_fc = torch.nn.Linear(64, 10)\n        \n    def forward(self, x):\n        \n        x = self.layer_init(x)       \n        \n        x = self.layer_1(x)\n        \n        x = self.layer_2(x)\n        \n        x = self.layer_3(x)\n\n        x = self.layer_fin_pool(x)\n        x = torch.flatten(x, 1)\n        x = self.layer_fin_fc(x)\n              \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:45:23.829955Z","iopub.execute_input":"2021-12-15T10:45:23.830268Z","iopub.status.idle":"2021-12-15T10:45:23.858590Z","shell.execute_reply.started":"2021-12-15T10:45:23.830230Z","shell.execute_reply":"2021-12-15T10:45:23.857933Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"net_name = 'myResNet20'\naccuracies[net_name] = {}\nlosses[net_name] = {}\naccuracies[net_name]['test'], accuracies[net_name]['train'], losses[net_name]['test'],  losses[net_name]['train']= \\\n    train(myResNetСifar(3), X_train, y_train, X_test, y_test, batch_size = 100, epoch_num = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:45:23.860844Z","iopub.execute_input":"2021-12-15T10:45:23.861196Z","iopub.status.idle":"2021-12-15T10:50:42.963267Z","shell.execute_reply.started":"2021-12-15T10:45:23.861144Z","shell.execute_reply":"2021-12-15T10:50:42.961804Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"net_name = 'myResNet20_bsize_50'\naccuracies[net_name] = {}\nlosses[net_name] = {}\naccuracies[net_name]['test'], accuracies[net_name]['train'], losses[net_name]['test'],  losses[net_name]['train']= \\\n    train(myResNetСifar(3), X_train, y_train, X_test, y_test, batch_size = 50, epoch_num = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:50:42.964903Z","iopub.execute_input":"2021-12-15T10:50:42.965172Z","iopub.status.idle":"2021-12-15T10:58:31.105798Z","shell.execute_reply.started":"2021-12-15T10:50:42.965122Z","shell.execute_reply":"2021-12-15T10:58:31.105078Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"net_name = 'myResNet20_bsize_300'\naccuracies[net_name] = {}\nlosses[net_name] = {}\naccuracies[net_name]['test'], accuracies[net_name]['train'], losses[net_name]['test'],  losses[net_name]['train']= \\\n    train(myResNetСifar(3), X_train, y_train, X_test, y_test, batch_size = 300, epoch_num = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T10:58:31.107466Z","iopub.execute_input":"2021-12-15T10:58:31.107729Z","iopub.status.idle":"2021-12-15T11:02:34.673578Z","shell.execute_reply.started":"2021-12-15T10:58:31.107692Z","shell.execute_reply":"2021-12-15T11:02:34.672727Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"net_name = 'myResNet20_no_norm'\naccuracies[net_name] = {}\nlosses[net_name] = {}\naccuracies[net_name]['test'], accuracies[net_name]['train'], losses[net_name]['test'],  losses[net_name]['train']= \\\n    train(myResNetСifar(3, batchnorm = False), X_train, y_train, X_test, y_test, batch_size = 100, epoch_num = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:02:34.675110Z","iopub.execute_input":"2021-12-15T11:02:34.676036Z","iopub.status.idle":"2021-12-15T11:07:02.525054Z","shell.execute_reply.started":"2021-12-15T11:02:34.675994Z","shell.execute_reply":"2021-12-15T11:07:02.524235Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"net_name = 'myResNet20_dropout_0.1'\naccuracies[net_name] = {}\nlosses[net_name] = {}\naccuracies[net_name]['test'], accuracies[net_name]['train'], losses[net_name]['test'],  losses[net_name]['train']= \\\n    train(myResNetСifar(3, dropout_p = 0.1), X_train, y_train, X_test, y_test, batch_size = 100, epoch_num = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:07:02.526531Z","iopub.execute_input":"2021-12-15T11:07:02.527647Z","iopub.status.idle":"2021-12-15T11:12:44.029728Z","shell.execute_reply.started":"2021-12-15T11:07:02.527604Z","shell.execute_reply":"2021-12-15T11:12:44.028847Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"net_name = 'myResNet20_dropout_0.2'\naccuracies[net_name] = {}\nlosses[net_name] = {}\naccuracies[net_name]['test'], accuracies[net_name]['train'], losses[net_name]['test'],  losses[net_name]['train']= \\\n    train(myResNetСifar(3, dropout_p = 0.2), X_train, y_train, X_test, y_test, batch_size = 100, epoch_num = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:12:44.031441Z","iopub.execute_input":"2021-12-15T11:12:44.031711Z","iopub.status.idle":"2021-12-15T11:18:23.739699Z","shell.execute_reply.started":"2021-12-15T11:12:44.031674Z","shell.execute_reply":"2021-12-15T11:18:23.738968Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"net_name = 'myResNet20_dropout_0.5'\naccuracies[net_name] = {}\nlosses[net_name] = {}\naccuracies[net_name]['test'], accuracies[net_name]['train'], losses[net_name]['test'],  losses[net_name]['train']= \\\n    train(myResNetСifar(3, dropout_p = 0.5), X_train, y_train, X_test, y_test, batch_size = 100, epoch_num = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:18:23.742715Z","iopub.execute_input":"2021-12-15T11:18:23.743391Z","iopub.status.idle":"2021-12-15T11:24:03.928696Z","shell.execute_reply.started":"2021-12-15T11:18:23.743351Z","shell.execute_reply":"2021-12-15T11:24:03.927196Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"net_name = 'myResNet20_lr_3.0e-4'\naccuracies[net_name] = {}\nlosses[net_name] = {}\naccuracies[net_name]['test'], accuracies[net_name]['train'], losses[net_name]['test'],  losses[net_name]['train']= \\\n    train(myResNetСifar(3), X_train, y_train, X_test, y_test, adam_params = {'lr': 3.0e-4}, batch_size = 100, epoch_num = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:24:03.930451Z","iopub.execute_input":"2021-12-15T11:24:03.930869Z","iopub.status.idle":"2021-12-15T11:29:23.631318Z","shell.execute_reply.started":"2021-12-15T11:24:03.930829Z","shell.execute_reply":"2021-12-15T11:29:23.630565Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"net_name = 'myResNet20_l2-reg_wc_1e-3'\naccuracies[net_name] = {}\nlosses[net_name] = {}\naccuracies[net_name]['test'], accuracies[net_name]['train'], losses[net_name]['test'],  losses[net_name]['train']= \\\n    train(myResNetСifar(3), X_train, y_train, X_test, y_test, adam_params = {'lr': 1.0e-3, 'weight_decay': 1e-3}, batch_size = 100, epoch_num = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:29:23.633096Z","iopub.execute_input":"2021-12-15T11:29:23.633892Z","iopub.status.idle":"2021-12-15T11:34:45.146236Z","shell.execute_reply.started":"2021-12-15T11:29:23.633849Z","shell.execute_reply":"2021-12-15T11:34:45.145466Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"net_name = 'myResNet20_l2-reg_wc_1e-4'\naccuracies[net_name] = {}\nlosses[net_name] = {}\naccuracies[net_name]['test'], accuracies[net_name]['train'], losses[net_name]['test'],  losses[net_name]['train']= \\\n    train(myResNetСifar(3), X_train, y_train, X_test, y_test, adam_params = {'lr': 1.0e-3, 'weight_decay': 1e-4}, batch_size = 100, epoch_num = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:39:49.958559Z","iopub.execute_input":"2021-12-15T11:39:49.958820Z","iopub.status.idle":"2021-12-15T11:45:12.865858Z","shell.execute_reply.started":"2021-12-15T11:39:49.958790Z","shell.execute_reply":"2021-12-15T11:45:12.865139Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"net_name = 'myResNet20_l2-reg_wc_1e-5'\naccuracies[net_name] = {}\nlosses[net_name] = {}\naccuracies[net_name]['test'], accuracies[net_name]['train'], losses[net_name]['test'],  losses[net_name]['train']= \\\n    train(myResNetСifar(3), X_train, y_train, X_test, y_test, adam_params = {'lr': 1.0e-3, 'weight_decay': 1e-5}, batch_size = 100, epoch_num = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:45:12.867905Z","iopub.execute_input":"2021-12-15T11:45:12.868396Z","iopub.status.idle":"2021-12-15T11:50:35.762764Z","shell.execute_reply.started":"2021-12-15T11:45:12.868357Z","shell.execute_reply":"2021-12-15T11:50:35.762009Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"net_name = 'myResNet32'\naccuracies[net_name] = {}\nlosses[net_name] = {}\naccuracies[net_name]['test'], accuracies[net_name]['train'], losses[net_name]['test'],  losses[net_name]['train']= \\\n    train(myResNetСifar(5), X_train, y_train, X_test, y_test, batch_size = 100, epoch_num = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:50:35.764199Z","iopub.execute_input":"2021-12-15T11:50:35.764520Z","iopub.status.idle":"2021-12-15T11:59:00.829023Z","shell.execute_reply.started":"2021-12-15T11:50:35.764481Z","shell.execute_reply":"2021-12-15T11:59:00.828201Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"net_name = 'myResNet44'\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\naccuracies[net_name] = {}\nlosses[net_name] = {}\naccuracies[net_name]['test'], accuracies[net_name]['train'], losses[net_name]['test'],  losses[net_name]['train']= \\\n    train(myResNetСifar(7), X_train, y_train, X_test, y_test, batch_size = 100, epoch_num = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:59:00.834095Z","iopub.execute_input":"2021-12-15T11:59:00.836559Z","iopub.status.idle":"2021-12-15T12:10:59.174857Z","shell.execute_reply.started":"2021-12-15T11:59:00.836509Z","shell.execute_reply":"2021-12-15T12:10:59.174134Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"net_name = 'myResNet56'\naccuracies[net_name] = {}\nlosses[net_name] = {}\naccuracies[net_name]['test'], accuracies[net_name]['train'], losses[net_name]['test'],  losses[net_name]['train']= \\\n    train(myResNetСifar(9), X_train, y_train, X_test, y_test, batch_size = 100, epoch_num = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T12:10:59.177384Z","iopub.execute_input":"2021-12-15T12:10:59.177790Z","iopub.status.idle":"2021-12-15T12:26:32.495630Z","shell.execute_reply.started":"2021-12-15T12:10:59.177753Z","shell.execute_reply":"2021-12-15T12:26:32.494875Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# show_experiments_plots(accuracies, losses)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T12:26:32.497145Z","iopub.execute_input":"2021-12-15T12:26:32.498325Z","iopub.status.idle":"2021-12-15T12:26:32.502120Z","shell.execute_reply.started":"2021-12-15T12:26:32.498281Z","shell.execute_reply":"2021-12-15T12:26:32.501442Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"net_name = 'myResNet110'\naccuracies[net_name] = {}\nlosses[net_name] = {}\naccuracies[net_name]['test'], accuracies[net_name]['train'], losses[net_name]['test'],  losses[net_name]['train']= \\\n    train(myResNetСifar(18), X_train, y_train, X_test, y_test, batch_size = 100, epoch_num = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T12:26:32.503231Z","iopub.execute_input":"2021-12-15T12:26:32.503789Z","iopub.status.idle":"2021-12-15T12:58:08.220373Z","shell.execute_reply.started":"2021-12-15T12:26:32.503750Z","shell.execute_reply":"2021-12-15T12:58:08.219611Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"net_name = 'myResNet110_no_norm'\naccuracies[net_name] = {}\nlosses[net_name] = {}\naccuracies[net_name]['test'], accuracies[net_name]['train'], losses[net_name]['test'],  losses[net_name]['train']= \\\n    train(myResNetСifar(18, batchnorm = False), X_train, y_train, X_test, y_test, batch_size = 100, epoch_num = 20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_object(accuracies, 'accuracies_6_4_3.pkl')\nsave_object(losses, 'losses_6_4_3.pkl')","metadata":{"execution":{"iopub.status.busy":"2021-12-15T12:58:08.222257Z","iopub.execute_input":"2021-12-15T12:58:08.222957Z","iopub.status.idle":"2021-12-15T12:58:08.284791Z","shell.execute_reply.started":"2021-12-15T12:58:08.222918Z","shell.execute_reply":"2021-12-15T12:58:08.284040Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"accuracies","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:22:01.411193Z","iopub.execute_input":"2021-12-15T13:22:01.411668Z","iopub.status.idle":"2021-12-15T13:22:01.542376Z","shell.execute_reply.started":"2021-12-15T13:22:01.411628Z","shell.execute_reply":"2021-12-15T13:22:01.541559Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"losses","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:19:25.707757Z","iopub.execute_input":"2021-12-15T13:19:25.708420Z","iopub.status.idle":"2021-12-15T13:19:25.847972Z","shell.execute_reply.started":"2021-12-15T13:19:25.708379Z","shell.execute_reply":"2021-12-15T13:19:25.847231Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:14:54.883501Z","iopub.execute_input":"2021-12-15T13:14:54.884113Z","iopub.status.idle":"2021-12-15T13:14:55.603102Z","shell.execute_reply.started":"2021-12-15T13:14:54.884074Z","shell.execute_reply":"2021-12-15T13:14:55.602222Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"show_experiments_plots(accuracies, losses)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T12:58:08.286035Z","iopub.execute_input":"2021-12-15T12:58:08.286296Z","iopub.status.idle":"2021-12-15T12:58:10.599746Z","shell.execute_reply.started":"2021-12-15T12:58:08.286260Z","shell.execute_reply":"2021-12-15T12:58:10.599142Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"from time import sleep\nsleep(10000000)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:39:03.468896Z","iopub.status.idle":"2021-12-15T11:39:03.469719Z","shell.execute_reply.started":"2021-12-15T11:39:03.469466Z","shell.execute_reply":"2021-12-15T11:39:03.469494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}