{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:50:51.424059Z","iopub.execute_input":"2022-04-26T12:50:51.424811Z","iopub.status.idle":"2022-04-26T12:50:51.446726Z","shell.execute_reply.started":"2022-04-26T12:50:51.424719Z","shell.execute_reply":"2022-04-26T12:50:51.44598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"Исходное задание.\n\nВ качестве домашнего задания мы предлагаем Вам попробовать дообучить BERT на более традиционном датасете - коллекции отзывов на фильмы (IMDB Dataset of 50K Movie Reviews).\n\nНа первый взгляд, задание кажется очень простым: Вам нужно перезапустить код семинара, подав на дообучение другие данные. После выполнения этого несложного упражнения, ответьте на вопросы:\n1. Удалось ли достичь такого же accuracy (98\\%) при использовании IMDB датасета?\n2. Удалось ли получить хорошее качество классификации всего за одну эпоху?\n3. Подумайте, в чем может быть причина различий в дообучении одной и той же модели на разных датасетах\n    - Внимательно изучите датасет с русскими твитами. В чем его особенности? Нет ли явных паттернов или ключевых слов, которые однозначно определяют сентимент твита?\n    - Попробуйте удалить пунктуацию из датасета с русскими твитами и перезапустите дообучение модели. Изменилось ли итоговое качество работы модели? Почему?","metadata":{}},{"cell_type":"raw","source":"Итоговое задание для меня:\n    + Запустить и сохранить через Save Version текущую версию ноутбука (с твитами), без использования импортов из dlnlputils\n    + Понять код семинара, где нужно добавить дополнительные комментарии\n        + разобраться с вопросами из комментариев, в особенности про саму выбранную модель берт, является ли они мультиязычной \n          или нет и т.п.\n    + Запустить BERT на более традиционном датасете - коллекции отзывов на фильмы (IMDB Dataset of 50K Movie Reviews)\n    + Ответить на вопросы:\n        + Удалось ли достичь такого же accuracy (98%) при использовании IMDB датасета? = Результаты ниже на 4%\n        + Удалось ли получить хорошее качество классификации всего за одну эпоху? = вполне, 93.93% (TRUNC_PAD_TYPE = \"pre\", \n          LEN_MAX=500)\n        + Подумайте, в чем может быть причина различий в дообучении одной и той же модели на разных датасетах\n            + Внимательно изучите датасет с русскими твитами. В чем его особенности? Нет ли явных паттернов или ключевых слов, \n              которые однозначно определяют сентимент твита? = огромный процент (>90%) позитивных спайлов в позитивных твитах \n              и негативных в негативных \n            + Попробуйте удалить пунктуацию из датасета с русскими твитами и перезапустите дообучение модели. Изменилось ли \n              итоговое качество работы модели? Почему? = 74%, очень возможно потому что модель английская, имеет смысл \n              попробовать мультиязычную или русскоязычную модель (попробовал мультиязычную bert-base-multilingual-uncased,\n              результат улучшился = 78.31%)","metadata":{}},{"cell_type":"markdown","source":"# Определение эмоциональной окраски твитов с помощью BERT","metadata":{"id":"jNKaJz5j_ylj"}},{"cell_type":"code","source":"# Если Вы запускаете ноутбук на colab или kaggle,\n# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n\n# !git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n# import sys; sys.path.append('./stepik-dl-nlp')","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:50:51.448189Z","iopub.execute_input":"2022-04-26T12:50:51.448616Z","iopub.status.idle":"2022-04-26T12:50:51.452685Z","shell.execute_reply.started":"2022-04-26T12:50:51.44858Z","shell.execute_reply":"2022-04-26T12:50:51.451753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Установка библиотек","metadata":{"id":"RX_ZDhicpHkV"}},{"cell_type":"code","source":"!pip install pytorch-transformers","metadata":{"id":"0NmMdkZO8R6q","outputId":"1cc59bfa-1dbb-4540-cb22-196f399f62af","execution":{"iopub.status.busy":"2022-04-26T12:50:51.454063Z","iopub.execute_input":"2022-04-26T12:50:51.454634Z","iopub.status.idle":"2022-04-26T12:50:58.890302Z","shell.execute_reply.started":"2022-04-26T12:50:51.454598Z","shell.execute_reply":"2022-04-26T12:50:58.889483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom pytorch_transformers import BertTokenizer, BertConfig\nfrom pytorch_transformers import AdamW, BertForSequenceClassification\nfrom tqdm import tqdm, trange\nimport pandas as pd\nimport io\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt","metadata":{"id":"Ok002ceNB8E7","outputId":"06ef90d2-7518-4209-da66-1dd45c357c78","execution":{"iopub.status.busy":"2022-04-26T12:50:58.893077Z","iopub.execute_input":"2022-04-26T12:50:58.893615Z","iopub.status.idle":"2022-04-26T12:51:01.348225Z","shell.execute_reply.started":"2022-04-26T12:50:58.893577Z","shell.execute_reply":"2022-04-26T12:51:01.34748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nif device.type == 'cpu':\n    print('cpu')\nelse:\n    n_gpu = torch.cuda.device_count()\n    print(torch.cuda.get_device_name(0))","metadata":{"id":"oYsV4H8fCpZ-","outputId":"b8812c8e-3149-475f-b4c0-262160485c39","execution":{"iopub.status.busy":"2022-04-26T12:51:01.349597Z","iopub.execute_input":"2022-04-26T12:51:01.350063Z","iopub.status.idle":"2022-04-26T12:51:01.388203Z","shell.execute_reply.started":"2022-04-26T12:51:01.350023Z","shell.execute_reply":"2022-04-26T12:51:01.387472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Загрузка данных\n","metadata":{"id":"guw6ZNtaswKc"}},{"cell_type":"markdown","source":"Мы выбрали необычный датасет с разметкой сентимента русскоязычных твитов (подробнее про него в [статье](http://www.swsys.ru/index.php?page=article&id=3962&lang=)). В корпусе, который мы использовали 114,911 положительных и 111,923 отрицательных записей. Загрузить его можно [тут](https://study.mokoron.com/).","metadata":{}},{"cell_type":"raw","source":"import pandas as pd\n\n!mkdir ./stepik-dl-nlp/\n!mkdir ./stepik-dl-nlp/datasets/\n!mkdir ./stepik-dl-nlp/datasets/bert_sentiment_analysis/\n\n!curl \"https://raw.githubusercontent.com/Samsung-IT-Academy/stepik-dl-nlp/master/datasets/bert_sentiment_analysis/positive.csv\" \\\n    -o ./stepik-dl-nlp/datasets/bert_sentiment_analysis/positive.csv\n!curl \"https://raw.githubusercontent.com/Samsung-IT-Academy/stepik-dl-nlp/master/datasets/bert_sentiment_analysis/negative.csv\" \\\n    -o ./stepik-dl-nlp/datasets/bert_sentiment_analysis/negative.csv\n\n# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\npos_texts = pd.read_csv('./stepik-dl-nlp/datasets/bert_sentiment_analysis/positive.csv', encoding='utf8', sep=';', header=None)\nneg_texts = pd.read_csv('./stepik-dl-nlp/datasets/bert_sentiment_analysis/negative.csv', encoding='utf8', sep=';', header=None)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:16:46.245727Z","iopub.execute_input":"2022-04-26T08:16:46.245927Z","iopub.status.idle":"2022-04-26T08:16:52.742897Z","shell.execute_reply.started":"2022-04-26T08:16:46.245903Z","shell.execute_reply":"2022-04-26T08:16:52.741905Z"}}},{"cell_type":"raw","source":"# #Попробуйте удалить пунктуацию из датасета с русскими твитами и перезапустите дообучение модели. Изменилось ли итоговое качество работы модели? Почему?\n# import re\n# pos_texts[3] = pd.Series([re.sub(r':D|D:|[^\\w\\s]', '', line) for line in list(pos_texts[3])])\n# neg_texts[3] = pd.Series([re.sub(r':D|D:|[^\\w\\s]', '', line) for line in list(neg_texts[3])])","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:16:52.744604Z","iopub.execute_input":"2022-04-26T08:16:52.744841Z","iopub.status.idle":"2022-04-26T08:16:52.749897Z","shell.execute_reply.started":"2022-04-26T08:16:52.744813Z","shell.execute_reply":"2022-04-26T08:16:52.748453Z"}}},{"cell_type":"raw","source":"pos_texts.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:16:52.751457Z","iopub.execute_input":"2022-04-26T08:16:52.751686Z","iopub.status.idle":"2022-04-26T08:16:52.784049Z","shell.execute_reply.started":"2022-04-26T08:16:52.751661Z","shell.execute_reply":"2022-04-26T08:16:52.783187Z"}}},{"cell_type":"raw","source":"sentences = np.concatenate([pos_texts[3].values, neg_texts[3].values])\n\nsentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\nlabels = [[1] for _ in range(pos_texts.shape[0])] + [[0] for _ in range(neg_texts.shape[0])]","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:16:52.786119Z","iopub.execute_input":"2022-04-26T08:16:52.786906Z","iopub.status.idle":"2022-04-26T08:16:53.391114Z","shell.execute_reply.started":"2022-04-26T08:16:52.786855Z","shell.execute_reply":"2022-04-26T08:16:53.390312Z"}}},{"cell_type":"raw","source":"assert len(sentences) == len(labels) == pos_texts.shape[0] + neg_texts.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:16:53.392318Z","iopub.execute_input":"2022-04-26T08:16:53.393226Z","iopub.status.idle":"2022-04-26T08:16:53.396852Z","shell.execute_reply.started":"2022-04-26T08:16:53.39319Z","shell.execute_reply":"2022-04-26T08:16:53.396296Z"}}},{"cell_type":"raw","source":"print(sentences[1000])","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:16:53.397654Z","iopub.execute_input":"2022-04-26T08:16:53.397868Z","iopub.status.idle":"2022-04-26T08:16:53.431802Z","shell.execute_reply.started":"2022-04-26T08:16:53.397843Z","shell.execute_reply":"2022-04-26T08:16:53.430799Z"}}},{"cell_type":"raw","source":"from sklearn.model_selection import train_test_split\n\ntrain_sentences, test_sentences, train_gt, test_gt = train_test_split(sentences, labels, test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:16:53.43459Z","iopub.execute_input":"2022-04-26T08:16:53.434912Z","iopub.status.idle":"2022-04-26T08:16:53.579032Z","shell.execute_reply.started":"2022-04-26T08:16:53.434872Z","shell.execute_reply":"2022-04-26T08:16:53.578151Z"}}},{"cell_type":"raw","source":"print(len(train_gt), len(test_gt))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:37:28.073859Z","iopub.execute_input":"2022-04-22T16:37:28.074114Z","iopub.status.idle":"2022-04-22T16:37:28.080391Z","shell.execute_reply.started":"2022-04-22T16:37:28.074085Z","shell.execute_reply":"2022-04-22T16:37:28.079179Z"}}},{"cell_type":"markdown","source":"## Inputs","metadata":{"id":"ex5O1eV-Pfct"}},{"cell_type":"raw","source":"from pytorch_transformers import BertTokenizer, BertConfig\n\n# Подробное описание модели https://huggingface.co/bert-base-uncased\n# Pretrained model on English language using a masked language modeling (MLM) \n# objective. It was introduced in this paper and first released in this repository. \n# This model is uncased: it does not make a difference between english and English.\n# Особое внимание на то, что модель обучена только на английском, и для данной \n# задачи имело бы смысл применять русскоязычную модель, т.е. текущая скорей всего \n# показывает хорошие результаты только за счет высокой роли смайлов в сообщении\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n#tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)\n\ntokenized_texts = [tokenizer.tokenize(sent) for sent in train_sentences]\nprint(train_sentences[0])\nprint(tokenized_texts[0])","metadata":{"id":"Z474sSC6oe7A","outputId":"fbaa8fd8-bccd-4feb-ce52-beba5d293cfa","execution":{"iopub.status.busy":"2022-04-22T16:37:28.08195Z","iopub.execute_input":"2022-04-22T16:37:28.082199Z","iopub.status.idle":"2022-04-22T16:39:06.497088Z","shell.execute_reply.started":"2022-04-22T16:37:28.08217Z","shell.execute_reply":"2022-04-22T16:39:06.495796Z"}}},{"cell_type":"raw","source":"BERTу нужно предоставить специальный формат входных данных.\n\n\n- **input ids**: последовательность чисел, отождествляющих каждый токен с его номером в словаре.\n- **labels**: вектор из нулей и единиц. В нашем случае нули обозначают негативную эмоциональную окраску, единицы - положительную.\n- **segment mask**: (необязательно) последовательность нулей и единиц, которая показывает, состоит ли входной текст из одного или двух предложений. Для случая одного предложения получится вектор из одних нулей. Для двух: <length_of_sent_1> нулей и <length_of_sent_2> единиц.\n- **attention mask**: (необязательно) последовательность нулей и единиц, где единицы обозначают токены предложения, нули - паддинг.","metadata":{"id":"87_kXUeT2-br"}},{"cell_type":"raw","source":"MAX_LEN = 100\n\ninput_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\ninput_ids = pad_sequences(\n    input_ids,\n    maxlen=MAX_LEN,\n    dtype=\"long\",\n    truncating=\"post\",\n    padding=\"post\"\n)\nattention_masks = [[float(i>0) for i in seq] for seq in input_ids]","metadata":{"id":"Cp9BPRd1tMIo","execution":{"iopub.status.busy":"2022-04-22T16:39:06.498413Z","iopub.execute_input":"2022-04-22T16:39:06.498652Z","iopub.status.idle":"2022-04-22T16:39:28.237168Z","shell.execute_reply.started":"2022-04-22T16:39:06.498606Z","shell.execute_reply":"2022-04-22T16:39:28.235968Z"}}},{"cell_type":"raw","source":"train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n    input_ids, train_gt, \n    random_state=42,\n    test_size=0.1\n)\n\ntrain_masks, validation_masks, _, _ = train_test_split(\n    attention_masks,\n    input_ids,\n    random_state=42,\n    test_size=0.1\n)","metadata":{"id":"aFbE-UHvsb7-","execution":{"iopub.status.busy":"2022-04-22T16:39:28.2391Z","iopub.execute_input":"2022-04-22T16:39:28.239372Z","iopub.status.idle":"2022-04-22T16:39:28.616826Z","shell.execute_reply.started":"2022-04-22T16:39:28.239336Z","shell.execute_reply":"2022-04-22T16:39:28.61585Z"}}},{"cell_type":"raw","source":"train_inputs = torch.tensor(train_inputs)\ntrain_labels = torch.tensor(train_labels)\ntrain_masks = torch.tensor(train_masks)","metadata":{"id":"jw5K2A5Ko1RF","execution":{"iopub.status.busy":"2022-04-22T16:39:28.618221Z","iopub.execute_input":"2022-04-22T16:39:28.618462Z","iopub.status.idle":"2022-04-22T16:39:30.379625Z","shell.execute_reply.started":"2022-04-22T16:39:28.618433Z","shell.execute_reply":"2022-04-22T16:39:30.378508Z"}}},{"cell_type":"raw","source":"validation_inputs = torch.tensor(validation_inputs)\nvalidation_labels = torch.tensor(validation_labels)\nvalidation_masks = torch.tensor(validation_masks)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:39:30.38101Z","iopub.execute_input":"2022-04-22T16:39:30.381302Z","iopub.status.idle":"2022-04-22T16:39:30.585352Z","shell.execute_reply.started":"2022-04-22T16:39:30.38127Z","shell.execute_reply":"2022-04-22T16:39:30.584187Z"}}},{"cell_type":"raw","source":"train_labels","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:39:30.586909Z","iopub.execute_input":"2022-04-22T16:39:30.587142Z","iopub.status.idle":"2022-04-22T16:39:30.621544Z","shell.execute_reply.started":"2022-04-22T16:39:30.587113Z","shell.execute_reply":"2022-04-22T16:39:30.620706Z"}}},{"cell_type":"raw","source":"train_data = TensorDataset(train_inputs, train_masks, train_labels)\ntrain_dataloader = DataLoader(\n    train_data,\n    sampler=RandomSampler(train_data),\n    batch_size=32\n)","metadata":{"id":"GEgLpFVlo1Z-","execution":{"iopub.status.busy":"2022-04-22T16:39:30.62326Z","iopub.execute_input":"2022-04-22T16:39:30.623829Z","iopub.status.idle":"2022-04-22T16:39:30.629682Z","shell.execute_reply.started":"2022-04-22T16:39:30.623784Z","shell.execute_reply":"2022-04-22T16:39:30.629033Z"}}},{"cell_type":"raw","source":"validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\nvalidation_dataloader = DataLoader(\n    validation_data,\n    sampler=SequentialSampler(validation_data),\n    batch_size=32\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:39:30.631127Z","iopub.execute_input":"2022-04-22T16:39:30.631871Z","iopub.status.idle":"2022-04-22T16:39:30.642258Z","shell.execute_reply.started":"2022-04-22T16:39:30.631826Z","shell.execute_reply":"2022-04-22T16:39:30.641659Z"}}},{"cell_type":"markdown","source":"## Обучение модели","metadata":{"id":"pNl8khAhPYju"}},{"cell_type":"markdown","source":"Загружаем [BertForSequenceClassification](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/modeling.py#L1129):","metadata":{}},{"cell_type":"raw","source":"from pytorch_transformers import AdamW, BertForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:39:30.643862Z","iopub.execute_input":"2022-04-22T16:39:30.644396Z","iopub.status.idle":"2022-04-22T16:39:30.653883Z","shell.execute_reply.started":"2022-04-22T16:39:30.644355Z","shell.execute_reply":"2022-04-22T16:39:30.653155Z"}}},{"cell_type":"markdown","source":"Аналогичные модели есть и для других задач:","metadata":{}},{"cell_type":"raw","source":"from pytorch_transformers import BertForQuestionAnswering, BertForTokenClassification","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:39:30.6551Z","iopub.execute_input":"2022-04-22T16:39:30.656849Z","iopub.status.idle":"2022-04-22T16:39:30.667601Z","shell.execute_reply.started":"2022-04-22T16:39:30.656804Z","shell.execute_reply":"2022-04-22T16:39:30.666648Z"}}},{"cell_type":"raw","source":"model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n# model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-uncased\", num_labels=2)\nmodel.cuda()","metadata":{"id":"gFsCTp_mporB","outputId":"dd067229-1925-4b37-f517-0c14e25420d1","execution":{"iopub.status.busy":"2022-04-22T16:39:30.671195Z","iopub.execute_input":"2022-04-22T16:39:30.67167Z","iopub.status.idle":"2022-04-22T16:39:42.955581Z","shell.execute_reply.started":"2022-04-22T16:39:30.67161Z","shell.execute_reply":"2022-04-22T16:39:42.936939Z"}}},{"cell_type":"raw","source":"param_optimizer = list(model.named_parameters())\nno_decay = ['bias', 'gamma', 'beta']\noptimizer_grouped_parameters = [\n    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n     'weight_decay_rate': 0.01},\n    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n     'weight_decay_rate': 0.0}\n]\n\noptimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n\n","metadata":{"id":"QxSMw0FrptiL","execution":{"iopub.status.busy":"2022-04-22T16:39:42.957607Z","iopub.status.idle":"2022-04-22T16:39:42.958248Z","shell.execute_reply.started":"2022-04-22T16:39:42.957934Z","shell.execute_reply":"2022-04-22T16:39:42.957964Z"}}},{"cell_type":"raw","source":"from IPython.display import clear_output\n\n# Будем сохранять loss во время обучения\n# и рисовать график в режиме реального времени\ntrain_loss_set = []\ntrain_loss = 0\n\n\n# Обучение\n# Переводим модель в training mode\nmodel.train()\n\n\nfor step, batch in enumerate(train_dataloader):\n    # добавляем батч для вычисления на GPU\n    batch = tuple(t.to(device) for t in batch)\n    # Распаковываем данные из dataloader\n    b_input_ids, b_input_mask, b_labels = batch\n    \n    # если не сделать .zero_grad(), градиенты будут накапливаться\n    optimizer.zero_grad()\n    \n    # Forward pass\n    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n\n    train_loss_set.append(loss[0].item())  \n    \n    # Backward pass\n    loss[0].backward()\n    \n    # Обновляем параметры и делаем шаг используя посчитанные градиенты\n    optimizer.step()\n\n    # Обновляем loss\n    train_loss += loss[0].item()\n    \n    # Рисуем график\n    clear_output(True)\n    plt.plot(train_loss_set)\n    plt.title(\"Training loss\")\n    plt.xlabel(\"Batch\")\n    plt.ylabel(\"Loss\")\n    plt.show()\n    \nprint(\"Loss на обучающей выборке: {0:.5f}\".format(train_loss / len(train_dataloader)))\n\n\n# Валидация\n# Переводим модель в evaluation mode\nmodel.eval()\n\nvalid_preds, valid_labels = [], []\n\nfor batch in validation_dataloader:   \n    # добавляем батч для вычисления на GPU\n    batch = tuple(t.to(device) for t in batch)\n    \n    # Распаковываем данные из dataloader\n    b_input_ids, b_input_mask, b_labels = batch\n    \n    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n    # Это ускорит процесс предсказания меток для валидационных данных.\n    with torch.no_grad():\n        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n\n    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n    logits = logits[0].detach().cpu().numpy()\n    label_ids = b_labels.to('cpu').numpy()\n    \n    batch_preds = np.argmax(logits, axis=1)\n    batch_labels = np.concatenate(label_ids)     \n    valid_preds.extend(batch_preds)\n    valid_labels.extend(batch_labels)\n\nprint(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n    accuracy_score(valid_labels, valid_preds) * 100\n))","metadata":{"id":"6J-FYdx6nFE_","outputId":"8e388ad1-f9db-4c7b-d080-6c0a0e964610","execution":{"iopub.status.busy":"2022-04-22T16:39:42.960535Z","iopub.status.idle":"2022-04-22T16:39:42.961097Z","shell.execute_reply.started":"2022-04-22T16:39:42.960797Z","shell.execute_reply":"2022-04-22T16:39:42.960826Z"}}},{"cell_type":"raw","source":"print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n    accuracy_score(valid_labels, valid_preds) * 100\n))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:39:42.962954Z","iopub.status.idle":"2022-04-22T16:39:42.963445Z","shell.execute_reply.started":"2022-04-22T16:39:42.963185Z","shell.execute_reply":"2022-04-22T16:39:42.963211Z"}}},{"cell_type":"markdown","source":"# Оценка качества на отложенной выборке","metadata":{"id":"mkyubuJSOzg3"}},{"cell_type":"raw","source":"tokenized_texts = [tokenizer.tokenize(sent) for sent in test_sentences]\ninput_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n\ninput_ids = pad_sequences(\n    input_ids,\n    maxlen=100,\n    dtype=\"long\",\n    truncating=\"post\",\n    padding=\"post\"\n)","metadata":{"id":"mAN0LZBOOPVh","execution":{"iopub.status.busy":"2022-04-22T16:39:42.965313Z","iopub.status.idle":"2022-04-22T16:39:42.965804Z","shell.execute_reply.started":"2022-04-22T16:39:42.965527Z","shell.execute_reply":"2022-04-22T16:39:42.965553Z"}}},{"cell_type":"raw","source":"attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n\nprediction_inputs = torch.tensor(input_ids)\nprediction_masks = torch.tensor(attention_masks)\nprediction_labels = torch.tensor(test_gt)\n\nprediction_data = TensorDataset(\n    prediction_inputs,\n    prediction_masks,\n    prediction_labels\n)\n\nprediction_dataloader = DataLoader(\n    prediction_data, \n    sampler=SequentialSampler(prediction_data),\n    batch_size=32\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:39:42.967301Z","iopub.status.idle":"2022-04-22T16:39:42.967788Z","shell.execute_reply.started":"2022-04-22T16:39:42.967511Z","shell.execute_reply":"2022-04-22T16:39:42.967537Z"}}},{"cell_type":"raw","source":"model.eval()\ntest_preds, test_labels = [], []\n\nfor batch in prediction_dataloader:\n    # добавляем батч для вычисления на GPU\n    batch = tuple(t.to(device) for t in batch)\n    \n    # Распаковываем данные из dataloader\n    b_input_ids, b_input_mask, b_labels = batch\n    \n    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n    # Это ускорит процесс предсказания меток для тестовых данных.\n    with torch.no_grad():\n        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n\n    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n    logits = logits[0].detach().cpu().numpy()\n    label_ids = b_labels.to('cpu').numpy()\n\n    # Сохраняем предсказанные классы и ground truth\n    batch_preds = np.argmax(logits, axis=1)\n    batch_labels = np.concatenate(label_ids)  \n    test_preds.extend(batch_preds)\n    test_labels.extend(batch_labels)","metadata":{"id":"Hba10sXR7Xi6","execution":{"iopub.status.busy":"2022-04-22T16:39:42.969447Z","iopub.status.idle":"2022-04-22T16:39:42.969927Z","shell.execute_reply.started":"2022-04-22T16:39:42.969672Z","shell.execute_reply":"2022-04-22T16:39:42.969696Z"}}},{"cell_type":"raw","source":"acc_score = accuracy_score(test_labels, test_preds)\nprint('Процент правильных предсказаний на отложенной выборке составил: {0:.2f}%'.format(\n    acc_score*100\n))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:39:42.971953Z","iopub.status.idle":"2022-04-22T16:39:42.972479Z","shell.execute_reply.started":"2022-04-22T16:39:42.972194Z","shell.execute_reply":"2022-04-22T16:39:42.97222Z"}}},{"cell_type":"raw","source":"print('Неправильных предсказаний: {0}/{1}'.format(\n    sum(np.array(test_labels) != np.array(test_preds)),\n    len(test_labels)\n))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:39:42.974133Z","iopub.status.idle":"2022-04-22T16:39:42.974593Z","shell.execute_reply.started":"2022-04-22T16:39:42.97433Z","shell.execute_reply":"2022-04-22T16:39:42.974353Z"}}},{"cell_type":"markdown","source":"### Задание. Внимательно изучите датасет с русскими твитами. В чем его особенности? Нет ли явных паттернов или ключевых слов, которые однозначно определяют сентимент твита?","metadata":{}},{"cell_type":"raw","source":"list(pos_texts[3])[:10]","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:39:42.976584Z","iopub.status.idle":"2022-04-22T16:39:42.977054Z","shell.execute_reply.started":"2022-04-22T16:39:42.976815Z","shell.execute_reply":"2022-04-22T16:39:42.976839Z"}}},{"cell_type":"raw","source":"len([line for line in list(pos_texts[3]) if (\")\" in line) or \":D\" in line])/len(list(pos_texts[3]))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:39:42.978153Z","iopub.status.idle":"2022-04-22T16:39:42.97864Z","shell.execute_reply.started":"2022-04-22T16:39:42.978366Z","shell.execute_reply":"2022-04-22T16:39:42.978391Z"}}},{"cell_type":"raw","source":"list(neg_texts[3])[:50]","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:39:42.98026Z","iopub.status.idle":"2022-04-22T16:39:42.980763Z","shell.execute_reply.started":"2022-04-22T16:39:42.980485Z","shell.execute_reply":"2022-04-22T16:39:42.980509Z"}}},{"cell_type":"raw","source":"len([line for line in list(neg_texts[3]) if (\"(\" in line) or \"D:\" in line])/len(list(pos_texts[3]))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:39:42.982332Z","iopub.status.idle":"2022-04-22T16:39:42.982821Z","shell.execute_reply.started":"2022-04-22T16:39:42.982551Z","shell.execute_reply":"2022-04-22T16:39:42.982575Z"}}},{"cell_type":"markdown","source":"### Задание. Попробуйте удалить пунктуацию из датасета с русскими твитами и перезапустите дообучение модели. Изменилось ли итоговое качество работы модели? Почему?","metadata":{}},{"cell_type":"code","source":"# import re\n# pos_texts[3] = pd.Series([re.sub(r':D|D:|[^\\w\\s]', '', line) for line in list(pos_texts[3])])\n# neg_texts[3] = pd.Series([re.sub(r':D|D:|[^\\w\\s]', '', line) for line in list(neg_texts[3])])","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:51:01.389613Z","iopub.execute_input":"2022-04-26T12:51:01.390305Z","iopub.status.idle":"2022-04-26T12:51:01.402799Z","shell.execute_reply.started":"2022-04-26T12:51:01.390257Z","shell.execute_reply":"2022-04-26T12:51:01.401857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Домашнее задание IMDB Dataset of 50K Movie Reviews","metadata":{}},{"cell_type":"markdown","source":"Скачайте датасет с отзывами на фильмы. Например, используйте датасет [IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews). ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n#dataset = pd.read_csv('datasets/bert_sentiment_analysis/homework/IMDB_Dataset.csv')\ndataset = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:51:01.404588Z","iopub.execute_input":"2022-04-26T12:51:01.404884Z","iopub.status.idle":"2022-04-26T12:51:02.006321Z","shell.execute_reply.started":"2022-04-26T12:51:01.404846Z","shell.execute_reply":"2022-04-26T12:51:02.005581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:51:02.008178Z","iopub.execute_input":"2022-04-26T12:51:02.009214Z","iopub.status.idle":"2022-04-26T12:51:02.02399Z","shell.execute_reply.started":"2022-04-26T12:51:02.009155Z","shell.execute_reply":"2022-04-26T12:51:02.023102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.sentiment.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:51:02.025626Z","iopub.execute_input":"2022-04-26T12:51:02.026145Z","iopub.status.idle":"2022-04-26T12:51:02.040391Z","shell.execute_reply.started":"2022-04-26T12:51:02.02609Z","shell.execute_reply":"2022-04-26T12:51:02.039489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.review.str.len().hist(bins=50)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:51:02.042261Z","iopub.execute_input":"2022-04-26T12:51:02.042879Z","iopub.status.idle":"2022-04-26T12:51:02.414327Z","shell.execute_reply.started":"2022-04-26T12:51:02.042835Z","shell.execute_reply":"2022-04-26T12:51:02.413649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.review.str.len().describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:51:02.415538Z","iopub.execute_input":"2022-04-26T12:51:02.415808Z","iopub.status.idle":"2022-04-26T12:51:02.462928Z","shell.execute_reply.started":"2022-04-26T12:51:02.415767Z","shell.execute_reply":"2022-04-26T12:51:02.462041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n\\n\".join(list(dataset.review.sample(3))))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:51:02.464518Z","iopub.execute_input":"2022-04-26T12:51:02.464801Z","iopub.status.idle":"2022-04-26T12:51:02.473595Z","shell.execute_reply.started":"2022-04-26T12:51:02.464762Z","shell.execute_reply":"2022-04-26T12:51:02.470481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences = list(dataset.review)\nsentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n\nlabels = list(dataset.sentiment.map({'positive': 1, 'negative': 0}))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:51:02.479687Z","iopub.execute_input":"2022-04-26T12:51:02.480259Z","iopub.status.idle":"2022-04-26T12:51:02.567351Z","shell.execute_reply.started":"2022-04-26T12:51:02.480225Z","shell.execute_reply":"2022-04-26T12:51:02.566546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[3:5]","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:51:02.568791Z","iopub.execute_input":"2022-04-26T12:51:02.569035Z","iopub.status.idle":"2022-04-26T12:51:02.580783Z","shell.execute_reply.started":"2022-04-26T12:51:02.569003Z","shell.execute_reply":"2022-04-26T12:51:02.579855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(zip(*(sentences[3:5], labels[3:5])))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:51:02.582484Z","iopub.execute_input":"2022-04-26T12:51:02.582973Z","iopub.status.idle":"2022-04-26T12:51:02.592545Z","shell.execute_reply.started":"2022-04-26T12:51:02.582934Z","shell.execute_reply":"2022-04-26T12:51:02.59159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_sentences, test_sentences, train_gt, test_gt = train_test_split(sentences, labels, shuffle=True, random_state=42, test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:51:02.594228Z","iopub.execute_input":"2022-04-26T12:51:02.595141Z","iopub.status.idle":"2022-04-26T12:51:02.627458Z","shell.execute_reply.started":"2022-04-26T12:51:02.595099Z","shell.execute_reply":"2022-04-26T12:51:02.62667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_gt), len(test_gt))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:51:02.628733Z","iopub.execute_input":"2022-04-26T12:51:02.629084Z","iopub.status.idle":"2022-04-26T12:51:02.635228Z","shell.execute_reply.started":"2022-04-26T12:51:02.629039Z","shell.execute_reply":"2022-04-26T12:51:02.634393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inputs","metadata":{"id":"ex5O1eV-Pfct"}},{"cell_type":"code","source":"from pytorch_transformers import BertTokenizer, BertConfig\n\n# Подробное описание модели https://huggingface.co/bert-base-uncased\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n#tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)\n\ntokenized_texts = [tokenizer.tokenize(sent) for sent in train_sentences]\nprint(train_sentences[0])\nprint(tokenized_texts[0])","metadata":{"id":"Z474sSC6oe7A","outputId":"fbaa8fd8-bccd-4feb-ce52-beba5d293cfa","execution":{"iopub.status.busy":"2022-04-26T12:51:02.636945Z","iopub.execute_input":"2022-04-26T12:51:02.637528Z","iopub.status.idle":"2022-04-26T12:54:16.956687Z","shell.execute_reply.started":"2022-04-26T12:51:02.637416Z","shell.execute_reply":"2022-04-26T12:54:16.955923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#only for quick analyze\nseries_tokenized_texts = pd.Series(tokenized_texts)\nseries_tokenized_texts.map(len).hist(bins=50)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:54:16.957952Z","iopub.execute_input":"2022-04-26T12:54:16.958199Z","iopub.status.idle":"2022-04-26T12:54:17.283974Z","shell.execute_reply.started":"2022-04-26T12:54:16.958165Z","shell.execute_reply":"2022-04-26T12:54:17.283271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"series_tokenized_texts.map(len).describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:54:17.285389Z","iopub.execute_input":"2022-04-26T12:54:17.285654Z","iopub.status.idle":"2022-04-26T12:54:17.311541Z","shell.execute_reply.started":"2022-04-26T12:54:17.285618Z","shell.execute_reply":"2022-04-26T12:54:17.310746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"BERTу нужно предоставить специальный формат входных данных.\n\n\n- **input ids**: последовательность чисел, отождествляющих каждый токен с его номером в словаре.\n- **labels**: вектор из нулей и единиц. В нашем случае нули обозначают негативную эмоциональную окраску, единицы - положительную.\n- **segment mask**: (необязательно) последовательность нулей и единиц, которая показывает, состоит ли входной текст из одного или двух предложений. Для случая одного предложения получится вектор из одних нулей. Для двух: <length_of_sent_1> нулей и <length_of_sent_2> единиц.\n- **attention mask**: (необязательно) последовательность нулей и единиц, где единицы обозначают токены предложения, нули - паддинг.","metadata":{"id":"87_kXUeT2-br"}},{"cell_type":"code","source":"MAX_LEN = 500\n\n# padding: String, 'pre' or 'post' (optional, defaults to 'pre'):\n#         pad either before or after each sequence.\n# truncating: String, 'pre' or 'post' (optional, defaults to 'pre'):\n#        remove values from sequences larger than `maxlen`, either \n#        at the beginning or at the end of the sequences.\n\n# возможно сентимент отзыва больше раскрывается в конце, а не в начале, \n# как следствие, может быть лучше задавать 'pre'\nTRUNC_PAD_TYPE = \"pre\" #'pre' or 'post'\n\ninput_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\ninput_ids = pad_sequences(\n    input_ids,\n    maxlen=MAX_LEN,\n    dtype=\"long\",\n    truncating=TRUNC_PAD_TYPE,\n    padding=TRUNC_PAD_TYPE\n)\nattention_masks = [[float(i>0) for i in seq] for seq in input_ids]","metadata":{"id":"Cp9BPRd1tMIo","execution":{"iopub.status.busy":"2022-04-26T12:54:17.312981Z","iopub.execute_input":"2022-04-26T12:54:17.313251Z","iopub.status.idle":"2022-04-26T12:54:40.403926Z","shell.execute_reply.started":"2022-04-26T12:54:17.313216Z","shell.execute_reply":"2022-04-26T12:54:40.403101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n    input_ids, train_gt, \n    random_state=42,\n    test_size=0.1\n)\n\ntrain_masks, validation_masks, _, _ = train_test_split(\n    attention_masks,\n    input_ids,\n    random_state=42,\n    test_size=0.1\n)","metadata":{"id":"aFbE-UHvsb7-","execution":{"iopub.status.busy":"2022-04-26T12:54:40.405172Z","iopub.execute_input":"2022-04-26T12:54:40.405455Z","iopub.status.idle":"2022-04-26T12:54:40.525263Z","shell.execute_reply.started":"2022-04-26T12:54:40.405402Z","shell.execute_reply":"2022-04-26T12:54:40.524475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_inputs = torch.tensor(train_inputs)\ntrain_labels = torch.tensor(train_labels)\ntrain_masks = torch.tensor(train_masks)","metadata":{"id":"jw5K2A5Ko1RF","execution":{"iopub.status.busy":"2022-04-26T12:54:40.526484Z","iopub.execute_input":"2022-04-26T12:54:40.526742Z","iopub.status.idle":"2022-04-26T12:54:41.771433Z","shell.execute_reply.started":"2022-04-26T12:54:40.526708Z","shell.execute_reply":"2022-04-26T12:54:41.77063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_inputs = torch.tensor(validation_inputs)\nvalidation_labels = torch.tensor(validation_labels)\nvalidation_masks = torch.tensor(validation_masks)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:54:41.772786Z","iopub.execute_input":"2022-04-26T12:54:41.773236Z","iopub.status.idle":"2022-04-26T12:54:41.916685Z","shell.execute_reply.started":"2022-04-26T12:54:41.773194Z","shell.execute_reply":"2022-04-26T12:54:41.915857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:54:41.917983Z","iopub.execute_input":"2022-04-26T12:54:41.918358Z","iopub.status.idle":"2022-04-26T12:54:41.926009Z","shell.execute_reply.started":"2022-04-26T12:54:41.918318Z","shell.execute_reply":"2022-04-26T12:54:41.925323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 10\n\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\ntrain_dataloader = DataLoader(\n    train_data,\n    sampler=RandomSampler(train_data),\n    batch_size=BATCH_SIZE\n)","metadata":{"id":"GEgLpFVlo1Z-","execution":{"iopub.status.busy":"2022-04-26T12:54:41.927302Z","iopub.execute_input":"2022-04-26T12:54:41.927873Z","iopub.status.idle":"2022-04-26T12:54:41.934913Z","shell.execute_reply.started":"2022-04-26T12:54:41.927833Z","shell.execute_reply":"2022-04-26T12:54:41.934142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\nvalidation_dataloader = DataLoader(\n    validation_data,\n    sampler=SequentialSampler(validation_data),\n    batch_size=BATCH_SIZE*3\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:54:41.936086Z","iopub.execute_input":"2022-04-26T12:54:41.936442Z","iopub.status.idle":"2022-04-26T12:54:41.944757Z","shell.execute_reply.started":"2022-04-26T12:54:41.936388Z","shell.execute_reply":"2022-04-26T12:54:41.943935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Обучение модели","metadata":{"id":"pNl8khAhPYju"}},{"cell_type":"markdown","source":"Загружаем [BertForSequenceClassification](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/modeling.py#L1129):","metadata":{}},{"cell_type":"code","source":"from pytorch_transformers import AdamW, BertForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:54:41.946078Z","iopub.execute_input":"2022-04-26T12:54:41.946384Z","iopub.status.idle":"2022-04-26T12:54:41.954392Z","shell.execute_reply.started":"2022-04-26T12:54:41.946349Z","shell.execute_reply":"2022-04-26T12:54:41.95361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Аналогичные модели есть и для других задач:","metadata":{}},{"cell_type":"code","source":"from pytorch_transformers import BertForQuestionAnswering, BertForTokenClassification","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:54:41.955528Z","iopub.execute_input":"2022-04-26T12:54:41.956173Z","iopub.status.idle":"2022-04-26T12:54:41.963214Z","shell.execute_reply.started":"2022-04-26T12:54:41.956147Z","shell.execute_reply":"2022-04-26T12:54:41.962382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n# model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-uncased\", num_labels=2)\nmodel.cuda()","metadata":{"id":"gFsCTp_mporB","outputId":"dd067229-1925-4b37-f517-0c14e25420d1","execution":{"iopub.status.busy":"2022-04-26T12:54:41.964343Z","iopub.execute_input":"2022-04-26T12:54:41.964777Z","iopub.status.idle":"2022-04-26T12:54:48.173189Z","shell.execute_reply.started":"2022-04-26T12:54:41.964741Z","shell.execute_reply":"2022-04-26T12:54:48.172435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_optimizer = list(model.named_parameters())\nno_decay = ['bias', 'gamma', 'beta']\noptimizer_grouped_parameters = [\n    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n     'weight_decay_rate': 0.01},\n    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n     'weight_decay_rate': 0.0}\n]\n\noptimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n\n","metadata":{"id":"QxSMw0FrptiL","execution":{"iopub.status.busy":"2022-04-26T12:54:48.174635Z","iopub.execute_input":"2022-04-26T12:54:48.174902Z","iopub.status.idle":"2022-04-26T12:54:48.183016Z","shell.execute_reply.started":"2022-04-26T12:54:48.174866Z","shell.execute_reply":"2022-04-26T12:54:48.182318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import clear_output\n\n# Будем сохранять loss во время обучения\n# и рисовать график в режиме реального времени\ntrain_loss_set = []\ntrain_loss = 0\n\n\n# Обучение\n# Переводим модель в training mode\nmodel.train()\n\n\nfor step, batch in enumerate(train_dataloader):\n    # добавляем батч для вычисления на GPU\n    batch = tuple(t.to(device) for t in batch)\n    # Распаковываем данные из dataloader\n    b_input_ids, b_input_mask, b_labels = batch\n    \n    # если не сделать .zero_grad(), градиенты будут накапливаться\n    optimizer.zero_grad()\n    \n    # Forward pass\n    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n\n    train_loss_set.append(loss[0].item())  \n    \n    # Backward pass\n    loss[0].backward()\n    \n    # Обновляем параметры и делаем шаг используя посчитанные градиенты\n    optimizer.step()\n\n    # Обновляем loss\n    train_loss += loss[0].item()\n    \n    # Рисуем график\n    clear_output(True)\n    plt.plot(train_loss_set)\n    plt.title(\"Training loss\")\n    plt.xlabel(\"Batch\")\n    plt.ylabel(\"Loss\")\n    plt.show()\n    \n    \nprint(\"Loss на обучающей выборке: {0:.5f}\".format(train_loss / len(train_dataloader)))","metadata":{"id":"6J-FYdx6nFE_","outputId":"8e388ad1-f9db-4c7b-d080-6c0a0e964610","execution":{"iopub.status.busy":"2022-04-26T12:54:48.184714Z","iopub.execute_input":"2022-04-26T12:54:48.185613Z","iopub.status.idle":"2022-04-26T12:54:57.667386Z","shell.execute_reply.started":"2022-04-26T12:54:48.185573Z","shell.execute_reply":"2022-04-26T12:54:57.666243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Валидация\n# Переводим модель в evaluation mode\nmodel.eval()\n\nvalid_preds, valid_labels = [], []\n\nfor batch in validation_dataloader:   \n    # добавляем батч для вычисления на GPU\n    batch = tuple(t.to(device) for t in batch)\n    \n    # Распаковываем данные из dataloader\n    b_input_ids, b_input_mask, b_labels = batch\n    \n    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n    # Это ускорит процесс предсказания меток для валидационных данных.\n    with torch.no_grad():\n        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n\n    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n    logits = logits[0].detach().cpu().numpy()\n    label_ids = b_labels.to('cpu').numpy()\n    \n    batch_preds = np.argmax(logits, axis=1)\n    # изначально было np.concatenate(label_ids), но по какой то причина на этом датасете\n    # такой вариант не работает, т.к. мы получаем плоский тензор, в итоге заменил на \n    # конструкцию ниже (хотя на само деле непонятно как работало раньше)\n    batch_labels = np.concatenate([label_ids] if label_ids.ndim == 1 else label_ids)\n    valid_preds.extend(batch_preds)\n    valid_labels.extend(batch_labels)\n\nprint(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n    accuracy_score(valid_labels, valid_preds) * 100\n))","metadata":{"id":"6J-FYdx6nFE_","outputId":"8e388ad1-f9db-4c7b-d080-6c0a0e964610","execution":{"iopub.status.busy":"2022-04-26T12:54:57.668575Z","iopub.execute_input":"2022-04-26T12:54:57.668994Z","iopub.status.idle":"2022-04-26T12:54:57.8826Z","shell.execute_reply.started":"2022-04-26T12:54:57.668953Z","shell.execute_reply":"2022-04-26T12:54:57.881815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n    accuracy_score(valid_labels, valid_preds) * 100\n))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:54:57.886471Z","iopub.execute_input":"2022-04-26T12:54:57.887236Z","iopub.status.idle":"2022-04-26T12:54:57.894202Z","shell.execute_reply.started":"2022-04-26T12:54:57.887197Z","shell.execute_reply":"2022-04-26T12:54:57.893286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Оценка качества на отложенной выборке","metadata":{"id":"mkyubuJSOzg3"}},{"cell_type":"code","source":"tokenized_texts = [tokenizer.tokenize(sent) for sent in test_sentences]\ninput_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n\ninput_ids = pad_sequences(\n    input_ids,\n    maxlen=MAX_LEN,\n    dtype=\"long\",\n    truncating=TRUNC_PAD_TYPE,\n    padding=TRUNC_PAD_TYPE\n)","metadata":{"id":"mAN0LZBOOPVh","execution":{"iopub.status.busy":"2022-04-26T12:54:57.895543Z","iopub.execute_input":"2022-04-26T12:54:57.896406Z","iopub.status.idle":"2022-04-26T12:56:25.896796Z","shell.execute_reply.started":"2022-04-26T12:54:57.896259Z","shell.execute_reply":"2022-04-26T12:56:25.895833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n\nprediction_inputs = torch.tensor(input_ids)\nprediction_masks = torch.tensor(attention_masks)\nprediction_labels = torch.tensor(test_gt)\n\nprediction_data = TensorDataset(\n    prediction_inputs,\n    prediction_masks,\n    prediction_labels\n)\n\nprediction_dataloader = DataLoader(\n    prediction_data, \n    sampler=SequentialSampler(prediction_data),\n    batch_size=BATCH_SIZE*3\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:57:36.884798Z","iopub.execute_input":"2022-04-26T12:57:36.885601Z","iopub.status.idle":"2022-04-26T12:57:42.923453Z","shell.execute_reply.started":"2022-04-26T12:57:36.885556Z","shell.execute_reply":"2022-04-26T12:57:42.922675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\ntest_preds, test_labels = [], []\n\nfor batch in prediction_dataloader:\n    # добавляем батч для вычисления на GPU\n    batch = tuple(t.to(device) for t in batch)\n    \n    # Распаковываем данные из dataloader\n    b_input_ids, b_input_mask, b_labels = batch\n    \n    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n    # Это ускорит процесс предсказания меток для тестовых данных.\n    with torch.no_grad():\n        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n\n    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n    logits = logits[0].detach().cpu().numpy()\n    label_ids = b_labels.to('cpu').numpy()\n\n    # Сохраняем предсказанные классы и ground truth\n    batch_preds = np.argmax(logits, axis=1)\n    batch_labels = np.concatenate([label_ids] if label_ids.ndim == 1 else label_ids)  \n    test_preds.extend(batch_preds)\n    test_labels.extend(batch_labels)","metadata":{"id":"Hba10sXR7Xi6","execution":{"iopub.status.busy":"2022-04-26T12:57:42.925137Z","iopub.execute_input":"2022-04-26T12:57:42.925398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc_score = accuracy_score(test_labels, test_preds)\nprint('Процент правильных предсказаний на отложенной выборке составил: {0:.2f}%'.format(\n    acc_score*100\n))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:56:32.884393Z","iopub.status.idle":"2022-04-26T12:56:32.885216Z","shell.execute_reply.started":"2022-04-26T12:56:32.884961Z","shell.execute_reply":"2022-04-26T12:56:32.884986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Неправильных предсказаний: {0}/{1}'.format(\n    sum(np.array(test_labels) != np.array(test_preds)),\n    len(test_labels)\n))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:56:32.886677Z","iopub.status.idle":"2022-04-26T12:56:32.887087Z","shell.execute_reply.started":"2022-04-26T12:56:32.886867Z","shell.execute_reply":"2022-04-26T12:56:32.886888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}